{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population bootstrap trend comparison\n",
    "\n",
    "We are going to create tren models (linear and cuadratict) and we are going to compare the coefficients of the models using bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as stats\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import statistics as stats\n",
    "import seaborn as sns \n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,recall_score, precision_score, confusion_matrix\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Código Externo</th>\n",
       "      <th>FALLECE</th>\n",
       "      <th>UCI</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Edad del Paciente</th>\n",
       "      <th>Sexo del Paciente</th>\n",
       "      <th>LEU</th>\n",
       "      <th>NEU</th>\n",
       "      <th>NEUp</th>\n",
       "      <th>LIN</th>\n",
       "      <th>...</th>\n",
       "      <th>WBC-N</th>\n",
       "      <th>ASLYP</th>\n",
       "      <th>ASLYA</th>\n",
       "      <th>RELPL</th>\n",
       "      <th>RELYP</th>\n",
       "      <th>RELYA</th>\n",
       "      <th>NEUGI</th>\n",
       "      <th>NEURI</th>\n",
       "      <th>ASLPL</th>\n",
       "      <th>Revision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>106066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600387200000000000</td>\n",
       "      <td>83</td>\n",
       "      <td>M</td>\n",
       "      <td>6.04</td>\n",
       "      <td>4.01</td>\n",
       "      <td>66.4</td>\n",
       "      <td>1.08</td>\n",
       "      <td>...</td>\n",
       "      <td>6.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.04</td>\n",
       "      <td>151.1</td>\n",
       "      <td>43.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>101660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1583280000000000000</td>\n",
       "      <td>76</td>\n",
       "      <td>F</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.84</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.29</td>\n",
       "      <td>...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.22</td>\n",
       "      <td>146.6</td>\n",
       "      <td>53.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>121289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1584835200000000000</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>9.10</td>\n",
       "      <td>7.52</td>\n",
       "      <td>82.7</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>9.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.11</td>\n",
       "      <td>151.4</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>127383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1587513600000000000</td>\n",
       "      <td>85</td>\n",
       "      <td>M</td>\n",
       "      <td>9.92</td>\n",
       "      <td>6.42</td>\n",
       "      <td>64.7</td>\n",
       "      <td>2.01</td>\n",
       "      <td>...</td>\n",
       "      <td>9.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>151.0</td>\n",
       "      <td>58.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1585612800000000000</td>\n",
       "      <td>65</td>\n",
       "      <td>M</td>\n",
       "      <td>5.57</td>\n",
       "      <td>2.55</td>\n",
       "      <td>45.8</td>\n",
       "      <td>2.27</td>\n",
       "      <td>...</td>\n",
       "      <td>5.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.13</td>\n",
       "      <td>154.8</td>\n",
       "      <td>50.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>104798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1585008000000000000</td>\n",
       "      <td>44</td>\n",
       "      <td>M</td>\n",
       "      <td>5.12</td>\n",
       "      <td>3.02</td>\n",
       "      <td>59.1</td>\n",
       "      <td>1.18</td>\n",
       "      <td>...</td>\n",
       "      <td>5.12</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>12.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>146.9</td>\n",
       "      <td>56.6</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>108894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1584057600000000000</td>\n",
       "      <td>72</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>111786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1585008000000000000</td>\n",
       "      <td>77</td>\n",
       "      <td>F</td>\n",
       "      <td>5.68</td>\n",
       "      <td>3.60</td>\n",
       "      <td>63.3</td>\n",
       "      <td>1.68</td>\n",
       "      <td>...</td>\n",
       "      <td>5.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>153.9</td>\n",
       "      <td>58.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>132015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1584144000000000000</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>6.72</td>\n",
       "      <td>5.63</td>\n",
       "      <td>83.8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>6.72</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.06</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.11</td>\n",
       "      <td>145.1</td>\n",
       "      <td>52.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>110435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1587168000000000000</td>\n",
       "      <td>67</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Código Externo  FALLECE  UCI                Fecha  Edad del Paciente  \\\n",
       "288          106066      NaN  NaN  1600387200000000000                 83   \n",
       "206          101660      NaN  NaN  1583280000000000000                 76   \n",
       "69           121289      0.0  0.0  1584835200000000000                 61   \n",
       "221          127383      NaN  NaN  1587513600000000000                 85   \n",
       "4             11258      NaN  NaN  1585612800000000000                 65   \n",
       "..              ...      ...  ...                  ...                ...   \n",
       "78           104798      NaN  NaN  1585008000000000000                 44   \n",
       "15           108894      0.0  0.0  1584057600000000000                 72   \n",
       "76           111786      NaN  NaN  1585008000000000000                 77   \n",
       "14           132015      NaN  NaN  1584144000000000000                 60   \n",
       "217          110435      0.0  0.0  1587168000000000000                 67   \n",
       "\n",
       "    Sexo del Paciente   LEU   NEU  NEUp   LIN  ...  WBC-N  ASLYP  ASLYA  \\\n",
       "288                 M  6.04  4.01  66.4  1.08  ...   6.04    0.0   0.00   \n",
       "206                 F  3.75  1.84  49.0  1.29  ...   3.75    0.0   0.00   \n",
       "69                  M  9.10  7.52  82.7  0.60  ...   9.10    0.0   0.00   \n",
       "221                 M  9.92  6.42  64.7  2.01  ...   9.92    0.0   0.00   \n",
       "4                   M  5.57  2.55  45.8  2.27  ...   5.57    0.0   0.00   \n",
       "..                ...   ...   ...   ...   ...  ...    ...    ...    ...   \n",
       "78                  M  5.12  3.02  59.1  1.18  ...   5.12    1.4   0.07   \n",
       "15                  M   NaN   NaN   NaN   NaN  ...    NaN    NaN    NaN   \n",
       "76                  F  5.68  3.60  63.3  1.68  ...   5.68    0.0   0.00   \n",
       "14                  F  6.72  5.63  83.8  0.75  ...   6.72    0.9   0.06   \n",
       "217                 M   NaN   NaN   NaN   NaN  ...    NaN    NaN    NaN   \n",
       "\n",
       "     RELPL  RELYP  RELYA  NEUGI  NEURI  ASLPL  Revision  \n",
       "288    3.7    0.7   0.04  151.1   43.5    0.0         2  \n",
       "206   17.1    5.9   0.22  146.6   53.8    0.0         1  \n",
       "69    18.3    1.2   0.11  151.4   49.3    0.0         2  \n",
       "221    5.0    1.0   0.10  151.0   58.6    0.0         2  \n",
       "4      5.7    2.3   0.13  154.8   50.2    0.0         3  \n",
       "..     ...    ...    ...    ...    ...    ...       ...  \n",
       "78    12.7    2.9   0.15  146.9   56.6    5.9         2  \n",
       "15     NaN    NaN    NaN    NaN    NaN    NaN         1  \n",
       "76     7.1    2.1   0.12  153.9   58.4    0.0         2  \n",
       "14    14.7    1.6   0.11  145.1   52.3    8.0         1  \n",
       "217    NaN    NaN    NaN    NaN    NaN    NaN         1  \n",
       "\n",
       "[203 rows x 71 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "\n",
    "X_train = pd.read_pickle(\"X_train\")\n",
    "y_train = np.load(\"y_train.npy\",allow_pickle = True)\n",
    "\n",
    "#print(X_train)\n",
    "\n",
    "#print(y_train)\n",
    "\n",
    "X_train[y_train ==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to compute linear model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def lin_reg_model(revi,x_val):\n",
    "    \"\"\"\n",
    "    Función que ajusta un modelo de regresión lineal para el conjunto de datos que viene dado por rev y x_val. Vamos a usar\n",
    "    sklearn, pero podríamos utilizar cualquier otro módulo de algebra lineal\n",
    "    \"\"\"\n",
    "    \n",
    "    #generamos la matrix X, que tiene que contener en una columna rev y en otra rev**2\n",
    "    \n",
    "    \n",
    "    rev_2 = revi**2\n",
    "    \n",
    "    X = np.vstack((np.ones(revi.shape),revi,rev_2)).T #JA Como quiero un polinomio de segundo orden... meto\n",
    "                      #unos que me sirven como \"a\", rev que me sirve como \"b\" y rev_2 que me sirve como \"c\"\n",
    "    \n",
    "    #ajustamos el modelo de regresion lineal\n",
    "    \n",
    "    #le digo false, para que me devuelva todo los coeficientes en coef_\n",
    "    clf = LinearRegression(fit_intercept=False) #yo creo que lo que haría, para que fuesen todos comparables sería \n",
    "    # normalizar los datos pero no lo tengo claro, lo tendría que pensar\n",
    "    \n",
    "    clf.fit(X,x_val)\n",
    "    \n",
    "    #devolvemos los coeficientes\n",
    "    return clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculo de medias según el dataframe y la variable\n",
    "\n",
    "def boot_model_coef(dataframe,variable,B=2000):\n",
    "    \n",
    "    revi= np.array([1,2,3,4])\n",
    "    coef_boot_dist = []\n",
    "    mean_b = []\n",
    "    \n",
    "    #bootstrap_resamplings\n",
    "    for b in range(B):\n",
    "        if(b%250 == 0):\n",
    "            clear_output(wait=True)\n",
    "            print(\"feat\",variable,\" -- boot strapt resamp:\",b,\"/\",B)\n",
    "\n",
    "        #run for each review\n",
    "        mean_array_b = []#mean value for this boot_resampling\n",
    "        \n",
    "        for i in dataframe['Revision'].unique(): ## JA, quiero que i coja los valores únicos. Es decir si aparece 1 que coja todos los 1 a la vez.\n",
    "           \n",
    "            df_mask=dataframe['Revision']==i #get only those with the current review\n",
    "            \n",
    "            filtered_df = dataframe[df_mask]\n",
    "\n",
    "            \n",
    "            data_rev = filtered_df[variable].to_numpy()\n",
    "            \n",
    "\n",
    "            \n",
    "            #get a bootstrap resampling\n",
    "            boot_idx = np.random.choice(range(len(data_rev)),size = len(data_rev))\n",
    "            \n",
    "            mean_rev = np.nanmean(data_rev[boot_idx])\n",
    "            #si tenemos valores que son NaN nos va a dar ese error\n",
    "            mean_array_b.append(mean_rev)\n",
    "            \n",
    "        \n",
    "        #compute the coefficientes for each bootstrap resampling using the mean_array_b\n",
    "        mean_b.append(mean_array_b)\n",
    "        coef_b = lin_reg_model(revi,mean_array_b)\n",
    "        \n",
    "        coef_boot_dist.append(coef_b)\n",
    " \n",
    "    return coef_boot_dist,mean_b #Tengo que poner return en lugar de print, pues si pongo print cuando ejecuto la funcion me sale None junto a los valores. Y si me \n",
    "              #None, no puedo meter la función en lin_reg_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat rNe/L  -- boot strapt resamp: 0 / 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-54-1df638af9d21>:32: RuntimeWarning: Mean of empty slice\n",
      "  mean_rev = np.nanmean(data_rev[boot_idx])\n",
      "<ipython-input-54-1df638af9d21>:32: RuntimeWarning: Mean of empty slice\n",
      "  mean_rev = np.nanmean(data_rev[boot_idx])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-89b50e8afe32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msanos_boot_feat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_b_sanos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboot_model_coef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mno_sanos_boot_feat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_b_no_sanos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboot_model_coef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msanos_boot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanos_boot_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-1df638af9d21>\u001b[0m in \u001b[0;36mboot_model_coef\u001b[0;34m(dataframe, variable, B)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#compute the coefficientes for each bootstrap resampling using the mean_array_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mmean_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_array_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mcoef_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlin_reg_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrevi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_array_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mcoef_boot_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-23f5e15af176>\u001b[0m in \u001b[0;36mlin_reg_model\u001b[0;34m(revi, x_val)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# normalizar los datos pero no lo tengo claro, lo tendría que pensar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#devolvemos los coeficientes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    519\u001b[0m                                    y_numeric=True, multi_output=True)\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    878\u001b[0m                     estimator=estimator)\n\u001b[1;32m    879\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n\u001b[0m\u001b[1;32m    881\u001b[0m                         ensure_2d=False, dtype=None)\n\u001b[1;32m    882\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    721\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "#run over features and compute the bootstrap mean and std for each coefficient and perform the statistical comparison\n",
    "\n",
    "#Creo una lista con los nombres de las columnas a las que me interesa sacar los coeficientes\n",
    "columns_names = X_train.columns.values\n",
    "columns_names_list = list(columns_names)\n",
    "feat_name = columns_names_list[7:-1] #cojo todas las variables hasta la penultima\n",
    "\n",
    "sanos_boot = []\n",
    "no_sanos_boot = []\n",
    "for i in feat_name:\n",
    "   \n",
    "    sanos_boot_feat,mean_b_sanos = boot_model_coef(X_train[y_train==0],i)\n",
    "    no_sanos_boot_feat,mean_b_no_sanos = boot_model_coef(X_train[y_train==1],i)  \n",
    "    \n",
    "    sanos_boot.append(sanos_boot_feat)\n",
    "    no_sanos_boot.append(no_sanos_boot_feat)\n",
    "    \n",
    "    #print(\"Coeficientes de\", i ,\": \\n SANOS:\",lin_reg_model(revi,sanos_means),\"\\n NO SANOS:\",lin_reg_model(revi,no_sanos_means))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11875463486722716\n",
      "0.29855902961946734\n",
      "0.11384471935529686\n",
      "0.7133500215870502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 10.,  50., 174., 369., 530., 451., 268., 116.,  26.,   6.]),\n",
       " array([-2.42426532, -1.91559286, -1.40692039, -0.89824793, -0.38957546,\n",
       "         0.119097  ,  0.62776947,  1.13644193,  1.6451144 ,  2.15378686,\n",
       "         2.66245933]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#working on performence the statistical analysis\n",
    "\n",
    "sanos_boot = np.array(sanos_boot)\n",
    "no_sanos_boot = np.array(no_sanos_boot)\n",
    "\n",
    "print(np.mean(sanos_boot[:,2]))\n",
    "print(np.std(sanos_boot[:,2]))\n",
    "print(np.mean(no_sanos_boot[:,2]))\n",
    "print(np.std(no_sanos_boot[:,2]))\n",
    "\n",
    "\n",
    "plt.hist(sanos_boot[:,2]-no_sanos_boot[:,2])\n",
    "#plt.hist(no_sanos_boot[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
