{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jorgealarconlucas/TFG/blob/master/Modelos_de_machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-ruNeqFp9jnV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as stats\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import statistics as stats\n",
    "import seaborn as sns \n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,recall_score, precision_score, confusion_matrix\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vxi0qdBF9isu"
   },
   "outputs": [],
   "source": [
    "x_train = pd.read_feather('x_train')\n",
    "y_train = np.load ('y_train.npy')\n",
    "x_test = pd.read_feather('x_test')\n",
    "y_test = np.load ('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XLvWaFk-KfP1"
   },
   "outputs": [],
   "source": [
    "y_train = pd.Series(y_train) #Lo paso de numpy a pandas.series\n",
    "y_test = pd.Series(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXcVUQjKBeKj"
   },
   "source": [
    "# Machine learning para revision = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juR47B0PLTdA"
   },
   "source": [
    "### Con X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "E2vhEerI65bC",
    "outputId": "491621a5-6730-498b-8b9d-05611f55179e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Edad del Paciente</th>\n",
       "      <th>Sexo del Paciente</th>\n",
       "      <th>LEU</th>\n",
       "      <th>NEU</th>\n",
       "      <th>NEUp</th>\n",
       "      <th>LIN</th>\n",
       "      <th>LINp</th>\n",
       "      <th>MON</th>\n",
       "      <th>MONp</th>\n",
       "      <th>EOS</th>\n",
       "      <th>...</th>\n",
       "      <th>WBC-N</th>\n",
       "      <th>ASLYP</th>\n",
       "      <th>ASLYA</th>\n",
       "      <th>RELPL</th>\n",
       "      <th>RELYP</th>\n",
       "      <th>RELYA</th>\n",
       "      <th>NEUGI</th>\n",
       "      <th>NEURI</th>\n",
       "      <th>ASLPL</th>\n",
       "      <th>Revision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.840</td>\n",
       "      <td>49.00</td>\n",
       "      <td>1.290</td>\n",
       "      <td>34.40</td>\n",
       "      <td>0.490</td>\n",
       "      <td>13.10</td>\n",
       "      <td>0.110</td>\n",
       "      <td>...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>17.1</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.22</td>\n",
       "      <td>146.60</td>\n",
       "      <td>53.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.05</td>\n",
       "      <td>1.170</td>\n",
       "      <td>38.50</td>\n",
       "      <td>1.050</td>\n",
       "      <td>34.40</td>\n",
       "      <td>0.800</td>\n",
       "      <td>8.84</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.08</td>\n",
       "      <td>151.00</td>\n",
       "      <td>56.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.64</td>\n",
       "      <td>5.416</td>\n",
       "      <td>53.06</td>\n",
       "      <td>3.348</td>\n",
       "      <td>37.26</td>\n",
       "      <td>0.692</td>\n",
       "      <td>7.92</td>\n",
       "      <td>0.064</td>\n",
       "      <td>...</td>\n",
       "      <td>9.64</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.004</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.20</td>\n",
       "      <td>147.86</td>\n",
       "      <td>49.04</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.25</td>\n",
       "      <td>15.160</td>\n",
       "      <td>87.90</td>\n",
       "      <td>0.980</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.880</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.050</td>\n",
       "      <td>...</td>\n",
       "      <td>17.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.11</td>\n",
       "      <td>155.30</td>\n",
       "      <td>48.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.89</td>\n",
       "      <td>3.570</td>\n",
       "      <td>72.90</td>\n",
       "      <td>0.610</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.350</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>4.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.14</td>\n",
       "      <td>148.70</td>\n",
       "      <td>52.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Edad del Paciente  Sexo del Paciente    LEU     NEU   NEUp    LIN   LINp  \\\n",
       "1                76.0                0.0   3.75   1.840  49.00  1.290  34.40   \n",
       "5                66.0                0.0   3.05   1.170  38.50  1.050  34.40   \n",
       "16               37.0                0.0   9.64   5.416  53.06  3.348  37.26   \n",
       "19               85.0                1.0  17.25  15.160  87.90  0.980   5.70   \n",
       "22               74.0                0.0   4.89   3.570  72.90  0.610  12.50   \n",
       "\n",
       "      MON   MONp    EOS  ...  WBC-N  ASLYP  ASLYA  RELPL  RELYP  RELYA  \\\n",
       "1   0.490  13.10  0.110  ...   3.75   0.00  0.000   17.1   5.90   0.22   \n",
       "5   0.800   8.84  0.010  ...   3.05   0.00  0.000    7.6   2.60   0.08   \n",
       "16  0.692   7.92  0.064  ...   9.64   0.14  0.004    8.6   2.54   0.20   \n",
       "19  0.880   5.10  0.050  ...  17.25   0.00  0.000   11.2   0.60   0.11   \n",
       "22  0.350   7.20  0.010  ...   4.89   0.00  0.000   23.0   2.90   0.14   \n",
       "\n",
       "     NEUGI  NEURI  ASLPL  Revision  \n",
       "1   146.60  53.80   0.00       1.0  \n",
       "5   151.00  56.50   0.00       1.0  \n",
       "16  147.86  49.04   0.34       1.0  \n",
       "19  155.30  48.60   0.00       1.0  \n",
       "22  148.70  52.10   0.00       1.0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_1 = x_train[x_train['Revision'] == 1]\n",
    "\n",
    "x_train_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SOpidxanKSpn"
   },
   "outputs": [],
   "source": [
    "#Elimino la variable 'Revision' puesto que una vez he cogido los pacientes con revision=1, la variable ya \n",
    "#no me hace falta.\n",
    "x_train_1 = x_train_1.drop([\"Revision\"],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "US2sPygL62WC",
    "outputId": "8cd00bc4-66a4-4b6e-9a4d-6a8f9a351770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "len(y_train)\n",
    "\n",
    "#get a boolean np.array as index\n",
    "idx = x_train['Revision'] == 1\n",
    "\n",
    "idx = idx.values\n",
    "\n",
    "y_train_aux = y_train.values\n",
    "\n",
    "y_train_1 = y_train_aux[idx]\n",
    "\n",
    "print(y_train_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdCoKBuhLYCr"
   },
   "source": [
    "### Con X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "T9VbcNWBK8BR",
    "outputId": "da195b57-a58c-4090-8c28-4b06a3bc082c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Edad del Paciente</th>\n",
       "      <th>Sexo del Paciente</th>\n",
       "      <th>LEU</th>\n",
       "      <th>NEU</th>\n",
       "      <th>NEUp</th>\n",
       "      <th>LIN</th>\n",
       "      <th>LINp</th>\n",
       "      <th>MON</th>\n",
       "      <th>MONp</th>\n",
       "      <th>EOS</th>\n",
       "      <th>...</th>\n",
       "      <th>WBC-N</th>\n",
       "      <th>ASLYP</th>\n",
       "      <th>ASLYA</th>\n",
       "      <th>RELPL</th>\n",
       "      <th>RELYP</th>\n",
       "      <th>RELYA</th>\n",
       "      <th>NEUGI</th>\n",
       "      <th>NEURI</th>\n",
       "      <th>ASLPL</th>\n",
       "      <th>Revision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.060</td>\n",
       "      <td>5.98</td>\n",
       "      <td>74.30</td>\n",
       "      <td>1.210</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.690</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0.140</td>\n",
       "      <td>...</td>\n",
       "      <td>8.060</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.080</td>\n",
       "      <td>159.30</td>\n",
       "      <td>49.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.862</td>\n",
       "      <td>7.67</td>\n",
       "      <td>73.30</td>\n",
       "      <td>1.434</td>\n",
       "      <td>18.52</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.036</td>\n",
       "      <td>...</td>\n",
       "      <td>9.862</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.008</td>\n",
       "      <td>11.44</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.148</td>\n",
       "      <td>147.94</td>\n",
       "      <td>52.50</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.184</td>\n",
       "      <td>17.12</td>\n",
       "      <td>65.20</td>\n",
       "      <td>2.550</td>\n",
       "      <td>9.70</td>\n",
       "      <td>0.608</td>\n",
       "      <td>18.20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>7.184</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.100</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.240</td>\n",
       "      <td>136.80</td>\n",
       "      <td>50.98</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.850</td>\n",
       "      <td>4.67</td>\n",
       "      <td>68.10</td>\n",
       "      <td>1.520</td>\n",
       "      <td>22.20</td>\n",
       "      <td>0.500</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.080</td>\n",
       "      <td>...</td>\n",
       "      <td>6.850</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.80</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.210</td>\n",
       "      <td>141.40</td>\n",
       "      <td>47.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.170</td>\n",
       "      <td>4.33</td>\n",
       "      <td>65.44</td>\n",
       "      <td>1.370</td>\n",
       "      <td>27.16</td>\n",
       "      <td>0.396</td>\n",
       "      <td>6.08</td>\n",
       "      <td>0.008</td>\n",
       "      <td>...</td>\n",
       "      <td>6.170</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11.84</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.146</td>\n",
       "      <td>152.26</td>\n",
       "      <td>51.58</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Edad del Paciente  Sexo del Paciente    LEU    NEU   NEUp    LIN   LINp  \\\n",
       "2                76.0                0.0  8.060   5.98  74.30  1.210  15.00   \n",
       "3                72.0                1.0  9.862   7.67  73.30  1.434  18.52   \n",
       "6                69.0                0.0  7.184  17.12  65.20  2.550   9.70   \n",
       "7                72.0                1.0  6.850   4.67  68.10  1.520  22.20   \n",
       "15               83.0                1.0  6.170   4.33  65.44  1.370  27.16   \n",
       "\n",
       "      MON   MONp    EOS  ...  WBC-N  ASLYP  ASLYA  RELPL  RELYP  RELYA  \\\n",
       "2   0.690   8.60  0.140  ...  8.060   0.00  0.000   6.60   1.00  0.080   \n",
       "3   0.538   6.18  0.036  ...  9.862   0.08  0.008  11.44   1.84  0.148   \n",
       "6   0.608  18.20  0.010  ...  7.184   0.40  0.100   9.40   0.90  0.240   \n",
       "7   0.500   7.30  0.080  ...  6.850   0.00  0.000  13.80   3.10  0.210   \n",
       "15  0.396   6.08  0.008  ...  6.170   0.22  0.006  11.84   1.96  0.146   \n",
       "\n",
       "     NEUGI  NEURI  ASLPL  Revision  \n",
       "2   159.30  49.60   0.00       1.0  \n",
       "3   147.94  52.50   0.88       1.0  \n",
       "6   136.80  50.98   3.90       1.0  \n",
       "7   141.40  47.90   0.00       1.0  \n",
       "15  152.26  51.58   1.18       1.0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_1 = x_test[x_test['Revision'] == 1]\n",
    "\n",
    "x_test_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TxsOfYy4LP3Y"
   },
   "outputs": [],
   "source": [
    "#Elimino la variable 'Revision' puesto que una vez he cogido los pacientes con revision=1, la variable ya \n",
    "#no me hace falta.\n",
    "x_test_1 = x_test_1.drop([\"Revision\"],axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ycp3vVjBLG4r",
    "outputId": "a7d13ae4-a15f-4dde-efbb-8765e04cc0a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "len(y_test)\n",
    "\n",
    "#get a boolean np.array as index\n",
    "idx = x_test['Revision'] == 1\n",
    "\n",
    "idx = idx.values\n",
    "\n",
    "y_test_aux = y_test.values\n",
    "\n",
    "y_test_1 = y_test_aux[idx]\n",
    "\n",
    "print(y_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iA8M8HS-O_s"
   },
   "source": [
    "# 1.XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Q2_52kUXC7tS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes, load_wine\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0BmHhZ0Li2s"
   },
   "source": [
    "## 1.1 Optimización de los hiperparámetros usando RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "BHAN5Yve-9Ch"
   },
   "outputs": [],
   "source": [
    "#Indico que el clasificador que voy a utlizar es XGBosst\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCpdvaAR-Nqa"
   },
   "source": [
    "Inicialmente creamos un diccionario de algunos parámetros a entrenar. Aquí las claves son básicamente los parámetros y los valores a entrenar. Así que el RandomizedSearchCV probará cada valor y encontrará el valor particular que da la mayor precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Klmci5LdABp_"
   },
   "outputs": [],
   "source": [
    "#Cuanto mayor sea gamma, más conservador será el algoritmo\n",
    "#min_child_weight: para controlar el sobreajuste, cuanto mayor sea min_child_weight, más conservador será el algoritmo\n",
    "\n",
    "params = {\n",
    " 'n_estimators' : [25,50,75,100,125,150,175,200,250,300,350,400],\n",
    " 'learning_rate' : [0.05,0.10,0.15,0.20,0.25,0.30],\n",
    " 'max_depth' : [3,4,5,6,8,10,12,15],\n",
    " 'gamma': [0.0,0.1,0.2,0.3,0.4],\n",
    " 'colsample_bytree' : [0.3,0.4,0.5,0.7]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_8hIRiEAqFu"
   },
   "source": [
    "A continuación, llamamos a RandomizedSearchCV() y le pasamos los siguientes parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3SHHuaOcAvQA",
    "outputId": "b7723b59-e244-4dae-98fb-cec08fec6f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:49:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           enable_categorical=False, gamma=None,\n",
       "                                           gpu_id=None, importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints...\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        'max_depth': [3, 4, 5, 6, 8, 10, 12,\n",
       "                                                      15],\n",
       "                                        'n_estimators': [25, 50, 75, 100, 125,\n",
       "                                                         150, 175, 200, 250,\n",
       "                                                         300, 350, 400]},\n",
       "                   random_state=2, scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verbose = genera mensajes durante el entramiento del modelo 'Fitting 5 folds...'\n",
    "\n",
    "#roc_auc = curva AUC-ROC es la métrica de selección del modelo para el problema de clasificación \n",
    "#de dos clases múltiples.ROC nos dice qué tan bueno es el modelo para distinguir las clases dadas, \n",
    "#en términos de la probabilidad predicha.\n",
    "\n",
    "#n_jobs = número de nucleos que se utilizan (-1 quiere decir que se utilizan todos)\n",
    "\n",
    "r_s_model = RandomizedSearchCV(xgb_model , param_distributions=params, n_iter=5, \n",
    "                               scoring='roc_auc',n_jobs=-1,cv=5,verbose=3,random_state = 2)\n",
    "r_s_model.fit(x_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwHr_OxHCJBY"
   },
   "source": [
    "Bien, nuestro modelo ha sido ajustado. Veamos ahora todos los parámetros que han sido seleccionados por el RandomizedSearch() para el XGBClassifier. Podemos hacerlo con la ayuda del método best_estimators_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rXz112xuCL9x",
    "outputId": "5589d989-9f1b-4bcb-db85-f07cd59dd827"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3,\n",
       "              enable_categorical=False, gamma=0.1, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.3, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_s_model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSJUkKA6HaQT"
   },
   "source": [
    "Una vez conozco los valores de hiperparámetros, vuelvo a buscar la optimización de los mismos, pero esta vez afinando más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "NyURH0MLHYip"
   },
   "outputs": [],
   "source": [
    "#Cuanto mayor sea gamma, más conservador será el algoritmo\n",
    "#min_child_weight: para controlar el sobreajuste, cuanto mayor sea min_child_weight, más conservador será el algoritmo\n",
    "\n",
    "params = {\n",
    " 'n_estimators' : [192,194,196,198,200,202,204,206,208],\n",
    " 'learning_rate' : [0.11,0.12,0.13,0.14,0.15,0.16,0.17,0.18,0.19],\n",
    " 'max_depth' : [8,9,10,11,12,13,14,15,16],\n",
    " 'gamma': [0.30,0.33,0.36,0.39,0.42,0.45,0.48],\n",
    " 'colsample_bytree' : [0.15,0.20,0.25,0.30,0.35,0.40,0.45]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tgq4jyIe6TTV",
    "outputId": "a2d655ce-ad2e-4910-dece-4ecb0c5bcfe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Edad del Paciente', 'Sexo del Paciente', 'LEU', 'NEU', 'NEUp', 'LIN',\n",
      "       'LINp', 'MON', 'MONp', 'EOS', 'EOSp', 'BAS', 'BASp', 'IG', 'IGp',\n",
      "       'ERIT', 'HGB', 'HCT', 'VCM', 'HCM', 'CHCM', 'RDW', 'ERBL', 'ERBLp',\n",
      "       'PLT', 'PLTI', 'VPM', 'rNe/L', 'rPL/L', 'MacR', 'MicR', 'BA-D#',\n",
      "       'NEFSC', 'BA-D%', 'BA-N#', 'BA-N%', 'HFLCA', 'HFLCP', 'LY-WX', 'LY-WY',\n",
      "       'LY-WZ', 'LY-X', 'LY-Y', 'LY-Z', 'MO-WX', 'MO-WY', 'MO-WZ', 'MO-X',\n",
      "       'MO-Y', 'MO-Z', 'NESFL', 'NESSC', 'NE-WX', 'NE-WY', 'NE-WZ', 'TNC-N',\n",
      "       'WBC-D', 'WBC-N', 'ASLYP', 'ASLYA', 'RELPL', 'RELYP', 'RELYA', 'NEUGI',\n",
      "       'NEURI', 'ASLPL'],\n",
      "      dtype='object')\n",
      "[0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_1.columns)\n",
    "print(y_train_1)\n",
    "#print(x_test_1['Revision'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6o2OeCTvIkWi",
    "outputId": "66561e7e-cbf5-44e0-faa7-13f48536ab3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:50:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           enable_categorical=False, gamma=None,\n",
       "                                           gpu_id=None, importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints...\n",
       "                                           verbosity=None),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.15, 0.2, 0.25,\n",
       "                                                             0.3, 0.35, 0.4,\n",
       "                                                             0.45],\n",
       "                                        'gamma': [0.3, 0.33, 0.36, 0.39, 0.42,\n",
       "                                                  0.45, 0.48],\n",
       "                                        'learning_rate': [0.11, 0.12, 0.13,\n",
       "                                                          0.14, 0.15, 0.16,\n",
       "                                                          0.17, 0.18, 0.19],\n",
       "                                        'max_depth': [8, 9, 10, 11, 12, 13, 14,\n",
       "                                                      15, 16],\n",
       "                                        'n_estimators': [192, 194, 196, 198,\n",
       "                                                         200, 202, 204, 206,\n",
       "                                                         208]},\n",
       "                   random_state=2, scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verbose = genera mensajes durante el entramiento del modelo 'Fitting 5 folds...'\n",
    "\n",
    "#roc_auc = curva AUC-ROC es la métrica de selección del modelo para el problema de clasificación \n",
    "#de dos clases múltiples.ROC nos dice qué tan bueno es el modelo para distinguir las clases dadas, \n",
    "#en términos de la probabilidad predicha.\n",
    "\n",
    "#n_jobs = número de nucleos que se utilizan (-1 quiere decir que se utilizan todos)\n",
    "\n",
    "r_s_model = RandomizedSearchCV(xgb_model , param_distributions=params, n_iter=5, \n",
    "                               scoring='roc_auc',n_jobs=-1,cv=5,verbose=3,random_state = 2)\n",
    "r_s_model.fit(x_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J8GzmVZNIm0X",
    "outputId": "08214ff3-37f4-4c9f-bf9f-e854e8dfa38a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.45,\n",
       "              enable_categorical=False, gamma=0.48, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.15, max_delta_step=0, max_depth=11,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=192, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_s_model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJT9dRNqfiKU"
   },
   "source": [
    "## 1.2 Rendimiento con todas las features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xG-bVWyjCZcx"
   },
   "source": [
    "Ahora, como conocemos todos los mejores parámetros, podemos simplemente construir nuestro modelo clasificador final pasando todos esos parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "MF6gOB1RChQp"
   },
   "outputs": [],
   "source": [
    "#Construyendo el modelo final\n",
    "xgb_model = xgb.XGBClassifier(colsample_bytree=0.45, gamma=0.3, learning_rate=0.15,\n",
    "              max_depth=16, n_estimators=202)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "kguJP0rx6TTa"
   },
   "outputs": [],
   "source": [
    "#print(x_test['Fecha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "0NSP3PtSNEB3"
   },
   "outputs": [],
   "source": [
    "x_test_WR = x_test.drop([\"Revision\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "NWmveSOUG3Wi",
    "outputId": "a92d0fdf-441c-48be-a7c2-3e63e65ce16f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:50:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prestaciones en test</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sensibility</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUC ROC</td>\n",
       "      <td>0.535256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prestaciones en test   XGBoost\n",
       "0             Accuracy  0.765625\n",
       "1          Sensibility  0.166667\n",
       "2          Specificity  0.903846\n",
       "3              AUC ROC  0.535256"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Métricas\n",
    "\n",
    "xgb_model.fit(x_train_1, y_train_1)\n",
    "\n",
    "y_pred = xgb_model.predict(x_test_WR)\n",
    "\n",
    "acc_xgb = accuracy_score(y_test, y_pred)\n",
    "sensibilidad_xgb = recall_score(y_test, y_pred)\n",
    "#precision_xgb = precision_score(y_test, y_pred)\n",
    "specificity_xgb = confusion_matrix(y_test, y_pred)[0][0]/(confusion_matrix(y_test, y_pred)[0][0]+confusion_matrix(y_test, y_pred)[0][1])\n",
    "auc_xgb = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "Tabla = pd.DataFrame({ \"Prestaciones en test\":[\"Accuracy\",\"Sensibility\",'Specificity',\"AUC ROC\"],\n",
    "                      \"XGBoost\" : [acc_xgb, sensibilidad_xgb, specificity_xgb, auc_xgb]})\n",
    "\n",
    "Tabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_w29Eajzaja"
   },
   "source": [
    "## 1.3 Selección de características (FS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PL0SquGRzibQ"
   },
   "source": [
    "La selección de características se entiende como una disminución del número de éstas, en función de un criterio elegido por el usuario, escogiendo aquellas que se consideran más informativas y eliminando aquellas que son irrelevantes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mp9Vyp9DzlTb"
   },
   "source": [
    "**Importancia de cada característica**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4qQSKeWzmFn"
   },
   "source": [
    "La importancia de características desempeña un papel importante, ya que proporciona una visión de los datos, del modelo y la base para la reducción de la dimensionalidad y la selección de características que pueden mejorar la eficiencia y la eficacia de un modelo predictivo en el problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Xy8wLPtQZYw"
   },
   "source": [
    "Para tener mas aleatoridad a la hora de valorar la importancia de las características sobre las que trabajo, voy a hacer:\n",
    "\n",
    "\n",
    "1.   Coger del dataframe x_test (62 muestras) 40 muestras con reemplazo y repestando la proporción de sanos y no sanos.\n",
    "2.   Con ese conjunto hago \"permutation importance\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7Aa4K-kq9kJ"
   },
   "source": [
    "# Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1P7QszfOt-Q",
    "outputId": "5af599fb-04cf-4b8d-fdec-c4260282e188"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 66)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "ls08H1bRrOn9",
    "outputId": "a10f3f71-a89f-4ec2-95dd-089cad95dd42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Edad del Paciente</th>\n",
       "      <th>Sexo del Paciente</th>\n",
       "      <th>LEU</th>\n",
       "      <th>NEU</th>\n",
       "      <th>NEUp</th>\n",
       "      <th>LIN</th>\n",
       "      <th>LINp</th>\n",
       "      <th>MON</th>\n",
       "      <th>MONp</th>\n",
       "      <th>EOS</th>\n",
       "      <th>...</th>\n",
       "      <th>WBC-D</th>\n",
       "      <th>WBC-N</th>\n",
       "      <th>ASLYP</th>\n",
       "      <th>ASLYA</th>\n",
       "      <th>RELPL</th>\n",
       "      <th>RELYP</th>\n",
       "      <th>RELYA</th>\n",
       "      <th>NEUGI</th>\n",
       "      <th>NEURI</th>\n",
       "      <th>ASLPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.060</td>\n",
       "      <td>5.98</td>\n",
       "      <td>74.30</td>\n",
       "      <td>1.210</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.690</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0.140</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.060</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.080</td>\n",
       "      <td>159.30</td>\n",
       "      <td>49.60</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.862</td>\n",
       "      <td>7.67</td>\n",
       "      <td>73.30</td>\n",
       "      <td>1.434</td>\n",
       "      <td>18.52</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.036</td>\n",
       "      <td>...</td>\n",
       "      <td>9.840</td>\n",
       "      <td>9.862</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.008</td>\n",
       "      <td>11.44</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.148</td>\n",
       "      <td>147.94</td>\n",
       "      <td>52.50</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.184</td>\n",
       "      <td>17.12</td>\n",
       "      <td>65.20</td>\n",
       "      <td>2.550</td>\n",
       "      <td>9.70</td>\n",
       "      <td>0.608</td>\n",
       "      <td>18.20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>7.164</td>\n",
       "      <td>7.184</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.100</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.240</td>\n",
       "      <td>136.80</td>\n",
       "      <td>50.98</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.850</td>\n",
       "      <td>4.67</td>\n",
       "      <td>68.10</td>\n",
       "      <td>1.520</td>\n",
       "      <td>22.20</td>\n",
       "      <td>0.500</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.080</td>\n",
       "      <td>...</td>\n",
       "      <td>6.860</td>\n",
       "      <td>6.850</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.80</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.210</td>\n",
       "      <td>141.40</td>\n",
       "      <td>47.90</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.170</td>\n",
       "      <td>4.33</td>\n",
       "      <td>65.44</td>\n",
       "      <td>1.370</td>\n",
       "      <td>27.16</td>\n",
       "      <td>0.396</td>\n",
       "      <td>6.08</td>\n",
       "      <td>0.008</td>\n",
       "      <td>...</td>\n",
       "      <td>6.094</td>\n",
       "      <td>6.170</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11.84</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.146</td>\n",
       "      <td>152.26</td>\n",
       "      <td>51.58</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Edad del Paciente  Sexo del Paciente    LEU    NEU   NEUp    LIN   LINp  \\\n",
       "2                76.0                0.0  8.060   5.98  74.30  1.210  15.00   \n",
       "3                72.0                1.0  9.862   7.67  73.30  1.434  18.52   \n",
       "6                69.0                0.0  7.184  17.12  65.20  2.550   9.70   \n",
       "7                72.0                1.0  6.850   4.67  68.10  1.520  22.20   \n",
       "15               83.0                1.0  6.170   4.33  65.44  1.370  27.16   \n",
       "\n",
       "      MON   MONp    EOS  ...  WBC-D  WBC-N  ASLYP  ASLYA  RELPL  RELYP  RELYA  \\\n",
       "2   0.690   8.60  0.140  ...  8.000  8.060   0.00  0.000   6.60   1.00  0.080   \n",
       "3   0.538   6.18  0.036  ...  9.840  9.862   0.08  0.008  11.44   1.84  0.148   \n",
       "6   0.608  18.20  0.010  ...  7.164  7.184   0.40  0.100   9.40   0.90  0.240   \n",
       "7   0.500   7.30  0.080  ...  6.860  6.850   0.00  0.000  13.80   3.10  0.210   \n",
       "15  0.396   6.08  0.008  ...  6.094  6.170   0.22  0.006  11.84   1.96  0.146   \n",
       "\n",
       "     NEUGI  NEURI  ASLPL  \n",
       "2   159.30  49.60   0.00  \n",
       "3   147.94  52.50   0.88  \n",
       "6   136.80  50.98   3.90  \n",
       "7   141.40  47.90   0.00  \n",
       "15  152.26  51.58   1.18  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EkPqRC33NFTr"
   },
   "outputs": [],
   "source": [
    "#XGB = x_test.sample(n=40, replace=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8ndp6UvLdGO"
   },
   "outputs": [],
   "source": [
    "#x_test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSuWHayWDRG-"
   },
   "outputs": [],
   "source": [
    "#sss = StratifiedShuffleSplit(n_splits=1, test_size=0.625, random_state=1) #40 de 64 es el 0.625%\n",
    "#sss.split(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1f79zoLkQ9BZ"
   },
   "outputs": [],
   "source": [
    "#Oscar: we are going to call validation the new subset from X and y test\n",
    "\n",
    "#for train_index, test_index in sss.split(x_test, y_test):\n",
    "#    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#    __, X_val = x_test.loc[train_index], x_test.loc[test_index]\n",
    "#    __, y_val = y_test[train_index], y_test[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTEEPlxV6TTh"
   },
   "outputs": [],
   "source": [
    "#X_val['Revision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "chre5MHa6TTi",
    "outputId": "0389d258-edeb-4d78-8c22-432e0522f7e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.45,\n",
       "              enable_categorical=False, gamma=0.3, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.15, max_delta_step=0, max_depth=16,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=202, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Oscar train the best model with all the training features \n",
    "\n",
    "xgb_model = xgb.XGBClassifier(colsample_bytree=0.45, gamma=0.3, learning_rate=0.15,\n",
    "              max_depth=16, n_estimators=202)\n",
    "\n",
    "xgb_model.fit(x_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "xLmEMqllqMEm"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "8ODkUYeAomcV"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S18G4_7jlkjU",
    "outputId": "24dae6ff-1d10-4002-c159-0c62c5d6ffbb"
   },
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdSEd8Ec6TTj",
    "outputId": "db0809a0-57cf-45c5-d92c-1f2085f91f5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PermutationImportance(estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                              colsample_bylevel=1,\n",
       "                                              colsample_bynode=1,\n",
       "                                              colsample_bytree=0.45,\n",
       "                                              enable_categorical=False,\n",
       "                                              gamma=0.3, gpu_id=-1,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints='',\n",
       "                                              learning_rate=0.15,\n",
       "                                              max_delta_step=0, max_depth=16,\n",
       "                                              min_child_weight=1, missing=nan,\n",
       "                                              monotone_constraints='()',\n",
       "                                              n_estimators=202, n_jobs=8,\n",
       "                                              num_parallel_tree=1,\n",
       "                                              predictor='auto', random_state=0,\n",
       "                                              reg_alpha=0, reg_lambda=1,\n",
       "                                              scale_pos_weight=1, subsample=1,\n",
       "                                              tree_method='exact',\n",
       "                                              validate_parameters=1,\n",
       "                                              verbosity=None),\n",
       "                      n_iter=100)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## perform permutation importance analysis on( Validation set\n",
    "\n",
    "perm = PermutationImportance(xgb_model,n_iter = 100)\n",
    "\n",
    "perm.fit(x_test_1,y_test_1)\n",
    "\n",
    "#perm.fit(X_val.values,y_val.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KK6xAaM06TTj",
    "outputId": "2d7847a8-b12b-4162-e3cd-2ec43f46b094"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0127\n",
       "                \n",
       "                    &plusmn; 0.0408\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                MicR\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 81.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0114\n",
       "                \n",
       "                    &plusmn; 0.0394\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                LIN\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.60%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0050\n",
       "                \n",
       "                    &plusmn; 0.0284\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                VCM\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.96%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0041\n",
       "                \n",
       "                    &plusmn; 0.0260\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                LY-Y\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                MacR\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                rPL/L\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                rNe/L\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                VPM\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                PLTI\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                PLT\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                MON\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                RDW\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                CHCM\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                HCM\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                BA-D#\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Sexo del Paciente\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                HGB\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                MONp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ERBL\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ERBLp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 46 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##show weights\n",
    "\n",
    "eli5.show_weights(perm,feature_names = x_test_1.columns.to_list() )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "1SwWZtpGTgya",
    "outputId": "17bb25c7-7a94-479a-be2d-ce93dda5f07a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MicR     0.015455\n",
       "LIN      0.013636\n",
       "VCM      0.007273\n",
       "LY-Y     0.004545\n",
       "MO-WX    0.000909\n",
       "           ...   \n",
       "MacR     0.000000\n",
       "BA-D#    0.000000\n",
       "ASLPL    0.000000\n",
       "LINp    -0.010000\n",
       "MO-Y    -0.046364\n",
       "Length: 66, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = x_test_1.columns.to_list()\n",
    "\n",
    "feature_importance = perm.feature_importances_\n",
    "\n",
    "pd.Series(feature_importance, columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "59LRT5CVmRf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\ndef permutation (x_train, y_train, x_test, y_test):\\n  encoder = ce.OneHotEncoder(use_cat_names=True)\\n\\n  x_train_s = encoder.fit_transform(x_train)\\n  x_test_s = encoder.transform(x_test)\\n\\n  #Fitting the model.\\n  model = xgb.XGBClassifier(random_state=42)\\n  model.fit(x_train_s, y_train)\\n\\n  permuter = PermutationImportance(\\n      estimator = model,\\n      scoring = 'r2',\\n      n_iter = 5,\\n      random_state = 42)\\n  \\n  permuter.fit(x_test_s, y_test)\\n\\n  columns = x_test_s.columns.to_list()\\n\\n  feature_importance = permuter.feature_importances_\\n\\n  pd.Series(feature_importance, columns).sort_values(ascending=False)\\n\\n  metric = eli5.show_weights(\\n      estimator = permuter,\\n      top = None,\\n      feature_names = columns)\\n  \\n  return metric\\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "def permutation (x_train, y_train, x_test, y_test):\n",
    "  encoder = ce.OneHotEncoder(use_cat_names=True)\n",
    "\n",
    "  x_train_s = encoder.fit_transform(x_train)\n",
    "  x_test_s = encoder.transform(x_test)\n",
    "\n",
    "  #Fitting the model.\n",
    "  model = xgb.XGBClassifier(random_state=42)\n",
    "  model.fit(x_train_s, y_train)\n",
    "\n",
    "  permuter = PermutationImportance(\n",
    "      estimator = model,\n",
    "      scoring = 'r2',\n",
    "      n_iter = 5,\n",
    "      random_state = 42)\n",
    "  \n",
    "  permuter.fit(x_test_s, y_test)\n",
    "\n",
    "  columns = x_test_s.columns.to_list()\n",
    "\n",
    "  feature_importance = permuter.feature_importances_\n",
    "\n",
    "  pd.Series(feature_importance, columns).sort_values(ascending=False)\n",
    "\n",
    "  metric = eli5.show_weights(\n",
    "      estimator = permuter,\n",
    "      top = None,\n",
    "      feature_names = columns)\n",
    "  \n",
    "  return metric\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "XZOnQgS8oZzD"
   },
   "outputs": [],
   "source": [
    "#permutation(x_train1, y_train1, X_test, Y_test) #si pongo x_train, y_train, x_test e y_test funciona ¿?¿?¿?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "j2lDeTU6zZ47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "#Plot feature importance\n",
    "def plot_feature_importance(importance,names,model_type):\n",
    "\n",
    "  #Create arrays from feature importance and feature names\n",
    "  feature_importance = np.array(importance)\n",
    "  feature_names = np.array(names)\n",
    "\n",
    "  #Create a DataFrame using a Dictionary\n",
    "  data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "  fi_df = pd.DataFrame(data)\n",
    "\n",
    "  #Sort the DataFrame in order decreasing feature importance\n",
    "  fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "  #Define size of bar plot\n",
    "  fig = plt.figure(figsize=(20,6))\n",
    "  #Plot Searborn bar chart\n",
    "  sns.barplot(y=fi_df['feature_importance'], x=fi_df['feature_names'])\n",
    "  #Add chart labels\n",
    "  plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "  plt.xlabel('FEATURE IMPORTANCE')\n",
    "  plt.ylabel('FEATURE NAMES')\n",
    "  plt.tight_layout()\n",
    "  fig.autofmt_xdate(rotation=45)\n",
    "\n",
    "\n",
    "plot_feature_importance(xgb_model.feature_importances_*100,x_train_1.columns,'XGBoost ')\n",
    "\n",
    "print(np.sum(xgb_model.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRc6k4ErgEKI"
   },
   "source": [
    "A partir de este gráfico se puede observar la importancia de cada característica haciendo uso de XGBoost. Así pues, VCM es la variable que aporta mayor información al realizar la tarea de clasificación, con lo que permitirá, en mayor medida, diferenciar un paciente sano de uno no sano. No obstante, las 3  variables siguientes MO-Y, MacR y IG también presentan información relevante para la predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lw5m7_pB2id9"
   },
   "source": [
    "**Selección de las características en base a la importancia de éstas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "0iM8ZAFW0kJV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=6, n_estimators=125;, score=0.806 total time=   6.6s\n",
      "[21:48:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.15, max_depth=12, n_estimators=200;, score=0.806 total time=   9.8s\n",
      "[21:48:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.3, max_depth=6, n_estimators=200;, score=1.000 total time=   8.8s\n",
      "[21:49:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=6, n_estimators=125;, score=0.972 total time=   8.4s\n",
      "[21:49:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=50;, score=0.962 total time=   3.6s\n",
      "[21:49:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.15, max_depth=4, n_estimators=175;, score=0.923 total time=  11.0s\n",
      "[21:49:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.3, max_depth=6, n_estimators=200;, score=0.861 total time=   4.9s\n",
      "[21:49:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END colsample_bytree=0.45, gamma=0.48, learning_rate=0.15, max_depth=11, n_estimators=192;, score=0.962 total time=  11.4s\n",
      "[21:49:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5] END colsample_bytree=0.45, gamma=0.48, learning_rate=0.15, max_depth=11, n_estimators=192;, score=0.917 total time=  12.9s\n",
      "[21:49:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END colsample_bytree=0.4, gamma=0.48, learning_rate=0.15, max_depth=15, n_estimators=200;, score=1.000 total time=  11.1s\n",
      "[21:50:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5] END colsample_bytree=0.45, gamma=0.3, learning_rate=0.15, max_depth=16, n_estimators=202;, score=0.972 total time=   5.6s\n",
      "[21:53:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:53:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:55:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:55:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:55:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5481/913984432.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mselection_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolsample_bytree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#cv estimation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_x_train_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mscores_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    446\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    248\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    249\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 250\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    251\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    252\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#SelectFromModel\n",
    "\n",
    "scores_cv = []\n",
    "thresholds = np.sort(xgb_model.feature_importances_) # obtiene la importancia de cada característica\n",
    "i = 0\n",
    "for thresh in thresholds:\n",
    "    print(\"{} de {}\".format(i,len(thresholds)))\n",
    "    selection = SelectFromModel(xgb_model, threshold=thresh, prefit=True)\n",
    "    select_x_train_1 = selection.transform(x_train_1)\n",
    "    # train model\n",
    "    selection_model = xgb.XGBClassifier(colsample_bytree=0.7, gamma=0.3, learning_rate=0.3, max_depth=8)\n",
    "    #cv estimation\n",
    "    sc =cross_val_score(selection_model, select_x_train_1, y_train_1, cv=10, scoring='roc_auc',n_jobs=-1)\n",
    "    scores_cv.append(sc)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZpG_Bv92uN-"
   },
   "outputs": [],
   "source": [
    "plt.rc('xtick',labelsize=15)\n",
    "plt.rc('ytick',labelsize=15)\n",
    "plt.figure(figsize = (80,20))\n",
    "sc_cv = np.asarray(scores_cv)\n",
    "scores_m = np.mean(sc_cv,axis = 1)\n",
    "scores_std = np.std(sc_cv,axis = 1)\n",
    "xx = np.arange(len(scores_m))\n",
    "plt.plot(xx,scores_m,'o-')\n",
    "plt.grid()\n",
    "_ = plt.xticks(xx,labels= np.arange(1,len(scores_m)+1))\n",
    "plt.xlabel('Number of features removed')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPWHtcuDgz84"
   },
   "source": [
    "Esta gráfica muestra el ***accuracy*** que se alcanza cuando se escogen X características. Desde la izquierda hacia la derecha se van quitando variables consecutivamente, y se puede observar que la predicción del modelo no se degrada hasta llegar a 67 variables. Es decir, solo quedándonos con 4  variables, el modelo es capaz de tener el mismo desempeño en predicción que utilizando todas las variables. Estas característica son las 4 primeras representadas anteriormente en la gráfica anterior.\n",
    "\n",
    "Además siempre es preferible tener un modelo menos complejo para que de esta forma pueda haber una mejor generalizacion con la incorporación de datos nuevos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2Ic4559fxkF"
   },
   "source": [
    "## 1.4 Rendimiento con FS en el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbNtndTNWPbj"
   },
   "outputs": [],
   "source": [
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)\n",
    "\n",
    "#convert into a dataframe with sorted feature importances\n",
    "fi = rf_feat_importance(xgb_model,x_train_1)\n",
    "\n",
    "#select the features\n",
    "selected_features_RF = fi[:len(fi)-63]['cols'].to_list()\n",
    "print(\"Numero de variables seleccionadas Pars:\",len(selected_features_RF))\n",
    "print(\"Selected features:\",selected_features_RF)\n",
    "\n",
    "\n",
    "X_train_FT_xgb = x_train_1[selected_features_RF]\n",
    "X_test_FT_xgb = x_test[selected_features_RF]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1OHoycnkr11"
   },
   "outputs": [],
   "source": [
    "xgb_FS = xgb.XGBClassifier(colsample_bytree=0.45, gamma=0.3, learning_rate=0.15,\n",
    "              max_depth=16, n_estimators=202)\n",
    "xgb_FS.fit(X_train_FT_xgb, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIYve4K_eYNf"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#Todas las características\n",
    "y_pred_tot = xgb_model.predict(x_test)\n",
    "acc_tot = accuracy_score(y_test, y_pred_tot)\n",
    "sensibilidad_tot = recall_score(y_test, y_pred_tot)\n",
    "#precision_tot=precision_score(y_test, y_pred_tot)\n",
    "specificity_tot = confusion_matrix(y_test, y_pred_tot)[0][0]/(confusion_matrix(y_test, y_pred_tot)[0][0]+confusion_matrix(y_test, y_pred_tot)[0][1])\n",
    "auc_tot = roc_auc_score(y_test, y_pred_tot)\n",
    "\n",
    "\n",
    "#8 características \n",
    "y_pred_8 = xgb_FS.predict(X_test_FT_xgb)\n",
    "acc_8 = accuracy_score(y_test, y_pred_8)\n",
    "sensibilidad_8 = recall_score(y_test, y_pred_8)\n",
    "#precision_8 = precision_score(y_test, y_pred_8)\n",
    "specificity_8 = confusion_matrix(y_test, y_pred_8)[0][0]/(confusion_matrix(y_test, y_pred_8)[0][0]+confusion_matrix(y_test, y_pred_8)[0][1])\n",
    "auc_8 = roc_auc_score(y_test, y_pred_8)\n",
    "\n",
    "Tabla_xgb = pd.DataFrame({\"Prestaciones en test\":[\"Accuracy\",\"Sensibility\",'Specificity',\"AUC ROC\"],\n",
    "                          \"XGBoost total\" : [acc_tot, sensibilidad_tot, specificity_tot, auc_tot], \n",
    "                      \"XGBoost 8 features \" : [acc_8, sensibilidad_8, specificity_8, auc_8]})\n",
    "Tabla_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4yngAoGR3pp"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "#XGBoost all features\n",
    "plot_confusion_matrix(xgb_model, x_test, y_test,display_labels=[\"Sano\",\"No sano\"],\n",
    "                                 cmap=plt.cm.Blues)\n",
    "plt.title(\"XGBoost all features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXjpBigeVV1p"
   },
   "outputs": [],
   "source": [
    "#XGBoost 8 features\n",
    "plot_confusion_matrix(xgb_FS, X_test_FT_xgb, y_test,display_labels=[\"Sano\",\"No sano\"],\n",
    "                                 cmap=plt.cm.Blues)\n",
    "plt.title(\"XGBoost 8 features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8MaaLxwrHnY"
   },
   "source": [
    "# 2.Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YK45kpe0BT4W"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQxjCymApESi"
   },
   "source": [
    "## 2.1 Optimización de los hiperparámetros usando RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70RPb-H7MWNt"
   },
   "outputs": [],
   "source": [
    "#Indico que el clasificador que voy a utlizar es GBoosting\n",
    "\n",
    "gb_model = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMXjUhN5Mgdo"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    " 'n_estimators' : [150,200,250,300,350,400,450,500],\n",
    " 'learning_rate' : [0.05,0.10,0.15,0.20,0.25,0.30],\n",
    " 'max_depth' : [20,25,30,35,40,45],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ap81OEvyMjTC"
   },
   "outputs": [],
   "source": [
    "#verbose = genera mensajes durante el entramiento del modelo 'Fitting 5 folds...'\n",
    "\n",
    "#roc_auc = curva AUC-ROC es la métrica de selección del modelo para el problema de clasificación \n",
    "#de dos clases múltiples.ROC nos dice qué tan bueno es el modelo para distinguir las clases dadas, \n",
    "#en términos de la probabilidad predicha.\n",
    "\n",
    "#n_jobs = número de nucleos que se utilizan (-1 quiere decir que se utilizan todos)\n",
    "\n",
    "r_s_model_2 = RandomizedSearchCV(gb_model , param_distributions=params, n_iter=5, \n",
    "                               scoring='roc_auc',n_jobs=-1,cv=5,verbose=3,random_state = 2)\n",
    "\n",
    "r_s_model_2.fit(x_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ohuKN0wMqqM"
   },
   "outputs": [],
   "source": [
    "r_s_model_2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NaX_GvsYItTG"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    " 'n_estimators' : [335,340,345,350,355,360,365],\n",
    " 'learning_rate' : [0.14,0.16,0.18,0.20,0.22,0.24,0.26],\n",
    " 'max_depth' : [26,27,28,29,30,31,32,33,34],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtKeKdCDJPjW"
   },
   "outputs": [],
   "source": [
    "#verbose = genera mensajes durante el entramiento del modelo 'Fitting 5 folds...'\n",
    "\n",
    "#roc_auc = curva AUC-ROC es la métrica de selección del modelo para el problema de clasificación \n",
    "#de dos clases múltiples.ROC nos dice qué tan bueno es el modelo para distinguir las clases dadas, \n",
    "#en términos de la probabilidad predicha.\n",
    "\n",
    "#n_jobs = número de nucleos que se utilizan (-1 quiere decir que se utilizan todos)\n",
    "\n",
    "r_s_model_2 = RandomizedSearchCV(gb_model , param_distributions=params, n_iter=5, \n",
    "                               scoring='roc_auc',n_jobs=-1,cv=5,verbose=3,random_state = 2)\n",
    "\n",
    "r_s_model_2.fit(x_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_L5mXQ-JRtg"
   },
   "outputs": [],
   "source": [
    "r_s_model_2.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoVKotCcpLRy"
   },
   "source": [
    "## 2.2 Rendimiento con todas las features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22LZf3hgMvey"
   },
   "outputs": [],
   "source": [
    "#Construyendo el modelo final\n",
    "gb_model = GradientBoostingClassifier(learning_rate=0.16, max_depth=26, n_estimators=355)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53iLdlm0M4hS"
   },
   "outputs": [],
   "source": [
    "#Métricas\n",
    "\n",
    "gb_model.fit(x_train_1, y_train_1)\n",
    "\n",
    "y_pred = gb_model.predict(x_test)\n",
    "\n",
    "acc_gb = accuracy_score(y_test, y_pred)\n",
    "sensibilidad_gb = recall_score(y_test, y_pred)\n",
    "#precision_xgb = precision_score(y_test, y_pred)\n",
    "specificity_gb = confusion_matrix(y_test, y_pred)[0][0]/(confusion_matrix(y_test, y_pred)[0][0]+confusion_matrix(y_test, y_pred)[0][1])\n",
    "auc_gb = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "Tabla_2 = pd.DataFrame({ \"Prestaciones en test\":[\"Accuracy\",\"Sensibility\",'Specificity',\"AUC ROC\"],\n",
    "                      \"GBoost\" : [acc_gb, sensibilidad_gb, specificity_gb, auc_gb]})\n",
    "\n",
    "Tabla_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijH2kiaPpQ41"
   },
   "source": [
    "## 2.3 Selección de características (FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQl1rMUr4xGN"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#Plot feature importance\n",
    "def plot_feature_importance(importance,names,model_type):\n",
    "\n",
    "  #Create arrays from feature importance and feature names\n",
    "  feature_importance = np.array(importance)\n",
    "  feature_names = np.array(names)\n",
    "\n",
    "  #Create a DataFrame using a Dictionary\n",
    "  data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "  fi_df = pd.DataFrame(data)\n",
    "\n",
    "  #Sort the DataFrame in order decreasing feature importance\n",
    "  fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "  #Define size of bar plot\n",
    "  fig = plt.figure(figsize=(20,6))\n",
    "  #Plot Searborn bar chart\n",
    "  sns.barplot(y=fi_df['feature_importance'], x=fi_df['feature_names'])\n",
    "  #Add chart labels\n",
    "  plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "  plt.xlabel('FEATURE IMPORTANCE')\n",
    "  plt.ylabel('FEATURE NAMES')\n",
    "  plt.tight_layout()\n",
    "  fig.autofmt_xdate(rotation=45)\n",
    "\n",
    "\n",
    "plot_feature_importance(gb_model.feature_importances_*100,x_train_1.columns,'Gradient Boosting')\n",
    "\n",
    "print(np.sum(gb_model.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zc8gjLZWq6G1"
   },
   "source": [
    "A partir de este gráfico se puede observar la importancia de cada característica haciendo uso de XGBoost. Así pues, MO-Y es la variable que aporta mayor información al realizar la tarea de clasificación, con lo que permitirá, en mayor medida, diferenciar un paciente sano de uno no sano. No obstante, la siguiente variable UCI también presentan información relevante para la predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slKvOlOp48LL"
   },
   "source": [
    "**Selección de las características en base a la importancia de éstas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9OdM9pcr48_P"
   },
   "outputs": [],
   "source": [
    "#SelectFromModel\n",
    "\n",
    "scores_cv = []\n",
    "thresholds = np.sort(gb_model.feature_importances_) # obtiene la importancia de cada característica\n",
    "i = 0\n",
    "for thresh in thresholds:\n",
    "    print(\"{} de {}\".format(i,len(thresholds)))\n",
    "    selection = SelectFromModel(gb_model, threshold=thresh, prefit=True)\n",
    "    select_x_train_1 = selection.transform(x_train_1)\n",
    "    # train model\n",
    "    selection_model = GradientBoostingClassifier(learning_rate=0.05, max_depth=25, n_estimators=350)\n",
    "    #cv estimation\n",
    "    sc =cross_val_score(selection_model, select_x_train_1, y_train_1, cv=10, scoring='roc_auc',n_jobs=-1)\n",
    "    scores_cv.append(sc)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JehCEQKh5MEg"
   },
   "outputs": [],
   "source": [
    "plt.rc('xtick',labelsize=15)\n",
    "plt.rc('ytick',labelsize=15)\n",
    "plt.figure(figsize = (80,20))\n",
    "sc_cv = np.asarray(scores_cv)\n",
    "scores_m = np.mean(sc_cv,axis = 1)\n",
    "scores_std = np.std(sc_cv,axis = 1)\n",
    "xx = np.arange(len(scores_m))\n",
    "plt.plot(xx,scores_m,'o-')\n",
    "plt.grid()\n",
    "_ = plt.xticks(xx,labels= np.arange(1,len(scores_m)+1))\n",
    "plt.xlabel('Number of features removed')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dK_wom1irWSd"
   },
   "source": [
    "Esta gráfica muestra el ***accuracy*** que se alcanza cuando se escogen X características. Desde la izquierda hacia la derecha se van quitando variables consecutivamente, y se puede observar que la predicción del modelo no se degrada hasta llegar a 69 variables. Es decir, solo quedándonos con 2  variables, el modelo es capaz de tener el mismo desempeño en predicción que utilizando todas las variables. Estas característica son las 2 primeras representadas anteriormente en la gráfica anterior.\n",
    "\n",
    "Además siempre es preferible tener un modelo menos complejo para que de esta forma pueda haber una mejor generalizacion con la incorporación de datos nuevos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1COH2pM_rfZr"
   },
   "source": [
    "## 2.4 Rendimiento con FS en el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bBSit54rkw7"
   },
   "outputs": [],
   "source": [
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)\n",
    "\n",
    "#convert into a dataframe with sorted feature importances\n",
    "fi = rf_feat_importance(gb_model,x_train_1)\n",
    "\n",
    "#select the features\n",
    "selected_features_RF = fi[:len(fi)-69]['cols'].to_list()\n",
    "print(\"Numero de variables seleccionadas Pars:\",len(selected_features_RF))\n",
    "print(\"Selected features:\",selected_features_RF)\n",
    "\n",
    "\n",
    "X_train_FT_gb = x_train_1[selected_features_RF]\n",
    "X_test_FT_gb = x_test[selected_features_RF]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqiyN7kNr8aC"
   },
   "outputs": [],
   "source": [
    "gb_FS = GradientBoostingClassifier(learning_rate=0.16, max_depth=26, n_estimators=355)\n",
    "gb_FS.fit(X_train_FT_gb, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qimkky5zsKT-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#Todas las características\n",
    "y_pred_tot = gb_model.predict(x_test)\n",
    "acc_tot = accuracy_score(y_test, y_pred_tot)\n",
    "sensibilidad_tot = recall_score(y_test, y_pred_tot)\n",
    "#precision_tot=precision_score(y_test, y_pred_tot)\n",
    "specificity_tot = confusion_matrix(y_test, y_pred_tot)[0][0]/(confusion_matrix(y_test, y_pred_tot)[0][0]+confusion_matrix(y_test, y_pred_tot)[0][1])\n",
    "auc_tot = roc_auc_score(y_test, y_pred_tot)\n",
    "\n",
    "\n",
    "#2 características \n",
    "y_pred_2 = gb_FS.predict(X_test_FT_gb)\n",
    "acc_2 = accuracy_score(y_test, y_pred_2)\n",
    "sensibilidad_2 = recall_score(y_test, y_pred_2)\n",
    "#precision_2 = precision_score(y_test, y_pred_2)\n",
    "specificity_2 = confusion_matrix(y_test, y_pred_2)[0][0]/(confusion_matrix(y_test, y_pred_2)[0][0]+confusion_matrix(y_test, y_pred_2)[0][1])\n",
    "auc_2 = roc_auc_score(y_test, y_pred_2)\n",
    "\n",
    "Tabla_gb = pd.DataFrame({\"Prestaciones en test\":[\"Accuracy\",\"Sensibility\",'Specificity',\"AUC ROC\"],\n",
    "                         \"GBoost total\" : [acc_tot, sensibilidad_tot, specificity_tot, auc_tot], \n",
    "                      \"GBoost 2 features \" : [acc_2, sensibilidad_2, specificity_2, auc_2]})\n",
    "Tabla_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9k_dOJt2WE41"
   },
   "outputs": [],
   "source": [
    "#GBoost all features\n",
    "plot_confusion_matrix(gb_model, x_test, y_test,display_labels=[\"Sano\",\"No sano\"],\n",
    "                                 cmap=plt.cm.Blues)\n",
    "plt.title(\"GBoost all features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSyoj6KZWUPW"
   },
   "outputs": [],
   "source": [
    "#GBoost 2 features\n",
    "plot_confusion_matrix(gb_FS, X_test_FT_gb, y_test,display_labels=[\"Sano\",\"No sano\"],\n",
    "                                 cmap=plt.cm.Blues)\n",
    "plt.title(\"GBoost 2 features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tI-esAG5rP9Q"
   },
   "source": [
    "# 3.Histogram-based Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jtl4ZFN3bbe8"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKZi2FJsvLCb"
   },
   "source": [
    "## 3.1 Optimización de los hiperparámetros usando RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQ2c4qzsbb8K"
   },
   "outputs": [],
   "source": [
    "#Indico que el clasificador que voy a utlizar es XGBosst\n",
    "\n",
    "hb_model = HistGradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymoVMrSmbcLj"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    " 'max_leaf_nodes': [1,3,5,7,10,13,15,20,25,30,35,40],\n",
    " 'learning_rate' : [0.05,0.10,0.15,0.20,0.25,0.30],\n",
    " 'max_depth' : [3,4,5,6,8,10,12,15,20,25,30],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jOtwpuEbcTj"
   },
   "outputs": [],
   "source": [
    "#verbose = genera mensajes durante el entramiento del modelo 'Fitting 5 folds...'\n",
    "\n",
    "#roc_auc = curva AUC-ROC es la métrica de selección del modelo para el problema de clasificación \n",
    "#de dos clases múltiples.ROC nos dice qué tan bueno es el modelo para distinguir las clases dadas, \n",
    "#en términos de la probabilidad predicha.\n",
    "\n",
    "#n_jobs = número de nucleos que se utilizan (-1 quiere decir que se utilizan todos)\n",
    "\n",
    "r_s_model_3 = RandomizedSearchCV(hb_model , param_distributions=params, n_iter=5, \n",
    "                               scoring='roc_auc',n_jobs=-1,cv=5,verbose=3,random_state = 2)\n",
    "r_s_model_3.fit(x_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hj7W2xHRbix2"
   },
   "outputs": [],
   "source": [
    "r_s_model_3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEwcF98aJXP1"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    " 'max_leaf_nodes': [22,23,24,25,26,27,28],\n",
    " 'learning_rate' : [0.20,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,0.30],\n",
    " 'max_depth' : [4,5,6,7,8,9,10,11,12],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58zIcoAaJyuR"
   },
   "outputs": [],
   "source": [
    "#verbose = genera mensajes durante el entramiento del modelo 'Fitting 5 folds...'\n",
    "\n",
    "#roc_auc = curva AUC-ROC es la métrica de selección del modelo para el problema de clasificación \n",
    "#de dos clases múltiples.ROC nos dice qué tan bueno es el modelo para distinguir las clases dadas, \n",
    "#en términos de la probabilidad predicha.\n",
    "\n",
    "#n_jobs = número de nucleos que se utilizan (-1 quiere decir que se utilizan todos)\n",
    "\n",
    "r_s_model_3 = RandomizedSearchCV(hb_model , param_distributions=params, n_iter=5, \n",
    "                               scoring='roc_auc',n_jobs=-1,cv=5,verbose=3,random_state = 2)\n",
    "r_s_model_3.fit(x_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXRFbyuvJ0ZZ"
   },
   "outputs": [],
   "source": [
    "r_s_model_3.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uo3TDvgGvTow"
   },
   "source": [
    "## 3.2 Rendimiento con todas las features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wdCrrnJabi6y"
   },
   "outputs": [],
   "source": [
    "#Construyendo el modelo final\n",
    "hb_model = HistGradientBoostingClassifier(learning_rate=0.29, max_depth=6,\n",
    "                               max_leaf_nodes=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coLW01zXdkLN"
   },
   "outputs": [],
   "source": [
    "#Métricas\n",
    "\n",
    "hb_model.fit(x_train_1, y_train_1)\n",
    "\n",
    "y_pred = hb_model.predict(x_test)\n",
    "\n",
    "acc_hb = accuracy_score(y_test, y_pred)\n",
    "sensibilidad_hb = recall_score(y_test, y_pred)\n",
    "#precision_xgb = precision_score(y_test, y_pred)\n",
    "specificity_hb = confusion_matrix(y_test, y_pred)[0][0]/(confusion_matrix(y_test, y_pred)[0][0]+confusion_matrix(y_test, y_pred)[0][1])\n",
    "auc_hb = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "Tabla_3 = pd.DataFrame({ \"Prestaciones en test\":[\"Accuracy\",\"Sensibility\",'Specificity',\"AUC ROC\"],\n",
    "                      \"HBoost\" : [acc_hb, sensibilidad_hb, specificity_hb, auc_hb]})\n",
    "\n",
    "Tabla_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1QskmnvvZmu"
   },
   "source": [
    "## 3.3 Selección de características (FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UF7lKwhL5Y0d"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#Plot feature importance\n",
    "def plot_feature_importance(importance,names,model_type):\n",
    "\n",
    "  #Create arrays from feature importance and feature names\n",
    "  feature_importance = np.array(importance)\n",
    "  feature_names = np.array(names)\n",
    "\n",
    "  #Create a DataFrame using a Dictionary\n",
    "  data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "  fi_df = pd.DataFrame(data)\n",
    "\n",
    "  #Sort the DataFrame in order decreasing feature importance\n",
    "  fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "  #Define size of bar plot\n",
    "  fig = plt.figure(figsize=(20,6))\n",
    "  #Plot Searborn bar chart\n",
    "  sns.barplot(y=fi_df['feature_importance'], x=fi_df['feature_names'])\n",
    "  #Add chart labels\n",
    "  plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "  plt.xlabel('FEATURE IMPORTANCE')\n",
    "  plt.ylabel('FEATURE NAMES')\n",
    "  plt.tight_layout()\n",
    "  fig.autofmt_xdate(rotation=45)\n",
    "\n",
    "\n",
    "plot_feature_importance(hb_model.feature_importances_*100,x_train_1.columns,'Histogram-based')\n",
    "\n",
    "print(np.sum(hb_model.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uu8VMWix5n00"
   },
   "source": [
    "**Selección de las características en base a la importancia de éstas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00Ov1Kpq5n88"
   },
   "outputs": [],
   "source": [
    "#SelectFromModel\n",
    "\n",
    "scores_cv = []\n",
    "thresholds = np.sort(hb_model.feature_importances_) # obtiene la importancia de cada característica\n",
    "i = 0\n",
    "for thresh in thresholds:\n",
    "    print(\"{} de {}\".format(i,len(thresholds)))\n",
    "    selection = SelectFromModel(hb_model, threshold=thresh, prefit=True)\n",
    "    select_x_train_1 = selection.transform(x_train_1)\n",
    "    # train model\n",
    "    selection_model = HistGradientBoostingClassifier(learning_rate=0.05, max_depth=25, max_leaf_nodes=25)\n",
    "    #cv estimation\n",
    "    sc =cross_val_score(selection_model, select_x_train_1, y_train_1, cv=10, scoring='roc_auc',n_jobs=-1)\n",
    "    scores_cv.append(sc)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mXll6dW6GQK"
   },
   "outputs": [],
   "source": [
    "plt.rc('xtick',labelsize=15)\n",
    "plt.rc('ytick',labelsize=15)\n",
    "plt.figure(figsize = (80,20))\n",
    "sc_cv = np.asarray(scores_cv)\n",
    "scores_m = np.mean(sc_cv,axis = 1)\n",
    "scores_std = np.std(sc_cv,axis = 1)\n",
    "xx = np.arange(len(scores_m))\n",
    "plt.plot(xx,scores_m,'o-')\n",
    "plt.grid()\n",
    "_ = plt.xticks(xx,labels= np.arange(1,len(scores_m)+1))\n",
    "plt.xlabel('Number of features removed')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5VOjw0FeWeb"
   },
   "source": [
    "## 3.4 Rendimiento con FS en el conjunto de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWyGEa_1fid8"
   },
   "source": [
    "# Machine learning para todas las revisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1klGt7oBBeax"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXsIk3ig90lW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Te damos la bienvenida a Colaboratory",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
