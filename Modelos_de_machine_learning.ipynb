{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jorgealarconlucas/TFG/blob/master/Modelos_de_machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-ruNeqFp9jnV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as stats\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import statistics as stats\n",
    "import seaborn as sns \n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,recall_score, precision_score, confusion_matrix\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vxi0qdBF9isu"
   },
   "outputs": [],
   "source": [
    "x_train = pd.read_feather('x_train')\n",
    "y_train = np.load ('y_train.npy')\n",
    "x_test = pd.read_feather('x_test')\n",
    "y_test = np.load ('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XLvWaFk-KfP1"
   },
   "outputs": [],
   "source": [
    "y_train = pd.Series(y_train) #Lo paso de numpy a pandas.series\n",
    "y_test = pd.Series(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXcVUQjKBeKj"
   },
   "source": [
    "# Machine learning para revision = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juR47B0PLTdA"
   },
   "source": [
    "### Con X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "E2vhEerI65bC",
    "outputId": "491621a5-6730-498b-8b9d-05611f55179e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Edad del Paciente</th>\n",
       "      <th>Sexo del Paciente</th>\n",
       "      <th>LEU</th>\n",
       "      <th>NEU</th>\n",
       "      <th>NEUp</th>\n",
       "      <th>LIN</th>\n",
       "      <th>LINp</th>\n",
       "      <th>MON</th>\n",
       "      <th>MONp</th>\n",
       "      <th>EOS</th>\n",
       "      <th>...</th>\n",
       "      <th>WBC-N</th>\n",
       "      <th>ASLYP</th>\n",
       "      <th>ASLYA</th>\n",
       "      <th>RELPL</th>\n",
       "      <th>RELYP</th>\n",
       "      <th>RELYA</th>\n",
       "      <th>NEUGI</th>\n",
       "      <th>NEURI</th>\n",
       "      <th>ASLPL</th>\n",
       "      <th>Revision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.840</td>\n",
       "      <td>49.00</td>\n",
       "      <td>1.290</td>\n",
       "      <td>34.40</td>\n",
       "      <td>0.490</td>\n",
       "      <td>13.10</td>\n",
       "      <td>0.110</td>\n",
       "      <td>...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>17.1</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.22</td>\n",
       "      <td>146.60</td>\n",
       "      <td>53.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.05</td>\n",
       "      <td>1.170</td>\n",
       "      <td>38.50</td>\n",
       "      <td>1.050</td>\n",
       "      <td>34.40</td>\n",
       "      <td>0.800</td>\n",
       "      <td>8.84</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.08</td>\n",
       "      <td>151.00</td>\n",
       "      <td>56.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.64</td>\n",
       "      <td>5.416</td>\n",
       "      <td>53.06</td>\n",
       "      <td>3.348</td>\n",
       "      <td>37.26</td>\n",
       "      <td>0.692</td>\n",
       "      <td>7.92</td>\n",
       "      <td>0.064</td>\n",
       "      <td>...</td>\n",
       "      <td>9.64</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.004</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.20</td>\n",
       "      <td>147.86</td>\n",
       "      <td>49.04</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.25</td>\n",
       "      <td>15.160</td>\n",
       "      <td>87.90</td>\n",
       "      <td>0.980</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.880</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.050</td>\n",
       "      <td>...</td>\n",
       "      <td>17.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.11</td>\n",
       "      <td>155.30</td>\n",
       "      <td>48.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.89</td>\n",
       "      <td>3.570</td>\n",
       "      <td>72.90</td>\n",
       "      <td>0.610</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.350</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>4.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.14</td>\n",
       "      <td>148.70</td>\n",
       "      <td>52.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Edad del Paciente  Sexo del Paciente    LEU     NEU   NEUp    LIN   LINp  \\\n",
       "1                76.0                0.0   3.75   1.840  49.00  1.290  34.40   \n",
       "5                66.0                0.0   3.05   1.170  38.50  1.050  34.40   \n",
       "16               37.0                0.0   9.64   5.416  53.06  3.348  37.26   \n",
       "19               85.0                1.0  17.25  15.160  87.90  0.980   5.70   \n",
       "22               74.0                0.0   4.89   3.570  72.90  0.610  12.50   \n",
       "\n",
       "      MON   MONp    EOS  ...  WBC-N  ASLYP  ASLYA  RELPL  RELYP  RELYA  \\\n",
       "1   0.490  13.10  0.110  ...   3.75   0.00  0.000   17.1   5.90   0.22   \n",
       "5   0.800   8.84  0.010  ...   3.05   0.00  0.000    7.6   2.60   0.08   \n",
       "16  0.692   7.92  0.064  ...   9.64   0.14  0.004    8.6   2.54   0.20   \n",
       "19  0.880   5.10  0.050  ...  17.25   0.00  0.000   11.2   0.60   0.11   \n",
       "22  0.350   7.20  0.010  ...   4.89   0.00  0.000   23.0   2.90   0.14   \n",
       "\n",
       "     NEUGI  NEURI  ASLPL  Revision  \n",
       "1   146.60  53.80   0.00       1.0  \n",
       "5   151.00  56.50   0.00       1.0  \n",
       "16  147.86  49.04   0.34       1.0  \n",
       "19  155.30  48.60   0.00       1.0  \n",
       "22  148.70  52.10   0.00       1.0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_1 = x_train[x_train['Revision'] == 1]\n",
    "\n",
    "x_train_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SOpidxanKSpn"
   },
   "outputs": [],
   "source": [
    "#Elimino la variable 'Revision' puesto que una vez he cogido los pacientes con revision=1, la variable ya \n",
    "#no me hace falta.\n",
    "x_train_1 = x_train_1.drop([\"Revision\"],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "US2sPygL62WC",
    "outputId": "8cd00bc4-66a4-4b6e-9a4d-6a8f9a351770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "len(y_train)\n",
    "\n",
    "#get a boolean np.array as index\n",
    "idx = x_train['Revision'] == 1\n",
    "\n",
    "idx = idx.values\n",
    "\n",
    "y_train_aux = y_train.values\n",
    "\n",
    "y_train_1 = y_train_aux[idx]\n",
    "\n",
    "print(y_train_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdCoKBuhLYCr"
   },
   "source": [
    "### Con X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "T9VbcNWBK8BR",
    "outputId": "da195b57-a58c-4090-8c28-4b06a3bc082c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Edad del Paciente</th>\n",
       "      <th>Sexo del Paciente</th>\n",
       "      <th>LEU</th>\n",
       "      <th>NEU</th>\n",
       "      <th>NEUp</th>\n",
       "      <th>LIN</th>\n",
       "      <th>LINp</th>\n",
       "      <th>MON</th>\n",
       "      <th>MONp</th>\n",
       "      <th>EOS</th>\n",
       "      <th>...</th>\n",
       "      <th>WBC-N</th>\n",
       "      <th>ASLYP</th>\n",
       "      <th>ASLYA</th>\n",
       "      <th>RELPL</th>\n",
       "      <th>RELYP</th>\n",
       "      <th>RELYA</th>\n",
       "      <th>NEUGI</th>\n",
       "      <th>NEURI</th>\n",
       "      <th>ASLPL</th>\n",
       "      <th>Revision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.060</td>\n",
       "      <td>5.98</td>\n",
       "      <td>74.30</td>\n",
       "      <td>1.210</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.690</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0.140</td>\n",
       "      <td>...</td>\n",
       "      <td>8.060</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.080</td>\n",
       "      <td>159.30</td>\n",
       "      <td>49.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.862</td>\n",
       "      <td>7.67</td>\n",
       "      <td>73.30</td>\n",
       "      <td>1.434</td>\n",
       "      <td>18.52</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.036</td>\n",
       "      <td>...</td>\n",
       "      <td>9.862</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.008</td>\n",
       "      <td>11.44</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.148</td>\n",
       "      <td>147.94</td>\n",
       "      <td>52.50</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.184</td>\n",
       "      <td>17.12</td>\n",
       "      <td>65.20</td>\n",
       "      <td>2.550</td>\n",
       "      <td>9.70</td>\n",
       "      <td>0.608</td>\n",
       "      <td>18.20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>7.184</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.100</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.240</td>\n",
       "      <td>136.80</td>\n",
       "      <td>50.98</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.850</td>\n",
       "      <td>4.67</td>\n",
       "      <td>68.10</td>\n",
       "      <td>1.520</td>\n",
       "      <td>22.20</td>\n",
       "      <td>0.500</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.080</td>\n",
       "      <td>...</td>\n",
       "      <td>6.850</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.80</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.210</td>\n",
       "      <td>141.40</td>\n",
       "      <td>47.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.170</td>\n",
       "      <td>4.33</td>\n",
       "      <td>65.44</td>\n",
       "      <td>1.370</td>\n",
       "      <td>27.16</td>\n",
       "      <td>0.396</td>\n",
       "      <td>6.08</td>\n",
       "      <td>0.008</td>\n",
       "      <td>...</td>\n",
       "      <td>6.170</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11.84</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.146</td>\n",
       "      <td>152.26</td>\n",
       "      <td>51.58</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Edad del Paciente  Sexo del Paciente    LEU    NEU   NEUp    LIN   LINp  \\\n",
       "2                76.0                0.0  8.060   5.98  74.30  1.210  15.00   \n",
       "3                72.0                1.0  9.862   7.67  73.30  1.434  18.52   \n",
       "6                69.0                0.0  7.184  17.12  65.20  2.550   9.70   \n",
       "7                72.0                1.0  6.850   4.67  68.10  1.520  22.20   \n",
       "15               83.0                1.0  6.170   4.33  65.44  1.370  27.16   \n",
       "\n",
       "      MON   MONp    EOS  ...  WBC-N  ASLYP  ASLYA  RELPL  RELYP  RELYA  \\\n",
       "2   0.690   8.60  0.140  ...  8.060   0.00  0.000   6.60   1.00  0.080   \n",
       "3   0.538   6.18  0.036  ...  9.862   0.08  0.008  11.44   1.84  0.148   \n",
       "6   0.608  18.20  0.010  ...  7.184   0.40  0.100   9.40   0.90  0.240   \n",
       "7   0.500   7.30  0.080  ...  6.850   0.00  0.000  13.80   3.10  0.210   \n",
       "15  0.396   6.08  0.008  ...  6.170   0.22  0.006  11.84   1.96  0.146   \n",
       "\n",
       "     NEUGI  NEURI  ASLPL  Revision  \n",
       "2   159.30  49.60   0.00       1.0  \n",
       "3   147.94  52.50   0.88       1.0  \n",
       "6   136.80  50.98   3.90       1.0  \n",
       "7   141.40  47.90   0.00       1.0  \n",
       "15  152.26  51.58   1.18       1.0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_1 = x_test[x_test['Revision'] == 1]\n",
    "\n",
    "x_test_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TxsOfYy4LP3Y"
   },
   "outputs": [],
   "source": [
    "#Elimino la variable 'Revision' puesto que una vez he cogido los pacientes con revision=1, la variable ya \n",
    "#no me hace falta.\n",
    "x_test_1 = x_test_1.drop([\"Revision\"],axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ycp3vVjBLG4r",
    "outputId": "a7d13ae4-a15f-4dde-efbb-8765e04cc0a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "len(y_test)\n",
    "\n",
    "#get a boolean np.array as index\n",
    "idx = x_test['Revision'] == 1\n",
    "\n",
    "idx = idx.values\n",
    "\n",
    "y_test_aux = y_test.values\n",
    "\n",
    "y_test_1 = y_test_aux[idx]\n",
    "\n",
    "print(y_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iA8M8HS-O_s"
   },
   "source": [
    "# 1.XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Q2_52kUXC7tS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes, load_wine\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0BmHhZ0Li2s"
   },
   "source": [
    "## 1.1 OptimizaciÃ³n de los hiperparÃ¡metros usando RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "BHAN5Yve-9Ch"
   },
   "outputs": [],
   "source": [
    "#Indico que el clasificador que voy a utlizar es XGBosst\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCpdvaAR-Nqa"
   },
   "source": [
    "Inicialmente creamos un diccionario de algunos parÃ¡metros a entrenar. AquÃ­ las claves son bÃ¡sicamente los parÃ¡metros y los valores a entrenar. AsÃ­ que el RandomizedSearchCV probarÃ¡ cada valor y encontrarÃ¡ el valor particular que da la mayor precisiÃ³n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Klmci5LdABp_"
   },
   "outputs": [],
   "source": [
    "#Cuanto mayor sea gamma, mÃ¡s conservador serÃ¡ el algoritmo\n",
    "#min_child_weight: para controlar el sobreajuste, cuanto mayor sea min_child_weight, mÃ¡s conservador serÃ¡ el algoritmo\n",
    "\n",
    "params = {\n",
    " 'n_estimators' : [25,50,75,100,125,150,175,200,250,300,350,400],\n",
    " 'learning_rate' : [0.05,0.10,0.15,0.20,0.25,0.30],\n",
    " 'max_depth' : [3,4,5,6,8,10,12,15],\n",
    " 'gamma': [0.0,0.1,0.2,0.3,0.4],\n",
    " 'colsample_bytree' : [0.3,0.4,0.5,0.7]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_8hIRiEAqFu"
   },
   "source": [
    "A continuaciÃ³n, llamamos a RandomizedSearchCV() y le pasamos los siguientes parÃ¡metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3SHHuaOcAvQA",
    "outputId": "b7723b59-e244-4dae-98fb-cec08fec6f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:49:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           enable_categorical=False, gamma=None,\n",
       "                                           gpu_id=None, importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints...\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        'max_depth': [3, 4, 5, 6, 8, 10, 12,\n",
       "                                                      15],\n",
       "                                        'n_estimators': [25, 50, 75, 100, 125,\n",
       "                                                         150, 175, 200, 250,\n",
       "                                                         300, 350, 400]},\n",
       "                   random_state=2, scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verbose = genera mensajes durante el entramiento del modelo 'Fitting 5 folds...'\n",
    "\n",
    "#roc_auc = curva AUC-ROC es la mÃ©trica de selecciÃ³n del modelo para el problema de clasificaciÃ³n \n",
    "#de dos clases mÃºltiples.ROC nos dice quÃ© tan bueno es el modelo para distinguir las clases dadas, \n",
    "#en tÃ©rminos de la probabilidad predicha.\n",
    "\n",
    "#n_jobs = nÃºmero de nucleos que se utilizan (-1 quiere decir que se utilizan todos)\n",
    "\n",
    "r_s_model = RandomizedSearchCV(xgb_model , param_distributions=params, n_iter=5, \n",
    "                               scoring='roc_auc',n_jobs=-1,cv=5,verbose=3,random_state = 2)\n",
    "r_s_model.fit(x_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwHr_OxHCJBY"
   },
   "source": [
    "Bien, nuestro modelo ha sido ajustado. Veamos ahora todos los parÃ¡metros que han sido seleccionados por el RandomizedSearch() para el XGBClassifier. Podemos hacerlo con la ayuda del mÃ©todo best_estimators_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rXz112xuCL9x",
    "outputId": "5589d989-9f1b-4bcb-db85-f07cd59dd827"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3,\n",
       "              enable_categorical=False, gamma=0.1, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.3, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_s_model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSJUkKA6HaQT"
   },
   "source": [
    "Una vez conozco los valores de hiperparÃ¡metros, vuelvo a buscar la optimizaciÃ³n de los mismos, pero esta vez afinando mÃ¡s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "NyURH0MLHYip"
   },
   "outputs": [],
   "source": [
    "#Cuanto mayor sea gamma, mÃ¡s conservador serÃ¡ el algoritmo\n",
    "#min_child_weight: para controlar el sobreajuste, cuanto mayor sea min_child_weight, mÃ¡s conservador serÃ¡ el algoritmo\n",
    "\n",
    "params = {\n",
    " 'n_estimators' : [192,194,196,198,200,202,204,206,208],\n",
    " 'learning_rate' : [0.11,0.12,0.13,0.14,0.15,0.16,0.17,0.18,0.19],\n",
    " 'max_depth' : [8,9,10,11,12,13,14,15,16],\n",
    " 'gamma': [0.30,0.33,0.36,0.39,0.42,0.45,0.48],\n",
    " 'colsample_bytree' : [0.15,0.20,0.25,0.30,0.35,0.40,0.45]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tgq4jyIe6TTV",
    "outputId": "a2d655ce-ad2e-4910-dece-4ecb0c5bcfe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Edad del Paciente', 'Sexo del Paciente', 'LEU', 'NEU', 'NEUp', 'LIN',\n",
      "       'LINp', 'MON', 'MONp', 'EOS', 'EOSp', 'BAS', 'BASp', 'IG', 'IGp',\n",
      "       'ERIT', 'HGB', 'HCT', 'VCM', 'HCM', 'CHCM', 'RDW', 'ERBL', 'ERBLp',\n",
      "       'PLT', 'PLTI', 'VPM', 'rNe/L', 'rPL/L', 'MacR', 'MicR', 'BA-D#',\n",
      "       'NEFSC', 'BA-D%', 'BA-N#', 'BA-N%', 'HFLCA', 'HFLCP', 'LY-WX', 'LY-WY',\n",
      "       'LY-WZ', 'LY-X', 'LY-Y', 'LY-Z', 'MO-WX', 'MO-WY', 'MO-WZ', 'MO-X',\n",
      "       'MO-Y', 'MO-Z', 'NESFL', 'NESSC', 'NE-WX', 'NE-WY', 'NE-WZ', 'TNC-N',\n",
      "       'WBC-D', 'WBC-N', 'ASLYP', 'ASLYA', 'RELPL', 'RELYP', 'RELYA', 'NEUGI',\n",
      "       'NEURI', 'ASLPL'],\n",
      "      dtype='object')\n",
      "[0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_1.columns)\n",
    "print(y_train_1)\n",
    "#print(x_test_1['Revision'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6o2OeCTvIkWi",
    "outputId": "66561e7e-cbf5-44e0-faa7-13f48536ab3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:50:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           enable_categorical=False, gamma=None,\n",
       "                                           gpu_id=None, importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints...\n",
       "                                           verbosity=None),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.15, 0.2, 0.25,\n",
       "                                                             0.3, 0.35, 0.4,\n",
       "                                                             0.45],\n",
       "                                        'gamma': [0.3, 0.33, 0.36, 0.39, 0.42,\n",
       "                                                  0.45, 0.48],\n",
       "                                        'learning_rate': [0.11, 0.12, 0.13,\n",
       "                                                          0.14, 0.15, 0.16,\n",
       "                                                          0.17, 0.18, 0.19],\n",
       "                                        'max_depth': [8, 9, 10, 11, 12, 13, 14,\n",
       "                                                      15, 16],\n",
       "                                        'n_estimators': [192, 194, 196, 198,\n",
       "                                                         200, 202, 204, 206,\n",
       "                                                         208]},\n",
       "                   random_state=2, scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verbose = genera mensajes durante el entramiento del modelo 'Fitting 5 folds...'\n",
    "\n",
    "#roc_auc = curva AUC-ROC es la mÃ©trica de selecciÃ³n del modelo para el problema de clasificaciÃ³n \n",
    "#de dos clases mÃºltiples.ROC nos dice quÃ© tan bueno es el modelo para distinguir las clases dadas, \n",
    "#en tÃ©rminos de la probabilidad predicha.\n",
    "\n",
    "#n_jobs = nÃºmero de nucleos que se utilizan (-1 quiere decir que se utilizan todos)\n",
    "\n",
    "r_s_model = RandomizedSearchCV(xgb_model , param_distributions=params, n_iter=5, \n",
    "                               scoring='roc_auc',n_jobs=-1,cv=5,verbose=3,random_state = 2)\n",
    "r_s_model.fit(x_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J8GzmVZNIm0X",
    "outputId": "08214ff3-37f4-4c9f-bf9f-e854e8dfa38a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.45,\n",
       "              enable_categorical=False, gamma=0.48, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.15, max_delta_step=0, max_depth=11,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=192, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_s_model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJT9dRNqfiKU"
   },
   "source": [
    "## 1.2 Rendimiento con todas las features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xG-bVWyjCZcx"
   },
   "source": [
    "Ahora, como conocemos todos los mejores parÃ¡metros, podemos simplemente construir nuestro modelo clasificador final pasando todos esos parÃ¡metros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "MF6gOB1RChQp"
   },
   "outputs": [],
   "source": [
    "#Construyendo el modelo final\n",
    "xgb_model = xgb.XGBClassifier(colsample_bytree=0.45, gamma=0.3, learning_rate=0.15,\n",
    "              max_depth=16, n_estimators=202)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "kguJP0rx6TTa"
   },
   "outputs": [],
   "source": [
    "#print(x_test['Fecha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "0NSP3PtSNEB3"
   },
   "outputs": [],
   "source": [
    "x_test_WR = x_test.drop([\"Revision\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "NWmveSOUG3Wi",
    "outputId": "a92d0fdf-441c-48be-a7c2-3e63e65ce16f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:50:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prestaciones en test</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sensibility</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUC ROC</td>\n",
       "      <td>0.535256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prestaciones en test   XGBoost\n",
       "0             Accuracy  0.765625\n",
       "1          Sensibility  0.166667\n",
       "2          Specificity  0.903846\n",
       "3              AUC ROC  0.535256"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MÃ©tricas\n",
    "\n",
    "xgb_model.fit(x_train_1, y_train_1)\n",
    "\n",
    "y_pred = xgb_model.predict(x_test_WR)\n",
    "\n",
    "acc_xgb = accuracy_score(y_test, y_pred)\n",
    "sensibilidad_xgb = recall_score(y_test, y_pred)\n",
    "#precision_xgb = precision_score(y_test, y_pred)\n",
    "specificity_xgb = confusion_matrix(y_test, y_pred)[0][0]/(confusion_matrix(y_test, y_pred)[0][0]+confusion_matrix(y_test, y_pred)[0][1])\n",
    "auc_xgb = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "Tabla = pd.DataFrame({ \"Prestaciones en test\":[\"Accuracy\",\"Sensibility\",'Specificity',\"AUC ROC\"],\n",
    "                      \"XGBoost\" : [acc_xgb, sensibilidad_xgb, specificity_xgb, auc_xgb]})\n",
    "\n",
    "Tabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_w29Eajzaja"
   },
   "source": [
    "## 1.3 SelecciÃ³n de caracterÃ­sticas (FS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PL0SquGRzibQ"
   },
   "source": [
    "La selecciÃ³n de caracterÃ­sticas se entiende como una disminuciÃ³n del nÃºmero de Ã©stas, en funciÃ³n de un criterio elegido por el usuario, escogiendo aquellas que se consideran mÃ¡s informativas y eliminando aquellas que son irrelevantes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mp9Vyp9DzlTb"
   },
   "source": [
    "**Importancia de cada caracterÃ­stica**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4qQSKeWzmFn"
   },
   "source": [
    "La importancia de caracterÃ­sticas desempeÃ±a un papel importante, ya que proporciona una visiÃ³n de los datos, del modelo y la base para la reducciÃ³n de la dimensionalidad y la selecciÃ³n de caracterÃ­sticas que pueden mejorar la eficiencia y la eficacia de un modelo predictivo en el problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Xy8wLPtQZYw"
   },
   "source": [
    "Para tener mas aleatoridad a la hora de valorar la importancia de las caracterÃ­sticas sobre las que trabajo, voy a hacer:\n",
    "\n",
    "\n",
    "1.   Coger del dataframe x_test (62 muestras) 40 muestras con reemplazo y repestando la proporciÃ³n de sanos y no sanos.\n",
    "2.   Con ese conjunto hago \"permutation importance\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7Aa4K-kq9kJ"
   },
   "source": [
    "# Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1P7QszfOt-Q",
    "outputId": "5af599fb-04cf-4b8d-fdec-c4260282e188"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 66)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "ls08H1bRrOn9",
    "outputId": "a10f3f71-a89f-4ec2-95dd-089cad95dd42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Edad del Paciente</th>\n",
       "      <th>Sexo del Paciente</th>\n",
       "      <th>LEU</th>\n",
       "      <th>NEU</th>\n",
       "      <th>NEUp</th>\n",
       "      <th>LIN</th>\n",
       "      <th>LINp</th>\n",
       "      <th>MON</th>\n",
       "      <th>MONp</th>\n",
       "      <th>EOS</th>\n",
       "      <th>...</th>\n",
       "      <th>WBC-D</th>\n",
       "      <th>WBC-N</th>\n",
       "      <th>ASLYP</th>\n",
       "      <th>ASLYA</th>\n",
       "      <th>RELPL</th>\n",
       "      <th>RELYP</th>\n",
       "      <th>RELYA</th>\n",
       "      <th>NEUGI</th>\n",
       "      <th>NEURI</th>\n",
       "      <th>ASLPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.060</td>\n",
       "      <td>5.98</td>\n",
       "      <td>74.30</td>\n",
       "      <td>1.210</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.690</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0.140</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.060</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.080</td>\n",
       "      <td>159.30</td>\n",
       "      <td>49.60</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.862</td>\n",
       "      <td>7.67</td>\n",
       "      <td>73.30</td>\n",
       "      <td>1.434</td>\n",
       "      <td>18.52</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.036</td>\n",
       "      <td>...</td>\n",
       "      <td>9.840</td>\n",
       "      <td>9.862</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.008</td>\n",
       "      <td>11.44</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.148</td>\n",
       "      <td>147.94</td>\n",
       "      <td>52.50</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.184</td>\n",
       "      <td>17.12</td>\n",
       "      <td>65.20</td>\n",
       "      <td>2.550</td>\n",
       "      <td>9.70</td>\n",
       "      <td>0.608</td>\n",
       "      <td>18.20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>7.164</td>\n",
       "      <td>7.184</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.100</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.240</td>\n",
       "      <td>136.80</td>\n",
       "      <td>50.98</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.850</td>\n",
       "      <td>4.67</td>\n",
       "      <td>68.10</td>\n",
       "      <td>1.520</td>\n",
       "      <td>22.20</td>\n",
       "      <td>0.500</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.080</td>\n",
       "      <td>...</td>\n",
       "      <td>6.860</td>\n",
       "      <td>6.850</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.80</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.210</td>\n",
       "      <td>141.40</td>\n",
       "      <td>47.90</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.170</td>\n",
       "      <td>4.33</td>\n",
       "      <td>65.44</td>\n",
       "      <td>1.370</td>\n",
       "      <td>27.16</td>\n",
       "      <td>0.396</td>\n",
       "      <td>6.08</td>\n",
       "      <td>0.008</td>\n",
       "      <td>...</td>\n",
       "      <td>6.094</td>\n",
       "      <td>6.170</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11.84</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.146</td>\n",
       "      <td>152.26</td>\n",
       "      <td>51.58</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Edad del Paciente  Sexo del Paciente    LEU    NEU   NEUp    LIN   LINp  \\\n",
       "2                76.0                0.0  8.060   5.98  74.30  1.210  15.00   \n",
       "3                72.0                1.0  9.862   7.67  73.30  1.434  18.52   \n",
       "6                69.0                0.0  7.184  17.12  65.20  2.550   9.70   \n",
       "7                72.0                1.0  6.850   4.67  68.10  1.520  22.20   \n",
       "15               83.0                1.0  6.170   4.33  65.44  1.370  27.16   \n",
       "\n",
       "      MON   MONp    EOS  ...  WBC-D  WBC-N  ASLYP  ASLYA  RELPL  RELYP  RELYA  \\\n",
       "2   0.690   8.60  0.140  ...  8.000  8.060   0.00  0.000   6.60   1.00  0.080   \n",
       "3   0.538   6.18  0.036  ...  9.840  9.862   0.08  0.008  11.44   1.84  0.148   \n",
       "6   0.608  18.20  0.010  ...  7.164  7.184   0.40  0.100   9.40   0.90  0.240   \n",
       "7   0.500   7.30  0.080  ...  6.860  6.850   0.00  0.000  13.80   3.10  0.210   \n",
       "15  0.396   6.08  0.008  ...  6.094  6.170   0.22  0.006  11.84   1.96  0.146   \n",
       "\n",
       "     NEUGI  NEURI  ASLPL  \n",
       "2   159.30  49.60   0.00  \n",
       "3   147.94  52.50   0.88  \n",
       "6   136.80  50.98   3.90  \n",
       "7   141.40  47.90   0.00  \n",
       "15  152.26  51.58   1.18  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EkPqRC33NFTr"
   },
   "outputs": [],
   "source": [
    "#XGB = x_test.sample(n=40, replace=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8ndp6UvLdGO"
   },
   "outputs": [],
   "source": [
    "#x_test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSuWHayWDRG-"
   },
   "outputs": [],
   "source": [
    "#sss = StratifiedShuffleSplit(n_splits=1, test_size=0.625, random_state=1) #40 de 64 es el 0.625%\n",
    "#sss.split(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1f79zoLkQ9BZ"
   },
   "outputs": [],
   "source": [
    "#Oscar: we are going to call validation the new subset from X and y test\n",
    "\n",
    "#for train_index, test_index in sss.split(x_test, y_test):\n",
    "#    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#    __, X_val = x_test.loc[train_index], x_test.loc[test_index]\n",
    "#    __, y_val = y_test[train_index], y_test[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTEEPlxV6TTh"
   },
   "outputs": [],
   "source": [
    "#X_val['Revision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "chre5MHa6TTi",
    "outputId": "0389d258-edeb-4d78-8c22-432e0522f7e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.45,\n",
       "              enable_categorical=False, gamma=0.3, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.15, max_delta_step=0, max_depth=16,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=202, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Oscar train the best model with all the training features \n",
    "\n",
    "xgb_model = xgb.XGBClassifier(colsample_bytree=0.45, gamma=0.3, learning_rate=0.15,\n",
    "              max_depth=16, n_estimators=202)\n",
    "\n",
    "xgb_model.fit(x_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "xLmEMqllqMEm"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "8ODkUYeAomcV"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S18G4_7jlkjU",
    "outputId": "24dae6ff-1d10-4002-c159-0c62c5d6ffbb"
   },
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdSEd8Ec6TTj",
    "outputId": "db0809a0-57cf-45c5-d92c-1f2085f91f5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PermutationImportance(estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                              colsample_bylevel=1,\n",
       "                                              colsample_bynode=1,\n",
       "                                              colsample_bytree=0.45,\n",
       "                                              enable_categorical=False,\n",
       "                                              gamma=0.3, gpu_id=-1,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints='',\n",
       "                                              learning_rate=0.15,\n",
       "                                              max_delta_step=0, max_depth=16,\n",
       "                                              min_child_weight=1, missing=nan,\n",
       "                                              monotone_constraints='()',\n",
       "                                              n_estimators=202, n_jobs=8,\n",
       "                                              num_parallel_tree=1,\n",
       "                                              predictor='auto', random_state=0,\n",
       "                                              reg_alpha=0, reg_lambda=1,\n",
       "                                              scale_pos_weight=1, subsample=1,\n",
       "                                              tree_method='exact',\n",
       "                                              validate_parameters=1,\n",
       "                                              verbosity=None),\n",
       "                      n_iter=100)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## perform permutation importance analysis on( Validation set\n",
    "\n",
    "perm = PermutationImportance(xgb_model,n_iter = 100)\n",
    "\n",
    "perm.fit(x_test_1,y_test_1)\n",
    "\n",
    "#perm.fit(X_val.values,y_val.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KK6xAaM06TTj",
    "outputId": "2d7847a8-b12b-4162-e3cd-2ec43f46b094"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0127\n",
       "                \n",
       "                    &plusmn; 0.0408\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                MicR\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 81.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0114\n",
       "                \n",
       "                    &plusmn; 0.0394\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                LIN\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.60%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0050\n",
       "                \n",
       "                    &plusmn; 0.0284\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                VCM\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.96%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0041\n",
       "                \n",
       "                    &plusmn; 0.0260\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                LY-Y\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                MacR\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                rPL/L\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                rNe/L\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                VPM\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                PLTI\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                PLT\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                MON\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                RDW\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                CHCM\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                HCM\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                BA-D#\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Sexo del Paciente\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                HGB\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                MONp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ERBL\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ERBLp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 46 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##show weights\n",
    "\n",
    "eli5.show_weights(perm,feature_names = x_test_1.columns.to_list() )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "1SwWZtpGTgya",
    "outputId": "17bb25c7-7a94-479a-be2d-ce93dda5f07a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MicR     0.015455\n",
       "LIN      0.013636\n",
       "VCM      0.007273\n",
       "LY-Y     0.004545\n",
       "MO-WX    0.000909\n",
       "           ...   \n",
       "MacR     0.000000\n",
       "BA-D#    0.000000\n",
       "ASLPL    0.000000\n",
       "LINp    -0.010000\n",
       "MO-Y    -0.046364\n",
       "Length: 66, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = x_test_1.columns.to_list()\n",
    "\n",
    "feature_importance = perm.feature_importances_\n",
    "\n",
    "pd.Series(feature_importance, columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "59LRT5CVmRf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\ndef permutation (x_train, y_train, x_test, y_test):\\n  encoder = ce.OneHotEncoder(use_cat_names=True)\\n\\n  x_train_s = encoder.fit_transform(x_train)\\n  x_test_s = encoder.transform(x_test)\\n\\n  #Fitting the model.\\n  model = xgb.XGBClassifier(random_state=42)\\n  model.fit(x_train_s, y_train)\\n\\n  permuter = PermutationImportance(\\n      estimator = model,\\n      scoring = 'r2',\\n      n_iter = 5,\\n      random_state = 42)\\n  \\n  permuter.fit(x_test_s, y_test)\\n\\n  columns = x_test_s.columns.to_list()\\n\\n  feature_importance = permuter.feature_importances_\\n\\n  pd.Series(feature_importance, columns).sort_values(ascending=False)\\n\\n  metric = eli5.show_weights(\\n      estimator = permuter,\\n      top = None,\\n      feature_names = columns)\\n  \\n  return metric\\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "def permutation (x_train, y_train, x_test, y_test):\n",
    "  encoder = ce.OneHotEncoder(use_cat_names=True)\n",
    "\n",
    "  x_train_s = encoder.fit_transform(x_train)\n",
    "  x_test_s = encoder.transform(x_test)\n",
    "\n",
    "  #Fitting the model.\n",
    "  model = xgb.XGBClassifier(random_state=42)\n",
    "  model.fit(x_train_s, y_train)\n",
    "\n",
    "  permuter = PermutationImportance(\n",
    "      estimator = model,\n",
    "      scoring = 'r2',\n",
    "      n_iter = 5,\n",
    "      random_state = 42)\n",
    "  \n",
    "  permuter.fit(x_test_s, y_test)\n",
    "\n",
    "  columns = x_test_s.columns.to_list()\n",
    "\n",
    "  feature_importance = permuter.feature_importances_\n",
    "\n",
    "  pd.Series(feature_importance, columns).sort_values(ascending=False)\n",
    "\n",
    "  metric = eli5.show_weights(\n",
    "      estimator = permuter,\n",
    "      top = None,\n",
    "      feature_names = columns)\n",
    "  \n",
    "  return metric\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "XZOnQgS8oZzD"
   },
   "outputs": [],
   "source": [
    "#permutation(x_train1, y_train1, X_test, Y_test) #si pongo x_train, y_train, x_test e y_test funciona Â¿?Â¿?Â¿?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "j2lDeTU6zZ47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABZAAAAG4CAYAAADbmcIVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAACIWElEQVR4nO3dd5gsRdWA8ffAJYNkBMkCghGES1CCSM5gIIOAIKCCWQRFxQAqIiZMiFkRFUEFMWAARTFgDphzxvyZA/X9cWqcvsPsbM/uzM5eeH/Ps89OrKnurq6uOl1dHaUUJEmSJEmSJEnqtcSkMyBJkiRJkiRJmp8MIEuSJEmSJEmS+jKALEmSJEmSJEnqywCyJEmSJEmSJKkvA8iSJEmSJEmSpL4MIEuSJEmSJEmS+jKALEmSJEmSJEnqywCyJEnS7VRErBgRP4qIoxqvrRQRP4mIhzZeWxgRV0fEHyLijxHxzYg4NyJWre8fHxH/jYi/1L8fRMQjx5z3XSPiZ9N85o0R8a9Gvv4SEYfX934UEX/vee+iPr9RIuKM+nyDns+XiPhr4/nOEXFdRJw0KK893/t5RFwYEUs23r8uIv7R81tXTbGMx0fEDY3nP6rLvEbP575cf3ejPuvm9xFxbURs0fj8PSLifRHxp4j4v4j4eETcv/H+RjW9Tv5+FBFn1ve+0Xj9vz3L8tT6mY0j4taIeGWfZSoR8bWIWKLx2nMj4o2N50tHxDkR8d26Ln8UEa9vLF/rdShJkqTZMYAsSZJ0O1VK+QtwMvDSiFizvnw+cFMp5XKAGjS8DvgUsEUpZRVgH+A/wJaN5G4spaxYSlkReChwfkTcd04WZLDzO/mqf+9ovHdgz3un9Xz3OOD39T+llJ80P18/s2XjtU8Oka8taxoPAA4HHt7z/mk9eTtwiLR/CBzZeRIR9waW6/O582se1gN+A7yxfn4Tcnt/DdgYuAtwJfDhiLhfTxqrNLb50yNiz1LKPRvr6JM9y3Je/d7DgD8AR0TEMn3ydhfgiAHLeDlwEHAUsDJZFr8A7N74zGzWoSRJkloygCxJknQ7Vkr5MPB+4GURsStwGPDoxkfOB95QSnleKeXX9Ts/KaU8s5Ry3RRpfhG4Gbh757WIOKiOTP1jHR3afO/u9bU/1s8c1Hhvv8gRz/9XR+s+KSJWAD4A3KUxuvQuI1olnd9dngyKPhrYLCIWjjL9jlLK98hg7VYjTPYtZIC24zjgzQPy8DfgUuBe9aVzyBMCTyul/L6U8n+llJfVdF8wRRo3Ad+g/XI8DDgb+DfQL7B7PvCsiFjQ+0ZE7AHsCRxcSvl8KeU/pZQ/lVJeUUp5XcvflyRJ0ogYQJYkSbr9ezywKzmq80mllF8C1EDt/YB3D5NYRGwL3A24qT6/G/B24HHAmsA1wFV1GoKlgKuADwNrAacDb4uIzWtyrwNOKaWsRAY4P1ZK+SuwL/CLxujSX8xw2afyEOAvwLuAD7FoQHZk6rQROwPfG2GynwHuVAPzS5IjnN86IA8rAkcDX6ov7Ukud693AjvW4HpvGjuQ22fa5YiInclRz5fVNPut2yuAPwPH93lvD+BzpZSfTvdbkiRJGj8DyJIkSbdzpZQ/kKNHlycDdx2rku3BX3VeiIjz60jhv0bE2Y3P7lBf/wvwOXK06nfre4cD7y+lXFtK+TdwATmlwv2BHYAVgeeXUv5VSvkYcDXdKRj+DdwjIu5USvlDHd08jCfVfP0xIn7b8957Gu/9MSIe0XjvOOAdpZT/kqNzj6zB7lH5YkT8lRypfR3QOxfwy3ry9pwh0++MQt4T+Bbw8z6feVJE/JEM+q5IN1i7BvDLPp//JVkeVm289tuI+DtwY12G97TI23HAB2q5uxTYNyLW6vlMAZ4OPKPPFBerT5G/XrNdh5IkSWrBALIkSdLtXEQcA2wEfIRFpyj4A3ArsE7nhVLKGXUe5CuB5vQCnymldObDXRu4J9CZ7/YuwI8badwK/BRYt7730/pax4/re5AjgfcDfhwR1/eZg3c6F9R8rVJKWaPnvUMa761SSnktQESsDzwQeFv93HuBZYH9W/zef4DeQPNSZCC8aWsyaHs4sD2wQs/7j+nJ29Nb/HbTW8j5gY9n6ukrOutm7VLKQaWU79fXf0tjmzesQ5aHPzReW6Mux5PIUewDg+wRsRxwKHXdllJuBH5S87qIUso19b2Te9763RT56zXbdShJkqQWDCBLkiTdjtWRny8GHgGcAhwWEbsA1KkiPgs8eJg061zJ76Y7t+0vgA0bvxnA+uSo2F8A60dEs925QX2POsftweT0Fu8hpzyAHKE6LseS7eCrIuJXwA/IAHKbaSx+QgbjmzamEUDvKOmd5OjdZ8wmw33S/jF5M739WHRUeRsfIYO8vQ4j50b+W89v/beU8iLgH8Cjpkn7QcCdgFdGxK/q+l2Xqdft2cDTyNHxzfxtFxHrTbskkiRJGjsDyJIkSbdvFwHvKaV8vM59fAbw2sa0AWcAD4+IMzvTDNTA3cZTJRgRq5OBwm/Ul94J7B8Ru9dpIJ4I/BP4NBmg/itwRkQsVW/kdyBwWZ0j+eiIWLlOffFn4L81zV8Dq0fEyqNZDYt4GPAs8oZwnb+H1GVYfZrvvgM4ISK2i3Q3co7pywZ85/nAyRGx9izz3etEYLd6ImAYzwLuHxHnRsRqEbFSRJxOrpenDPje88ntuOyAzxwHvB64N911uyOwVUTcu/fD9UaNX6vf67z2EeBa4MqI2CYiFtQ8nhoRDx9iOSVJkjQCBpAlSZJupyLiEGAn4Mmd10oplwA/o46ILaXcAOwG7AJ8p86Z+0Fy3t6XN5K7X0T8pc6BfDNwC3lDPEop3waOqZ//LRkgPrDOefwv4CDypni/JefRfVgp5Vs13WOBH0XEn4FTazrU998O/KDOb3uXGayCqzp5rn9X1pvBbQS8opTyq8bf+8i5go8clGAp5UPAmcAbgD+RNwx8E3DxgO98DbiexnYALurJ2xeGXbhSyvdLKTfN4HvfJcvFlsCPyPmGHwLsXUr51ICvvp+c3uIR/d6MiHWB3YGX9KzbL5Bl6rh+3yNHIa/W89pDyXX7DnI9fx1YSI5O7pj1OpQkSdL0opRxXh0oSZIkSZIkSVpcOQJZkiRJkiRJktSXAWRJkiRJkiRJUl8GkCVJkiRJkiRJfY0tgBwRr4+I30TE1xuvrRYR10bEd+v/Vcf1+5IkSZIkSZKk2RnnCOQ3Avv0vHYm8NFSymbAR+tzSZIkSZIkSdI8FKWU8SUesRFwdSnlXvX5t4FdSym/jIh1gOtKKZtPl84aa6xRNtpoo7HlU5IkSZIkSZLuqL7whS/8tpSyZr/3FsxxXu5cSvklQA0irzXVByPiZOBkgA022ICbbrppjrIoSZIkSZIkSXccEfHjqd6btzfRK6VcXEpZWEpZuOaafYPfkiRJkiRJkqQxmusA8q/r1BXU/7+Z49+XJEmSJEmSJLU01wHk9wHH1cfHAe+d49+XJEmSJEmSJLU0tgByRLwduBHYPCJ+FhEnAs8H9oyI7wJ71ueSJEmSJEmSpHlobDfRK6UcOcVbu4/rNyVJkiRJkiRJozNvb6InSZIkSZIkSZosA8iSJEmSJEmSpL4MIEuSJEmSJEmS+jKALEmSJEmSJEnqywCyJEmSJEmSJKkvA8iSJEmSJEmSpL4MIEuSJEmSJEmS+jKALEmSJEmSJEnqa8GkMzCMW1711lmnseYjjxlBTiRJkiRJkiTp9s8RyJIkSZIkSZKkvgwgS5IkSZIkSZL6MoAsSZIkSZIkSerLALIkSZIkSZIkqS8DyJIkSZIkSZKkvgwgS5IkSZIkSZL6MoAsSZIkSZIkSerLALIkSZIkSZIkqS8DyJIkSZIkSZKkvgwgS5IkSZIkSZL6MoAsSZIkSZIkSerLALIkSZIkSZIkqS8DyJIkSZIkSZKkvgwgS5IkSZIkSZL6MoAsSZIkSZIkSerLALIkSZIkSZIkqS8DyJIkSZIkSZKkvgwgS5IkSZIkSZL6MoAsSZIkSZIkSerLALIkSZIkSZIkqS8DyJIkSZIkSZKkvgwgS5IkSZIkSZL6MoAsSZIkSZIkSerLALIkSZIkSZIkqS8DyJIkSZIkSZKkvgwgS5IkSZIkSZL6MoAsSZIkSZIkSerLALIkSZIkSZIkqS8DyJIkSZIkSZKkvgwgS5IkSZIkSZL6MoAsSZIkSZIkSerLALIkSZIkSZIkqS8DyJIkSZIkSZKkvgwgS5IkSZIkSZL6MoAsSZIkSZIkSerLALIkSZIkSZIkqS8DyJIkSZIkSZKkvgwgS5IkSZIkSZL6MoAsSZIkSZIkSerLALIkSZIkSZIkqS8DyJIkSZIkSZKkvgwgS5IkSZIkSZL6MoAsSZIkSZIkSerLALIkSZIkSZIkqS8DyJIkSZIkSZKkviYSQI6Ix0fENyLi6xHx9ohYdhL5kCRJkiRJkiRNbc4DyBGxLvAYYGEp5V7AksARc50PSZIkSZIkSdJgk5rCYgGwXEQsAJYHfjGhfEiSJEmSJEmSpjDnAeRSys+BC4CfAL8E/lRK+fBc50OSJEmSJEmSNNgkprBYFTgY2Bi4C7BCRBzT53MnR8RNEXHTLbfcMtfZlCRJkiRJkqQ7vElMYbEH8MNSyi2llH8DVwD37/1QKeXiUsrCUsrCNddcc84zKUmSJEmSJEl3dJMIIP8E2CEilo+IAHYHbp5APiRJkiRJkiRJA0xiDuTPApcDXwS+VvNw8VznQ5IkSZIkSZI02IJJ/Ggp5ZnAMyfx25IkSZIkSZKkdiYxhYUkSZIkSZIkaTFgAFmSJEmSJEmS1JcBZEmSJEmSJElSXwaQJUmSJEmSJEl9GUCWJEmSJEmSJPVlAFmSJEmSJEmS1JcBZEmSJEmSJElSXwaQJUmSJEmSJEl9GUCWJEmSJEmSJPVlAFmSJEmSJEmS1JcBZEmSJEmSJElSXwaQJUmSJEmSJEl9GUCWJEmSJEmSJPVlAFmSJEmSJEmS1JcBZEmSJEmSJElSXwaQJUmSJEmSJEl9GUCWJEmSJEmSJPVlAFmSJEmSJEmS1JcBZEmSJEmSJElSXwaQJUmSJEmSJEl9GUCWJEmSJEmSJPVlAFmSJEmSJEmS1JcBZEmSJEmSJElSXwaQJUmSJEmSJEl9GUCWJEmSJEmSJPVlAFmSJEmSJEmS1JcBZEmSJEmSJElSXwaQJUmSJEmSJEl9GUCWJEmSJEmSJPVlAFmSJEmSJEmS1JcBZEmSJEmSJElSXwaQJUmSJEmSJEl9GUCWJEmSJEmSJPVlAFmSJEmSJEmS1JcBZEmSJEmSJElSXwaQJUmSJEmSJEl9GUCWJEmSJEmSJPVlAFmSJEmSJEmS1JcBZEmSJEmSJElSXwaQJUmSJEmSJEl9GUCWJEmSJEmSJPVlAFmSJEmSJEmS1JcBZEmSJEmSJElSXwaQJUmSJEmSJEl9GUCWJEmSJEmSJPVlAFmSJEmSJEmS1JcBZEmSJEmSJElSXwaQJUmSJEmSJEl9LZh0Bibtlle/btZprHnqiSPIiSRJkiRJkiTNL1OOQI6IbSNi7cbzh0XEeyPiZRGx2txkT5IkSZIkSZI0KYOmsHgN8C+AiNgFeD7wZuBPwMXjz5okSZIkSZIkaZIGTWGxZCnl9/Xx4cDFpZR3A++OiC+PPWeSJEmSJEmSpIkaNAJ5yYjoBJh3Bz7WeO8OP3eyJEmSJEmSJN3eDQoEvx24PiJ+C/wd+CRARGxKTmMhSZIkSZIkSbodmzKAXEo5NyI+CqwDfLiUUupbSwCnz0XmJEmSJEmSJEmTM+UUFhGxWynlM6WUK4G1Oq+XUr4DbDSbH42IVSLi8oj4VkTcHBH3m016kiRJkiRJkqTRGzQH8gWNx+/uee/sWf7uS4EPllK2ALYEbp5lepIkSZIkSZKkERs0B3JM8bjf89Yi4k7ALsDxAKWUfwH/mml6kiRJkiRJkqTxGDQCuUzxuN/zYdwVuAV4Q0R8KSIuiYgVej8UESdHxE0RcdMtt9wyi5+TJEmSJEmSJM3EoADyXSPifRFxVeNx5/nGs/jNBcDWwKtKKfcF/gqc2fuhUsrFpZSFpZSFa6655ix+TpIkSZIkSZI0E4OmsDi48fiCnvd6nw/jZ8DPSimfrc8vp08AWZIkSZIkSZI0WVMGkEsp14/jB0spv4qIn0bE5qWUbwO7A98cx29JkiRJkiRJkmZuygByRHx10BdLKfeZxe+eDrwtIpYGfgCcMIu0JEmSJEmSJEljMGgKi1vJm+VdClwF/H1UP1pK+TKwcFTpSZIkSZIkSZJGb8qb6JVStgKOBFYkg8jnAvcEfl5K+fGc5E6SJEmSJEmSNDFTBpABSinfKqU8s5SyNTkK+c3A4+ckZ5IkSZIkSZKkiRo0hQURsS5wBPAg4A9k8PjKOciXJEmSJEmSJGnCBt1E73pgJeCdwPHA7+tbS0fEaqWU30/1XUmSJEmSJEnS4m/QCOQNyZvonQKc3Hg96ut3HWO+JEmSJEmSJEkTNmUAuZSy0RzmQ5IkSZIkSZI0zwycA7lXRGxCzol8ZCnlXuPJ0uLvN6++aFbfX+vU00aUE0mSJEmSJEmauSWm+0BErBMRj4uIzwHfIIPOR449Z5IkSZIkSZKkiZoygBwRj4iIjwHXA2sAJwG/LKU8q5TytbnKoCRJkiRJkiRpMgZNYfEK4EbgqFLKTQARUeYkV5IkSZIkSZKkiRsUQL4LcChwYUTcGXgnsNSc5EqSJEmSJEmSNHFTBpBLKb8FXgW8KiLWI2+e95uIuBm4spTy1DnKo4Bfv+r5s/r+nR955ohyIkmSJEmSJOmOYtqb6AGUUn5WSrmglLINcAjwz7HmSpIkSZIkSZI0cVOOQI6IXQZ87+NjyIskSZIkSZIkaR4ZNAfyk/u8VoAtgfWAJceSI0mSJEmSJEnSvDBoDuQDm88jYifgacAvgdPGnC9JkiRJkiRJ0oQNGoEMQETsDjydHH18Xinl2rHnSpIkSZIkSZI0cYPmQN6fHHH8J+BppZRPzVmuJEmSJEmSJEkTN2gE8lXAz4DfAU+JiEXeLKUcNMZ8SZIkSZIkSZImbFAA+YFzlgvNuV++8qxZp7HOo543gpxIkiRJkiRJmq8G3UTv+rnMiCRJkiRJkiRpflli0hmQJEmSJEmSJM1PBpAlSZIkSZIkSX3NKIAcEYPmTpYkSZIkSZIk3Q5MGUCOiBsaj9/S8/bnxpYjSZIkSZIkSdK8MGgE8gqNx/fseS/GkBdJkiRJkiRJ0jwyKIBcZvieJEmSJEmSJOl2YNBcxqtExIPIIPMqEfHg+noAK489Z5IkSZIkSZKkiRoUQL4eOKjx+MDGe58YW44kSZIkSZIkSfPClAHkUsoJc5kRSZIkSZIkSdL8MmgOZCJiyYhYo/F86Yg4OSJuHn/WJEmSJEmSJEmTNGUAOSKOAH4PfDUiro+IBwI/APYFjp6j/EmSJEmSJEmSJmTQHMhnA9uUUr4XEVsDNwJHlFKunJusSZIkSZIkSZImadAUFv8qpXwPoJTyReCHBo8lSZIkSZIk6Y5j0AjktSLiCY3nKzafl1IuHF+2JEmSJEmSJEmTNiiA/FpgpQHPJUmSJEmSJEm3Y1MGkEspz5rLjGjx97OLTpp1GuuddskIciJJkiRJkiRpFKYMIEfEy3peKsBvgY+XUm4Ya64kSZIkSZIkSRM3aAqLL/R5bTXghRHxjlLKS8aTJUmSJEmSJEnSfDBoCos39Xs9Il4NfBp4yZjyJEmSJEmSJEmaB5YY9gullL+PIyOSJEmSJEmSpPll0BQWtxERC4BjgZ+NJzuSJEmSJEmSpPli0E30/o+8cV7T34HrgVPGmSmp4/svP3jWaWxy+ntHkBNJkiRJkiTpjmfQCOR7lVJ+PGc5kSRJkiRJkiTNK4PmQL5yznIhSZIkSZIkSZp3Bo1AjjnLhTSHvvHKg2adxj0f9b4R5ESSJEmSJEma3wYFkNeNiJdN9WYp5TFjyI+0WPrCqw+c1fe3OfWqEeVEkiRJkiRJGp1BAeS/A1+Yq4xIkiRJkiRJkuaXQQHk35VS3jRnOZEkSZIkSZIkzSuDbqL3r34vRsSOEfGKMeVHkiRJkiRJkjRPTDkCuZSyQ+dxRGwFHAUcBvwQuGLsOZMkSZIkSZIkTdSUAeSIuBtwBHAk8DvgHUCUUh44R3mTJEmSJEmSJE3QoDmQvwV8EjiwlPI9gIh4/JzkSpIkSZIkSZI0cYPmQH4I8Cvg4xHx2ojYHYi5yZYkSZIkSZIkadKmDCCXUq4spRwObAFcBzweuHNEvCoi9prtD0fEkhHxpYi4erZpSZIkSZIkSZJGb9AIZABKKX8tpbytlHIAsB7wZeDMEfz2Y4GbR5COJEmSJEmSJGkMpgwgR8RujccbA5RSfl9KeQ3witn8aESsB+wPXDKbdCRJkiRJkiRJ4zNoBPIFjcfv7nnvabP83ZcAZwC3zjIdSZIkSZIkSdKYDAogxxSP+z1vLSIOAH5TSvnCNJ87OSJuioibbrnllpn+nCRJkiRJkiRphgYFkMsUj/s9H8aOwEER8SPgMmC3iHjrbX68lItLKQtLKQvXXHPNWfycJEmSJEmSJGkmFgx4764R8T5ytHHnMfX5xjP9wVLKWcBZABGxK/CkUsoxM01PkiRJkiRJkjQegwLIBzceX9DzXu9zSZIkSZIkSdLtzKAA8g9LKT8Z54+XUq4Drhvnb0iSJEmSJEmSZmbQHMjv6TyIiHePPyuSJEmSJEmSpPlk0AjkaDy+67gzImlRn774gFl9//4nXz2inEiSJEmSJOmOatAI5DLFY0mSJEmSJEnSHcCgEchbRsSfyZHIy9XH1OellHKnsedOkiRJkiRJkjQxUwaQSylLzmVGJEmSJEmSJEnzy6ARyJJuZ6577f6z+v6uj3j/iHIiSZIkSZKkxYEBZEkz9qHX7TfrNPY+8ZoR5ESSJEmSJEnjMOgmepIkSZIkSZKkOzADyJIkSZIkSZKkvpzCQtK8cvXr9511Ggc8/AMjyIkkSZIkSZIcgSxJkiRJkiRJ6ssAsiRJkiRJkiSpLwPIkiRJkiRJkqS+DCBLkiRJkiRJkvoygCxJkiRJkiRJ6ssAsiRJkiRJkiSprwWTzoAkjdsVb9hn1mk8+IQPjiAnkiRJkiRJixdHIEuSJEmSJEmS+jKALEmSJEmSJEnqywCyJEmSJEmSJKkvA8iSJEmSJEmSpL4MIEuSJEmSJEmS+jKALEmSJEmSJEnqywCyJEmSJEmSJKkvA8iSJEmSJEmSpL4WTDoDkrQ4uuyNe886jSOO/9AIciJJkiRJkjQ+jkCWJEmSJEmSJPVlAFmSJEmSJEmS1JcBZEmSJEmSJElSXwaQJUmSJEmSJEl9GUCWJEmSJEmSJPVlAFmSJEmSJEmS1JcBZEmSJEmSJElSXwsmnQFJUnrTG/ea1fePO/7DI8qJJEmSJElScgSyJEmSJEmSJKkvA8iSJEmSJEmSpL4MIEuSJEmSJEmS+jKALEmSJEmSJEnqywCyJEmSJEmSJKmvBZPOgCRpfC55896z+v5JD/vQiHIiSZIkSZIWR45AliRJkiRJkiT1ZQBZkiRJkiRJktSXU1hIklp75VtnNyUGwKOOcVoMSZIkSZIWF45AliRJkiRJkiT1ZQBZkiRJkiRJktSXAWRJkiRJkiRJUl8GkCVJkiRJkiRJfRlAliRJkiRJkiT1ZQBZkiRJkiRJktSXAWRJkiRJkiRJUl8GkCVJkiRJkiRJfRlAliRJkiRJkiT1ZQBZkiRJkiRJktSXAWRJkiRJkiRJUl8GkCVJkiRJkiRJfc15ADki1o+Ij0fEzRHxjYh47FznQZIkSZIkSZI0vQUT+M3/AE8spXwxIlYCvhAR15ZSvjmBvEiSJEmSJEmSpjDnI5BLKb8spXyxPv4/4GZg3bnOhyRJkiRJkiRpsEmMQP6fiNgIuC/w2T7vnQycDLDBBhvMbcYkSXPmxZfuPes0Hn/UhxZ5/rzLZp/mWUd8aPoPSZIkSZJ0Ozexm+hFxIrAu4HHlVL+3Pt+KeXiUsrCUsrCNddcc+4zKEmSJEmSJEl3cBMZgRwRS5HB47eVUq6YRB4kSRrGM965z6zTePZhHxxBTiRJkiRJmjtzHkCOiABeB9xcSrlwrn9fkqT54gnvnn1Q+sKHGJSWJEmSJI3PJKaw2BE4FtgtIr5c//abQD4kSZIkSZIkSQPM+QjkUsoNQMz170qSJEmSJEmShjOxm+hJkiRJkiRJkuY3A8iSJEmSJEmSpL7mfAoLSZI0PidcObsb873hQd6UT5IkSZLUZQBZkiQNtO/7DpnV9z9w0HtGkg9JkiRJ0txzCgtJkiRJkiRJUl8GkCVJkiRJkiRJfRlAliRJkiRJkiT1ZQBZkiRJkiRJktSXAWRJkiRJkiRJUl8GkCVJkiRJkiRJfRlAliRJkiRJkiT1ZQBZkiRJkiRJktSXAWRJkiRJkiRJUl8GkCVJkiRJkiRJfRlAliRJkiRJkiT1ZQBZkiRJkiRJktSXAWRJkiRJkiRJUl8GkCVJkiRJkiRJfRlAliRJkiRJkiT1tWDSGZAkSXcs+7731Fmn8YGDX73I8/3ec8as07zmkPMXTfPKc2af5oMWTWO/K58/gjTPnHUakiRJktSWI5AlSZIkSZIkSX0ZQJYkSZIkSZIk9WUAWZIkSZIkSZLUl3MgS5IkLcb2v+LCWX3//Q9+wohyIkmSJOn2yACyJEmSFrH/FRfN6vvvf/BpI8qJJEmSpElzCgtJkiRJkiRJUl+OQJYkSdJY7f/u18w6jfc/5JQR5ESSJEnSsByBLEmSJEmSJEnqywCyJEmSJEmSJKkvp7CQJEnSYmf/d79u1mm8/yEnjiAnkiRJ0u2bI5AlSZIkSZIkSX0ZQJYkSZIkSZIk9WUAWZIkSZIkSZLUlwFkSZIkSZIkSVJf3kRPkiRJAg5495tmncbVDzluBDmRJEmS5g9HIEuSJEmSJEmS+jKALEmSJEmSJEnqywCyJEmSJEmSJKkvA8iSJEmSJEmSpL4MIEuSJEmSJEmS+jKALEmSJEmSJEnqywCyJEmSJEmSJKkvA8iSJEmSJEmSpL4MIEuSJEmSJEmS+jKALEmSJEmSJEnqywCyJEmSJEmSJKkvA8iSJEmSJEmSpL4MIEuSJEmSJEmS+jKALEmSJEmSJEnqywCyJEmSJEmSJKkvA8iSJEmSJEmSpL4MIEuSJEmSJEmS+jKALEmSJEmSJEnqywCyJEmSJEmSJKmviQSQI2KfiPh2RHwvIs6cRB4kSZIkSZIkSYPNeQA5IpYEXgHsC9wDODIi7jHX+ZAkSZIkSZIkDTaJEcjbAd8rpfyglPIv4DLg4AnkQ5IkSZIkSZI0wCQCyOsCP208/1l9TZIkSZIkSZI0j0QpZW5/MOJQYO9Sykn1+bHAdqWU03s+dzJwcn26OfDtFsmvAfx2hNk1zfmf5uKQR9Oc/2kuDnk0Tbe5ac6/NBeHPJrm/E9zccijabrNTXP+pbk45NE03eamOf/SXBzyaJqTS3PDUsqa/d5YMNr8tPIzYP3G8/WAX/R+qJRyMXDxMAlHxE2llIWzy55pLk5pLg55NM35n+bikEfTdJub5vxLc3HIo2nO/zQXhzyaptvcNOdfmotDHk3TbW6a8y/NxSGPpjk/05zEFBafBzaLiI0jYmngCOB9E8iHJEmSJEmSJGmAOR+BXEr5T0ScBnwIWBJ4fSnlG3OdD0mSJEmSJEnSYJOYwoJSyjXANWNIeqgpL0zzdpHm4pBH05z/aS4OeTTN+Z2ead4x01wc8mia8z/NxSGPpjm/0zPNO2aai0MeTXN+p2ead8w0F4c8muY8THPOb6InSZIkSZIkSVo8TGIO5BmLiJh0HjQ1t48kqS2PGZIkSZK0eFisAsjAJqNOMCImMo3H7dQCGF1QICKWHEU6U6Q97wMXEbHypPOguTfqshkRy4wyPS0e9ceojak+XnWUid0Rt4vu2MZwvFhiHOmOUkSsMOk8SHNpPu+PHePqs833ZZ/v+ZMWF+5Li4/FJoAcESsC74qIu48wzZ2Ah9fHd6hCGxGbRcTdRpjefsAnImL5MoJ5USJiL+CxEbHG7HO3SLrLAJRSSqejNKJ0R3oiIiL2BZ4eESuNMM1tI2KVUaU3LhGx9ojTG+u+PcITJmvD/8rmqNI8CHhpRCw9ivTGJSJWiohlJ52P6UTE8hGxYBR13OIkInYEjqiPR1U2DwCujYhVR7iPLlvTvkMdz5tGuH12iYiLRpFWI82RB/5Gfbyoaa5Q/8/LNnJE3C0iNoiIO4+yLRMR9wHeHRFLjLqOG2G53BQ4OyK2HEV6jXQ723xkdUdEbBURjxpVeuMy6pMGzfI5ivTGJSLuExEbjTjNu0fE+iNM754Rsfko24XjEBH3Bk6oj0dVjnaNiO1GXMfdYxTp9Fi+pj22QU/zVUQsP8K0xlK+Rz2IZj7vh70iYs1RLn9EbNeJw434WLk1ZP93ROndNyI2GEVafdJebLb/OM3LxvEU/g38nNHe+G9N4LAa/BtXxTXrdMcwwmRf4B3ALhGx+QjS2we4kBxNNuuKqh6EnwY8Djg6ItadbZo13f2BV0XEpbWDdOuIts/WZIdm9dnn8n/B83OBK0op/zeKNKuHAR+KMY1sHtG63Bb4RUQcPIIsdYy18TCiEya7AzdGxEmdNGe7Pms5Ogd4YynlX7PNY03zPlFPPI2q4RgRewIXAcdExGojSG9cdfkBwBvJfej+4wguzceGSd0+HwceCSMr73sD5wGPKqX8Ybbp1TTvBnwgIpYbRXo1zXGVpZGWnYhYPyLu3An8jSj9rwGHR8SLR5AWEbEh8JD6eCQN+3rM/UxEHDuK9Gqa+wPfioi1Sim3zjKte0bEvXpem9W2qe2t95JthPdFxD1HkM9OOf838O/ZplfT3CYijoiIx0TEDiMMSK8BLAU8tHfdzlREHAh8JCKWGWEHNoCdgQ1Hkd641Pbre2FkdfttyucI0hzHfrQn8CFgs9mk05NmAE8HnhUR640gvRXIOvMZEbHZPA8i7wvsAqMLAgHbApdHxNqj6K/VNuvFEfGm0WQvg9zA9yPiXqWU/44iiDyOtmUj7VEG/fYELoyIhSNIKzrlJkY40ClycNsbR5kmsNYI0xqb2pZ5G7BpRCw1omQfC5wIIw32LgGcHxEPGEFanfL9fOCo2abXL+0RLvd2EfGaUaTVSHMk8bI25n0AudMZLKX8E7gBOKi+PoozfZ8H/lpK+c+IGsxR/98lIlZsdOZmlNeIOLVZqY5CrfBfCjyhlHJJKeXbs0xvb+C5ZIXyVWCn2eaxlPJf4LXAd4HlyE7srHaKms/nAZcCKwBvqb81inX7e2BX4JGzDYDVfF4JfKuU8un62qzKem2EUko5HfgUcOUogsiN8t45mI6iPlkDKMDza8BuVmoQ9Z0R8ZyIOHzWuaNbZiLipIh4RUQ8KSJ2mWWyfycD3Q+MiMd1fmemjb1ajt4GfKWU8pn62mzL0XJkZ/glEfEk4NgRpHkAuV9eDnywlPL72aRXrV7THuUVBvsBzwZeDFwPnA9sMcs0O/vP5hGxQ0QsNdP6KHLU00hH5NV0O4HeE4AfjCjNvcj696tkHT+rerixj/wT+Esp5e+jOmbWfXDviHhV3c93nk16EbFJTffWUZXPGrD5EPBy4Opajmbcnom0RA3sbw4cHBEvm2UeVwfuDOwUEWcDp8UsTkA1GvK/A04jT+AeMZs81nT3Idsz/wfM+Fhe1+GGwEeAj0XEwyJH8TPLbbMHcAFwEnAycDXw3Nmsy6pz9cePgI0j4v6zSazWl28F7g8sJE/snDKbdkfnu/V49lZyMMlRkSMfZ5PXvci6fU1gZFfl1TroU8DWEbHybPf3UdfxjXrz58A/RpTmSMvnGPejvckA9w+oQc+ZtrWa6jZ/OLAkcFbMciRyKeWvZH/gZuApMaKRyI22xxKjWO7qbcByEbHUCPK3BEAp5YXAO4HTY5ZXt0YOSnkqGUPYMCJePZs8NtyHDCi+PyK2GkUQubYPRn1Va2eb3GlE6e1HDvz4CNlnm5VGv+rRwMsi4rza9prxuowcLPc84D3AX2abx5rmCmQfaM3mNppNmY8ckHJifdy5GmS2fav9yLb7y0op3yil/Hs26TW8ZUTpNAVwCzDrq8kadcSbGPG0qrXu3S0iXhQRx0TENjNJp5GfHwLbxQiu9KvHyqWB10XE9rNNr415HUCOPKv10oh4e23Yr06dM7FW0kMXioi4X0Q8KiI2KKX8DPh35Oi/2VYAUQvXPsDHgFcB10SOaPjvsI3HWnkcQQY8e98bervVwrUkefB8dinlumYjYtj06vceQFbOZ5RSPgX8ie6lPDPZNqs1GpofAZYGNia3++ERcZcZ5nN7cnucWUr5CPBMYJmIeFpE3DtmOU1EKeVH5Oje+5MNnRmNRK7l8ALgUcAaEfHsmv7Q5aeR5p7AuRHRORN3JvAVZhlEbpT3fYErIuJKcsqRWY1oL6V8gNw+3yEbETMO+tZ98dnA+8mRVXvMNn+NtB8FHA28CzgY2GOWSX4PuBb4OrB6RDweZhZEjhxN9TzyqoCfR8RTZ1oP1fQiItYhA7xXAb8FHg9cV0/2zEhEbEGeJX5cKeWqWh8TEQ+fyYG55nMt4McRcdCognSRl8g/G7ihlHJjKeXZ5OjMo2eRZmf/2Zssn+eSwb8DYsjOdv38YeT+d5+Z5qlPuvsDLwIeX0p5G3lyY1ZTSNVG7UvJ9fltMpA420tKO4GlHwPL1t/o/N5sO7J3B55C7p9LA6+o62Umaa0MnBcR59b8zrp81vr9+WQQ9XHAb4AnN94ftu7YE3gdGZB9YD2hsxDYP2YQRK775OpkcPtmsh5+MvCWUsrfhk2vYdOa/lKllKvJ+ujciJjNPrkvGTx+FPAJYPeZplXSj4E3k2Vna+DUiLgkIlaPOjBimO1T22/HAN8ppXyqlPJ3oFMfzzgAWOvhqyPiseSInc/Q50q/tnmtx91nAo8opTymlPIw4HDg+Pp/JuVyL+CGyKDCVsBPgFeT5emwmGFgNboBhjPIYO+sp8iLnLZik9pe/Ql5MmKJWQY8x1HHd6a1+jM5Qm22J8dGXj7HtB/tT+7njwOeRZ7Ymu1JzI2jjvArpfwDOIU8Lp1Z207DprdtRBxS0/saWSf/FDgjIraYbRC5fv9AcqDO5RFxj5hBwCoidoo8sbE5WY42Bjaa5brcC3hDROxQX7qCDCxtVt+fST73IuukD9Vj2n7AvWIEQeRSysuAZwA3kic5tptpEDkijouIn9R0/xMjCiI32pv7AO+JiJdFxJNnmn7kiZHzgJNLKZeXUr4wonweRR4jngw8GNhlpn2MWv8+DTitlPIOYMmIWDoi1o3ZTen3d+DXkNuo8+IsBn+sRLb/Xxt5cv1xEbHSLPtWK5J18RNKKVdHDmhcNzJQPfRJ0ojYPSL2iYzJ/Q44sPa1FjkZNYN0V46IFeqyvgPYpr4+03K5c0RsHRF3JQPSh9Z1+b+r8mZSb3byU+uk88hBg7sBJ9d6dEZKKbcAewL3jVmORK7Hyn+RJ9z+t4yRJ/RGdlVm07wOIAM/Ay4GvglsRQZpdouIw2DGI/Q2IoOo50fEp8izhzvMIj0a370XeWA6GXh0zf9nY8gRQZGXY765lLIreUb3bY33/pdWDHF2uxau/wL/qn+QZ8lppDds0OZOwCmllI/V5zeTlxxBLcDRMhhSG6/fBF4eEfcupfyKrPy/DHwRuCtZGczksrClgT8Af6mV5xvJAOXa9Te2q3kYphF6z4g4pfO8lPIT8hLvbckO6FAiL+k9AHhYKeVNwBPIsv6smv7QwYbaUD6fDMb/oKbzr1LK48ltNaMgcqMxsh1wKtl5fxs5gvbRMeSclPXg9IDoBt4/CbwbeAQ5EnmokWWRNgKuAV5USnkN2VBewOguPVqbrEfuBvwNeHatqNccIp8LIwOIlFJ+Q04TsA/wfWCjiHhMfa9VvdQoH3sBjymlPI8MBqwDPKFTd8zgQB+llF8Cr4yIj5MH+TcDf4qc0mKoS1Qby7IkGYS+oXGAvgA4Hbgg8tLA1mod9xuy3LwhIvbrLO9MGvM1P6uQdcfLgVsj4uH1rb+RDZQZqdt0C/JYcXApZXdytNb+wAb1t9ts8xXIzvkbyTrtlKgBhmiMLhr2uBY5d+VdgNNLKTfUl79AXjre/Fzry+Jqg/P35DHjIrK83wl4SMwwMF0biu+JDCw9iVwH/zvmdBr1bZc/MiixSn28kKxD3lJKeVEp5TzgbOAxwxx7a1qbAbeSI3Y2iIhn1Pzd2lyHbffNWsetSF4ufX0p5WOllF+Q9TARsUpELDlMp6bWRc8n1+GSZEdms0YQ+YCYwXQWJUcJv5k8lm9LntjaPnIkxwOHTa/WN1+JiI+RAwy2Aq4DHgqcExEPmUGa25AnNc4opdxIBv6Wru8Ne9y9X3QvkX4Pefx9QSnlWLKtcQ1Zv92/7faJHBH8AvJYWyLiebVMH0F39PBM/ZMMxi5NtkEeQAaVTouIEyNirchO3sC81jK5BrmtL6/1+lKRo9k/TAZwXhARW8+gs/034J5kYG5X4NPkyNFlycDV4ZFzI7cWEfcl20dPKqVcS14Ncaf63kyPF5uS6/Kp5InBR5DH40NmkebI6/iaz89GxFPIkwYfJ6/26/1c23pz5OVzTPvRumSw5sklr/D7DbB+RCwTMwwqRV51+GTgabFoEPkR5ICns4dIK+px8hpyYMaLIuISYEWyzH8OeFJEbDSb/mrkqP2zyKDNd8mBKzt38tAyjXXJkebPIAc6nU62XbaeSZ4a/ktOh3F6RLygbqc/kid5hh48FotejffJmsbfyP1yRkHkiNg+ctqoTj7+ALyBbM99OCK2HTaIXNsvbwE+GhGfrfn8T0QsmGndUdPtXAm9kBwdfwHwWXJbvXSGaa8A/LKUcn39jVGNYl+XPE7sTR6Dz6npt+5XNfyGjCn8te5TZ5Oj+a8jR/MPNbVQ5EnB5Wu85Otke4OIODMizooM/g8dnyg5TeXLySvy/kJe5fn+iDho2GNaI82/kIHu7euynw9cQh6bXlz3iVYig4/rklPpXEzu86uRx9xtqXHEYU+QRl5J8lzyPignk/vjZjWt/wzb7qoOIafYeB/ZP1+VbLdu0snfkG3itRr52QJ4CfDiUsq5ZNm8kZwKdsUh6s0HkNOuHRkRO5dSflvzvV5EvLZt3nrS3DLyxPVaZKzn1Pr608n96ZV1W41WKWVe/pFn7HtfW488C/9a4Igh09sd2LXntfsBx5JnVB7eeD1apnlX8izEisAqZIX3UWDlxmfeTnbCh13+lwIH1McfJg+ASzXev6JtuuSoivXq4wuA9zbeW7rx+PHABjPZVmTA+ATg/Y3XTyQr7AUt0lhIjsD8Djlq4STgZcArgJXIxs0lZHB2yZb52gS4c328F3np+bfIEY+dzzyXDBAMs7xBniV9M3Biz3sbkJXK44dIrzO36unNsl+32w3AswbtF1OkuVVd1m17Xn9Q4/HLyKDQnVqmuXHn++RUE+8lA4DN33wrsMMQy37nut/8Bngl2ei+EzkCbCGwYy0Tx86gXF5ANo7Xqs+vruvzIrKDtzawTMs8dvafA8lA9PnkCMqrG597BNlhGriNavlZm+7JnPPJDtHa5FnjPcmD3yuApwyxvJv0eW1p8qTWy8gOw1KdPAyR7oL6/8nkwekAsj69hGyIbj3kdumk1zlptH59fidyNNgqwJFkY2fa7VO/e09y+pw16vOHkoGF/Xv2qQOp9WqLNPch669dahk4qpbRj9GoQ4dY7nXrdl6HDNCdX8vnIY3PvAZ4Q8v0DiDryk+RJ1fvSwYUXwFs1fjcacA5Q+RzI3LfvmfPuns9GWzpfO4Qso5vU97vRF4e/8hm+SOv2nhhzfcWQ67PDcmA5M7kybvXkPv3v8lRw2fXZblL23IJXEYGUVeqr30N+GzjMyuQddy6Q+RzX3L03PpkAP5+ZMf9GT2fOwLYo2WanfW3M3ncPLmxjX5LBls+X9fLli3Suzc5UnLH+vwuZJ2xaeMzq5FtpRfOoOwfRl6ud05dhy+vz/caMp1lyGPP22rZv4TcR99D1k/nkMeTVvt4TXP9mr97N147khzJsSS1vUFtS7RI767A2+rjVcn984RaXr9HBkHPIOu+FYdI87L6eG1y//xk3c6d+rRV26DFbz2SHPxwWE3/SrJdO207rn7/OPIE9R6dfDXW4buAY4bMT6f+WUgGah5M1venkkG1L5InZ543RB7vSrb979Z47Ul1my/R+M21h0hzDbKDeWh9fn+yvr+s5m3HYbcRY6jjyXbxvcg2xvFksPLz5Mm9Z5Nt77sDKwyRz5GXz3HsRzWtTp9gibqcXwXWbLy/C33aUlOkdS8y8H4AeWLsf22s+v6y5DHksCGX/WByxPHjyGPZpeQ0Ra8n2x+XMsQxqCfte5KByhc3Xnsk8A1glRbfj7o9rqDbR92EHIj1BrJuvg9DtDF70l+GHNhzIHlS4jW13P8QeOKQaR1I1g9nkX29p9JoU5Inm68D3jpEmpuSJ92+QQardiUHpny+lv3jyP7M/YbM6/PJExuQU7p9rs9nHkNtL7dIbwNgnfp4LbIf9brGOt6cvMx/uyHyeKf6f2XgAyxaf3bq+L1o0Qckryzerz4+ANiSDFJ+Gfho43NPIvfzYfosS5JxgxeTQc/f1bJ5NNmuv5qeeNA06XUC2ucBT6xpPL2uh4uA7Wse9xsizdUaj1eqaT+wPn89uf/fWMvsai3TbB679qj74u/JKxj2Jds6Z5MDjNqktzFZl6/TyOf6ZCzlWjLGcEX9zIPbbiMylndVLSsHkMec99V96HGNsjSjNk3N493JPvrHyH7WO+t6aNXmrOvy/dS6gdzvbyCPa51j2t3I+mPaPgbdNvsZZDvmKvI4dm7dxhuTV4efM+Sy7gr8iry6vDOn/1lkXPIisg+0F1n/zahOnvK3R5nYOP7IDlenMC1LdvKOIw+gDx0inceTw/mhETStz3ckR5M9aoj0tiAPIKfQrVT3JCvpoxufO5MhDnqNnX8vcsqFzusfoVv5X0WO8GiT3j51J3pAZ9nJgPSFPZ87jhytuOY06e0O7DnFexuTN36DbJzfCNxnmvR2IoOxG5GV8AXk6NPtyc7hP4BH18/uTftO3L5kEPIsugGqnerOfwi1cVzz+QbaB6oOJM/irkh2sF5D7bz3lKdL2+ysZOX5dXLUzzp93r87WUEN1WknT2y8sj7uVHYvIDta1zQ+93xgwyHS/CPdDtLBZMX82MZnLulsrxbprV7/H00egB5ft9nJZIDl0sY6/zI1qDNNmkHjoENWzj8mpzD5MNlpOoE8ELyexsmeAWkurPm6ELiJDHDenex4ndnYf75Jo0HVIt39yE7RJ+v3P0IelJ9V3z+87g+rTpPOkmRQ5nfAcxqvd4LFnSDyS4Dn0OjgTJPuFtT6gDwgf6Kuz9PIwNWvGf7kyxpkILGz7S8iR650gvyd+u+RZLB22rySddz3yMbwzxtpP4QMinU6OafU9zdtkeZ+ZL25b2f/IBuLR9b18IhmmWuR3uZkfXgWsE997V51+76A2tkgjyGvnW65a/6+WMvmo2vaC8nO9dlkgGFN4NBa/qcN8tNt4GxWt8thnfJT/59DrYfIffarwGZDbPv7k4GlR/Z5/flkkGXa/YduB/a9wFE97x1KBr8OJDthl5GN0mVb5vGuZEP2uY3Xvk4ek1YnO7I/oAbXW6S3P9nY3rNnXd6PPEY8oz4/hmzo373tdmo835ocQXgNWcetQTb0n1C3WauTwjWN1zaeX0d2Di6ge+JweVoGVxrprEkeJw8ij7enknXAm4ZM525kgGsD8iTM62taO9ftdhFZR99ay9nAAFijHL2nWdbJ+nQ3Fj05egLZYV6+ZRn6EjVwT3aMv0wG9g9pfG7lIZb9rjWNTpqr1/JzfifPw6zLKX5jyWbaPeX1Nm2TQeWybufvA7v1pP066km9lnnq1Emd48JuZJ3+kEZ53J48rk2779TvrEG2Bx5any9T/+8KvKtnm7+1zTZvfOcp5EnV5RuvLUfWbS+uv9F2EMA46vjVyYDKoY3XliDbsl8n29jvIfsYV9O+rTDy8jmO/WiK33kPcNf6+GFke2zaIF1dVz+r+VyKbIe8kuzzNQfmnEP7oEVzHzqKbINsSdZJW5EnW68ng1lrD7sf1cebkINfrm6WGTLAsu0QaR5PBrnu0/P6eTWt1gMLyBPBHycDz0tRr4Ko+85RZBDxg2S9vmWL9Dr1xcuBnerjA+rz3iD/CmTdPu36BJar/19A7puPIfvNx5F121Pq+48nA97LMk37kG4dd49aVpZvlMvPNz73cfLK5DbrsxOfOJVuP+A0cprJXRufu5TGoKIW5f0isp+/fN3GT6DnBFtdJxcwfRv2TrUc3ki2NVao2/9dZJ9gU/Kk+heBe7TM45b1f6fPu14tWw9m0X7hxfQM/pom3aeSbcrVybr3zjWNPYB3N8r9c1umtw/Zttqb7jH2ubUM3YcMzB5Atjc/QO0ftdg+byHbqs8iT16uQuNEYyOf57csk5uSddphze1c038Mua+uQ568X69FHjvpbkEOUDis8d5SdX2+nAzStx0ouEhMqmc7v5g8Pq5K7l/ntcln4/t3Jvt7F9Xn65P9zNeSddMmZNB32j5lz3KeQdYhR5PH+deTcahPke3Xs4dI7yBqjLFukx3J/eowsl10P/KY9Pq267T1b48ysVlnJjuSR5Gdqa173rsf2Rlcvm7UI2nRqG18/1Tgqp5CvB3djvsDyE7Nykxf4a9DNmRuM5KCPHv9w1pwH1QL174t8rdEz/M7kx3kUxqvXUuOWHz7VN/rSeMBZFBrj57X70M2Hj5IBuvOIA/M03aKybNDnUD8kizaMFmPbNycR3baB1b6dIOnp5Kj85YkOwNvpBuY2xXYfMhydAAZ3NiBGkxqvPdA8mB1EDl67os0Rh5Nk+6e5GiCTgBoBbJyeg2LBpROIg/MA3fWWtY+BOzc3JZ9ysK9yYPIGi3y2GksHAp8oPH63YFn1sfX0XMCYYh1uy8ZQDm08fwDtbxvU8v7A1qks38t38fW548nG8cPJgPT55AHw04wcNrRMD1l8aHUhi15id2t9ATKe8vGNGm/nBx18ODGttuL3CevITuNbfafXclO1RFkUHEnspP0UPIAdznZiFiZPEC1CZp3GiCbkB3Jp/W+1ygT57RZbrJxdz7ZSOoEkTuNsmvJQOxB5EFv7yHL0IFkA2lFcn98Y93+nU7csWSAf9oRqbX8fYbumfvXkHXIKvX5QWSH8/VkXbhlizRXpc6B2qdcrUgeo15K+ytANicb80f3vL4UWe+dT9ab59ZlOWia9Nasn28G+84lp2uBHGHUCWT8hvb1210bj08kg5ErNF7bmQz0Hk2L+r2x7JvRHcGwAxns7w0i70IGB6et4xrfeRjZgb9n47Vla3larvHawPJOTwCCDNBcw6JB5K+RneVzqPX1NGkuQXY2bqV7Qmhj8ph7VzKocr+6/3yirpOBJ1v7/MYjgKfWxwvJDuZpPZ8ZOHqSDD4/l+6x58NkA/kF5D74SLLx+V2yI9GmHr4P2Sg+oVmm6nsvqetxX/IY+dghlnd7sh5+BtkG25jcr59J48Ry/e0Nh0j3uD7laCXq8ZOsjz4zaD+qy/xkMsi9Gtmx7rQtVyNPrD6pPl+GDF5P186cMs36/prk8eKVTHPif5rf+V87juxwLkO2i5q/1eYk2SLLVNfr9+mORD6m7kfTntCgZ8RVTbtz/NmVDIQMfVVSI70nk/Vjs564CzVgU/P+2UHbvPG9+wKHN56/mezENzvcy9Wy+7zmbw5Icyx1fGPZP9ez7KuTI7VWoJ5sY5pRVeMon+PYjwb8VqfO+zjZHj2srpc27bj9yDph1872rf/3ItvCzyeP74fWfantiObefejh5LFhr548TxtQqp/bjEWvBOh8f0MyCHIO2fa8LxmUHliOyOPM/4JJ5CjMt/ZuXzI49CZaDsyp33kNeex+Ti2PR5HBxKXJ+v5UcqTdtCOv+61vprgab4j87UteFdc5GfxqMlC6PRm4eTfZZ+mckFplyPQX1Lw9v/HaFWSA9RrqaPxOORmQzsbklaVH93mvU55OIPuV36BedTRN3vahe4KpM/hqu1q2zwDuW197WE2z7cm8k8j2+Zsarx1Sy8CHyBNZbduva5MnF99DthH6Dm6gexy6a4s0tyD7A0eQMZNtyH7EQjLOsS4Z7Hxr3U5tjhedwSn70HMsrGn8g0VPkLUZRLM/2S8/guxTva2Wz4dw2xO7X2SamAqL9gVO4rZ9ga1oEeNoke61PekuXZflDbQfJf04po5JdYKzw4xeX5+sfzqxlDXJk4qv7iwDOdjre2RMctcWaXZim8dTB8mQJyJeSh2tX39377rsrWNe5H54Mdln+x55wuRAMrawB3k1x4dp0fcd9m+kic0qI1lovl8X9qq6YV5V31uPHNm7X+Pz057FJ0e1bl0fr07eEKgTbFlIBkH2anx+2oZd/dxO1LNO9fk+ZBDgOWQQaEsyiPwG6pmJQQWY7uiMIDvcG9bndyMrw+0an20GlPuug5rOEmQl+tj62qq1oJ1GBraXJRtqzyIbO20r/H6B+G2B7evjT5AV7MDgD3nQ/U7ne43Xl6J72d9ZMyhHK5MBzV16Xj+DnP4iyEDI18gDXdszm3uTlf62jbK1P3nQP5Rs2F5KjnL8Eu0aoauTnfS+lQWNypmeUfNTfH5rupcIr0CezXpC4/3Ome1jyM5Im6lFNqufvRt1JCzZSP4e3VFb+5MnXz5Md3+b8sBC98TBLjQag+SB+FV0L2tapVmmhygDp9b0N2u89nwyCLJhyzR6R/ltQx6ovsWiZ/CXJA96q7RIc2/yxMa55Nn788jRUAfX/HZGaw0T2N6TnCbn6WQn4C7AL3v3HfKA8ghaTldSv7N9XW8vpxtE3pQchf0ecjTYA5lB8II8sN9MnhB8ABlY+gHZqfkK03dkopbxb9E9sG9EziF2KXks6Uxf8VBydPZWLfO2Btmp7DSUe0/orE02wF9CuxHs51EvTWy89giy8XRvss56KdkImPZSV7LjfCjZUX1Mfe18GmetyQDDObQfKbsRGUR7bmNbvxb4cOMz9ycDol+h3UjZfcg6/lKyTty8vr4t/YPI044SZpoOLHni49Ms2gAfdOxdkRy1+pie1zciO23PbLz2CeB9LdPtBGEeSl7d9PC6vR/b+MwCsg78EEM27mr5+wqNjjI58uBaMujSdmqEjcgTis+iezy/HPgFix5/1qXFZZTkfv118iTYVWRw60Hkvnpn8sTD9eQIo5WYZjRI7zquZeeFNb/rkIGQ15HtxmGCaNOVo1XqermYDNL1bSdQAz7kMeeV5EnRG8jR5Jc1Pnc0uX+1CX60SrN+dq2a77YBpWkHadTHLwaObLke9+t5rRk4fRBZz19Ado7v1bIMXUpjgAbdwNdmZBtxZ7IuGuYqxH6B3ssbZWANcqqOZ9e8TjcAImoZvpa8GucMsj2wMXlsOKYn78sOsZ1GWse3WPY71WXftrl8c1U+x7EfTfE7zZMlq9X/Z5J10vUt1+U9yP7dKfX5BuTxbSHZFuwMgvkQecwYWOaZfh96MDXgNN226ZP2AXU/6Qx6WbJRHu9GBm1vJI/1iwSp+2yfpeo2+RUZnFq2rosLqCe9WXRk77TtQrIO34LutCJbk23Ob5PHxnNYdJTidFeVjOtqvAPIPuNeLHrMfQM5KrfTz99wmG3UKIud/8uTQeMjG595H4tOlTfdlGEnABc3nt+X7rQL65Mnx/5B7v93H5Rm3e5rkcfATv9kGbLtshJZ172RPFZeTfYNpizvveukpn1fsq31qsbrnauGh5lGZxVyyoG3k+3rH5HHuk6AbmNywNy3aLef36mW7VfW9XAiORK5s98fQZ2qspbjaftW9AxO6VM+T6Q72nVJ6vSgg9Znzed7aQwUJE9YPp7sT29OBkEfUcvwwGWnXV9gc/IkxTBXQUybbmMf3btt2kw9OHS7WrZuoP1+vmpdR7+u5fpEMk5zJzKu9JL6uQ3Jkz2XTFW2G6/3xjbfRR0BTp7Iuphsl3Vik23iMp1BGg+r+duerKOOrO/vTh53O9PLtj6RN8zfyBOcUSYyon8z3ZGYy9UC+t7GBttq0EbqSa8z+ucy8izx28nK8pfAgfUzp9AzwqxN2vVza5KNg+eQgZR3kpX8M8kg2kp1A36HbpBtqsK1RCPP15Od2V+SFV+QO/1tggoMHnnc6bweQzZu9yMPSu8gz7BfyqLz6k43EmYjpg/Ed87Knsb0FVRnTuPOKOOlm8tEdyTye6gjrIYoS6uTFfTmjdfOIiuu19NtjG9P3i24TZor1W38+sZvfJZucH5Z8sB8Lnmp1XQdj03pjpB8Y2PdNhu3m9V12XoOILrBgGeSQal9yY5CcyqUo8gGY5vRnUuQDa1bazn6EtmA37muvx82tvs+5FnPR06T5sr0GXXdeP/xZEDgQbS8dJRFg9CdeYo6o1mbDdqXkMGN6UaG956xPQfYpj4/jgx+bUXumy9umcc9yDl5d6nPd6jbYWF9/iDyzHDrud3rOv8cGYx5Ljn6Yb26Dn5DDSKTB8Hf0G56gK2ol/zV55uTAZuLyA72vclA1Y5kUKzVSbcpfmt/st7vzDe7LXlgHqZRsj3Z2Xg62QF+XH39UeRo7A3q89aXIdfPX0k9VtTnnY72lmTQfjnaNRiD3MdPaDw/iGxoP42sRzYlrxB4Ltlg3XK6sll//8FkcP+T1AZUz2dbzd1ZP7sReby9vpaXU2tZupA6qpVs2L2BdiOPO1dr7ETWj+eQwZBOQ3n7uu1bTe9Eiw5sY92cTXYUpjuurVbTeFgt371TEW1Uy9Ahjdd+SD0ODEh3P/JY27l64mDgP3SPH83RlEvQcnqNxneXIUd3ddovSzeW/f5kW2SVIdLcgDriupGvD5MnRac9cdlIZ2+yPtqx8drDyYD+gbXMblRffy7trq7o5Kd5JcV2LBpE3oA8Pj9puvy2LEeddsibyLplypMl3HYE0fJksP0IcoqBCxvvvYB2l3lOl+YFPe+3nRKhzSCNzkm3U3rzMUV636zboXNyqFMOdwDOq4+Pr+uxTae9c3J51z7r4YHkSfEt6/OdaDFSh5aB3vrZK8kTmW3quOY+91Gy7fUEcmTVeXU9d0amth7tyAjr+CGX/YVk+2u6enPk5XNM+9F0J0veTta/x5BTs7UdRHMfMqh0MhlQvI6eKz/q59ZgmjpuiH3oFLJ92LZN3Jx3/FCy7dkZmLGAbp9rW7K9fTYD+kN068SNyaDUh2q53JcMgDQDlm2DNfuTfbXryBF919Ad5HIyGaC6jjyZ3+nTTlc2x3E13npkO227xj7V7CNcQvYtW0/tRAbJd+t5rbO99iDnVr5N27rlvrQ7eWJgn7ptL6tl5+3koLIl6F5F1gmuThWfWFD/3lufr0K2ta8mTzJ3+vDLk33gKafb61lnJ5P70KPq840aZepBZDuzdbuoke5udVlXpzsdxjfJGMCO5An9Kct5n/Q602q+iJ42FRn7eNmQ+ZtucMq9yHp64FWIfdJ9CznIKRr7wDJ1+TvTpG1Bu3pzI6bpC9TPvZCW83G3SLfVtJc9aQ2KSf2C7gmPixnuPijPIK/GOYcMGr+urscjyNHyz62fvTsZ87hgwP4zVWzz/cDz6mvPIPuInfuPTFfHNQdpXFOX9eBmWSL38YHTlIzib6yJt9hYnQPlVvRvHN2D7Ijdtfn5NoWg/l+x/t+BDARdSo70ap5lb9v4XocM6t2/Pt+XesMjMqiwTP17G90h6geRU10MDDSQDbqL6F6a9SO6ZxJ2JivrtiMX9iMPGKvUnewssvH+MrKCWYZs9Ly8dzv0SWuoQHzL/G1UC/7zacwx2FMeNicDSVvTcqQBtw3Kdi6pWYruqOEdyIp2mKlP1icrlZ3JhutzyZFfredP6klvVTKQ8oK6Lc4iA7Mr9HzumJrX1mdg6/c2JCuVs8hG1J5kB/5aMpj8DdqNAlqdHM26Vi3nZ5JnXx9DNuzOJQ/UfyMDB0EGCd7K4EbEwFHX9TOPITsN046iIzsZz6C7r9+J3AdXqHnqNMrWrf9bj5YlDxifoTsi5mH19ePq+ryBdlMibFD3m2uBdzRev5zGzZ7IEXE3kB2+NsGvWxv74fpkXdmZWmQz8sTOdeQBbLq5yKOm8WdydMJzyRFPa9Yy9EQaI27JA3+rOmma392PHBEwzNQFvdMibEc2Ei/v+dw76c793vbYsUT9O4dsIN2t5/1HkPvlwMYt2dFapT4+nWzEdAKKa1KD5OQlzZ3RQdvUsnybMkqjoUa3nlyebDh8iMZNOxnisrK6Hjuds13JffthZL3+cbIeuZDuaK02c8AuUctic+TY1uQxaEO6++J9yU7MwDm+O2k21ut0HdjDmaaTQDamv0M2Aleu33ktjamI6ufO4rZTQG08IN19yePD4SzaYT2AvOz+fzd1HKJM3uZzZKP1NBY9QdY5sTFwtAE5cvGUntc2JNsZz2689vnmeh2UP7Ie/hNwfH2tuewnksHazo1Il2pZjtYg20Kdstdc1u3J/fMZZF20Hu3m6R2mHB3GFCfd6I78+QF99j2yzbAV2da5uPNai/XYNs3XtCk7jTRaD9Jomd4uZLvyNjeKIvf1X7DoiMk2U5+sTh6vOnOWNgdXdE6adI5vw9RxbQK9ncDV8bQIBJF9k2PpHg8PJa9QOrSm+6la5p80RD5HXse3XPZO2+lopmlvk+2q74+yfA6RZqv9qH5mmJMlKzH9vV96R052AkvfAV7Q896utDumDbsPtb3Z9T3IttrFdI+1Dybbds325p5k4HPXun7OoM+xgzxOH0z3ZPyxZJDvQWQ74ZVkW7R1MI3sM3yBPCm0AnlV11vJuq8zoKAzTcBPpyuXjeUZ+dV45LHiWvJEY9/9juxzvoL2wfPTyYEoO03xe5fRHVwy7AC39cm2+4fJE2K7kTGG+5MBsc7+/kiyv7F8v7TJtvkl9fHVdXv9hIx5nEL2uX/P8DeIPJRsWxxKnpA/u76+FjnQrdWVAPU7q9PY18jjxPlkIPbeNb9HkQG7F9DuhMFW3HYQzQVkO2GtxutLk/vZmm23Tf3elfQfnHJfMsh9MC3uLUL2F+5PtqfeD5zReK/Tpt+feu+sFukN2xdoe9+oodKdJq1hB4cuSbspo5Zu7BdLkifUnkO2C1cir9Z/GnlM/ycZW1mS7EfcZsAT7WObd6ll9mxa3N+L/oM0TiRjPJ2rQDrHzgsZItY1k7+xJdyyYHUuiV+LPAO5ac/7K5KVySFDpLkGeebxNoWR7CQ9nhx10vru32SH6wvkmcZvkR3h23y/VgBfpBGgY4qGc93ozekFHkVWHB+jeyfWLciD1hPJxsB0l640O6/NsxG9N6g6hWxUDezEMWQgnhaVKFmxv4882J9HY3L7RsF/FnDwMOWIRYOyTyWDsiv2fO4hZIep7R1N70wG9h9Xl28nssK6gkYAiRxlNbCjQKMRULfTeXRHiL66lptdyLOmx5InHtoEevsFAzYiDyids8PL1t/cjnZnIJep2+CFZAW3IdnQfALZOFmJPAnxbLJTunvje1OV9zajrregBuZp1wDv3LxyRbLBfVJdvx8Hzm187pj6m9Pe0KLxnQeSB6hOkPJYcv8/tv7GarQc5dco8/es6/SK+v999AQie8vsNOnuT54Q6KyHt5L7dmc/ult9f6sh0nwUeQb8RLKeeyv1pptk3fTytss9xG8eTO6v09YhTD0twlY0pkUgO8M3tyzvG3PbeXDvQu7rLyTr01XJ/fybtBtJtwcZUFuV7mX2D2fRuVq3Jw/82zT3vZ50mkGlxzVfr/87o9ReSmO0Tcv1vnot05+lG9B+EHVO3Jrfj5CdwzNbprmwlrt1yLr22fX1V5KXlX6A7BCeW7dZm2BA2w7sy1vmcQtyRF/viOPDyKBi5yqVbchR1J1ROoOm5ekEUW+gG6TrnFTu5HtPssP14CG2UXPUzpa1LC0gR9K8lTwmL0t2xq5nmtH7NZ+HkycTT+x5bwPyqohmR6TVDfjqZ8+mcQkri06B8UGGaMc1vteZL73TVmwGkbckj89nDNo2MyhHF7XZd+r/7ei5MWTPct+P7NC2uQnOMGm+gHYdjqEHadCuHXci3SsT/jeavv5fq7EPLNnMxzRprlP3n76jheiO5h0meNw20HtG2zRrOk8k20TvI9uJ9yADV52y9VDy5Mc3aHdflU4Q9XF9tt2M6vghlv3JLdO7O3VAxgjL5zBptt2PRnqypKeMN0+M3YcMID2J2iYgg1Xfo91N+MaxD21OBuceU/N2Ld2ReQ8h54hdSHeAweGNddY32FDL+puo7XYyAP8WulMtdqYj/CztpnK7D1nP7tJcvvr4zTRu3kj7+4CM42q8tclj7epku6VT/yygu2/el+7UH21uwncEGfRbgTwWfZ/uCbNm2XoJ2UZpM1/8pmT78u50jyHLcdtBSduQJ5Du0nht5SnS3Ltuz30br+1FHo8XNLbP8xiur35/sv/TGQ2/Sf2dp0+Xpz5p7Ve3+TtZtL/3BHIf/CHdoOIK05VN2g2ieTmN+AHDHYumG5xyci3/bQKe+5Ixqa0a5fDL1EFOjc89kRwYMfC4zhj6AjNId9pjMMPFpNqeZL0HeRy/luzznlxffyr1njqNz96TdvNct41tHtoyj20GafyaIUaEj+Jvzn6ozwrZi+xs7F2fX05ettE7pP8CGmdNW6bd2+loXuK5LnnziRfRbhTMumTQ4Ij6fJVa+F9BN+K/Enlw/lonrww4a0ie8TuKPCCfWl87izxb1rwZ24fJztESDBihR//O67J1udeje/ZnafKs45eYfpqFkQfiG98/q67TF5IV9IMb7x1e89dmFEiboOzOZOV6Qk231WVqNY3O5W0vqettAVlhvZismJcmJ/z/ItPP2drbQOwsZ2fU+RPIyupDZEO3TSU1KBiwIRkAbdU56JP2juQo8c5lwhuRHaZzWHSer06DZdDBaZhR15fSbr/sjGDo3CDkJDKgshfZYft6fX5R/dy0I3B7nu9HBrrOa7x2NNnZPnLQ8k6R/tlkcGZ9srH3N7oN+6Ev1Wqkuy85t/NFNE5sNMpbq2kMWPSE0xlk3bweWVftW/enb5IN3lmPPO7z+21Gm7eZFuFb5OVGn6JdoHcZsuFwNj0jUsg69UyycfFBsiEw7Umdxvf3IUcYrVDX4etrfh9S//43r+FU5YnBQaXmPInHkid0Wp0c63yfPJ69jKwrjiFHyj6a7mXiW5Nn3ttc0t1p1HZODt2lrrvr67rrdMAOJuu7DVvmc5gO7MATTzVP36J7nFhAXrGxNRmo35fsLL6fbJC3bnuQJ8MurmmtRY5geH/dZ84h6+uHksf5Faba5lOkfXrdRhfUZQ/yZM/ba/4/zfR13IFkg31FMlj+Gm4bRN+RrIOHmbqiWXc8lax779Eso+RVIbu0TbNPufo+jfZc/b8NOZKs7Q26RlKOyGPDR+mevFpIdlgf1fO5h9Zy3qZDOPI06+dHPkijfu8ptZw0t33Uvy2br7VIaz26dfil1Om1WHS+1nszg6u+GHGgt1nmyQDTheRxcS+yo96cE3Fb2o2cHBREnXEdP8plp3vTuGb5/O4IyvzI0mR8J0sGXQmxA9mHeQI5ddynaH9flZHtQ/VzG5F1Rqevuh7Zr34k3QD3wWSw5p/UfZ52J9+2II9BvyMHLpxN1iedwUmb0XI+e7K//G6y39IJjnduPLcp2dZqPcc1I74ar5HGy6g3oqvpXdvncw8nYwltToS/ijxOv5E8Zt+ZjAN8l8aNx8l+/3PJKx3bzCN9fF3+F5IDwxay6A0ylyHbzl+hxdQI5HHwH3Qvqb8rGfjujc0cUdPcdEBavf2qg8n21avojo7fmDzutr7nEdm2vqGmt1UtS82bsV0OvLJt+e5Je9Agmo+SQeSVW6Y1jsEp+5D1TOfExRrkvn8QWZc/jRx1flItW23a7iPtC4wjXcYzOHQLsk/5cHJAwuF1H3pxff+pZN96N3quLugt243Xh45tTpVWn7RHPkhjNn9z9kN9VsTpZCV1LRkQuBvZYXssNXhGNpi+TYu7ZfZJf6pOxw7k2fxVWqazB90bi3QauSuRjYXXkI3cu5MV4rSFoZGPFcng41vIwNRS5EHlxeQogSuANw6xvFN1Xr9LNhq3Iiue62gZBGFEgXjyAL9i4/lKZOX5UDJY9RbywPoCsvPZ9q6rbYOyHyQvG2mb7mY05iOr6+GVZKXXmc7igprm15kmKE23AdppbN2FPAC8kmx8Po1uA2ol2jW+hwkGDBOoaDaOe+ea3LCWsefQDRAMnOC/sQ5HNuq6fr9Zf3Qq6qPJAEHnUu4HkZfKDDwZ0VwGFr2J5R7Uyr/x/uG0u1S6t8yvWJd5ZzIo+7b6N9SdoKf4rT3IBmSnfDVHxw+z7ZsdmWeSB9ZOXbyArGNmdPOaESxj22kR7k374PH2ZAPv7mSj9sl0R2vdptHJkNPJ1O905jhcvpatM2qZfSX1EtoB320bVDqYPCmzcss87U5PI4vsrFxQy+THWfTESZt593obtWvWMr8mGdB/HovOyzhso37WHdj6uS1rOTq6lpvL6ZnHvJbze9Cdr3e60YMH1rwtTx6/L675fEP9nX3IY3vnSo02I6qal2U+lOwsdW7q8mOyQ7NU/duc6W9S1Tn50jlhsQI5EvE1LHrS+iRmdnftZt1xNnlc7AQtjibr9hnXHdy2PXca2baZdpuPshzVbfkVekZd0Q1+dUYUnkQGLdrca2DkadbPj3SQBrkvr9DI2+tpHAvptsNeTstpzci20MvpzoV5IfDxPp97GBmgHWrOfUYY6G18vjco8khyQMkLyJPOrU/a0z6IOlQdP8plJ0/W39goR6vU/1vTOB4NWebHkeZYTpbU7w66EmIrsv/3Faa/Yd7I96HGd7cgb9jaGdjUmcLgfPKkWOf4sw/d6TumG5nYW1fsR44QPoMc/flE2l/Kvkzj8bJkYO49zf2KPJHxYVrOWdr47kivxiP7D08k68b9yDbB1WTbbQ3yWHwEeVxr09Z8HXBpfbxO3SadvtApZGB7+7q93jnkst+V3L+PJwdKvZ/stz2ovr8v2eY5uLOep0lvIdleeQRZf9xIHfVY39+Q7Mt9Y9Cys2i/6n5k22upupwvJUfJr9NIc8qpwXrS7Zww6CzfduQUBq+gO+XGfnWdDzVCuPF41oNoGMPglMayH1Kfb0qOVO+MYu+0by8mg9TTDWwbeV9gzOmObHBo/c7TaFz1U1/biAwiP47c7y8g+2ttT9yOPLbJmAdpzPRvzn6ozwpZg+5IzvfWFb0ZWfF/om7Ar7XZqQb8Rm+n49G0v7yoc5DfGXh34/XOAWn5mr/O/K+dIfWDDsYvqcu1a6MgPaju7IeTB9VHkxXLExvfG3TDvDad16vIQN0StJgaYJp1OFQgnjz79PG6Ex7cWUdkY/vV9fly5MFvV9ofRIYJyq5Iy1Ge5CUXt5KXOT2anOi9MxL5GWTHNWpeX0/70QYHkjv9vcig0KPr67uSFd6LaB8AGnkwgMaZUqYOIq9NVq5vZMBZ58Z3Rz7qumf7v7imcSXd0QfHkg2HY9qm1UjzyWTj9dpaXjtzSL+T4c6OT1Xmnwe8rT5flrxJ5FuGzecUv7kv2aAbanQwt+0MN0c8PZbsFE07YmOcfww3LcJC2gc8b6J7c8R71G3/ZBYN3p1I1lWt56zt81v7k42eVTrbfqr135O/YYJK095MqpHG46jTJ7Fop25jsk7/AcNNW9HbqN2EbNR2bmKxbt1uL2GIua7rd0fSgSWDCg8nT4TsQp54+AY988PVvA9zw6tOXbx343e2IUeYNxt9F1Pr5unKJ93AXycYv3Ut+6eQdeUy5IngT9P+ao1v070XwEa1TC4gjxuXkMeJU8j6ue38g9PVHTeRjd3PMIt2XCPNfYGvknX+zQw3Nc+syhFZf69Sy3HnxrErkMehzhQndyM7mO8h99Etp1t/o06zJ/2RdWTI+ujz5PH6LLI+vJI81q5L91jfCaq0mvqEbPs9ggwodO77cSU5XdLCWlaPoUVwrkX5nE2g90B6bvTDou2k9ckrk35P7ptt98thgqjD1PEjWXbyhOytdOvyTchgx1b1+ULy2Na6fI4pzbFd0dr47lR9oYV1Pxo4Zce49qH6nU4b+3617NwMPKfx/pPJfvUibY/ecjJF2gtYdKTbOmS76Ac1n23K+l51Wc+hXnFK1nVvrtu5EwQ6nqyvVp7h9pn11Xg9aZ5NHnM7x8u3kv3pD5BtnDZXii5N1glvaLz2aOCFjecn132ieY+UYW6gfizdm/QeSI6g/QEZ9DyF7gCLQfGJA+n2d7cj55n9I92rpJsB4aNpMU9v/expZFvlxbVs3okcPHchGetofdPsRpr7k22VLWt5eRZZB3+WjH2sQNatw/aHRjKIhjEOTqnL/kVy4NW1dPvT0fN/2pgHI+4LjDvdmsZIBofW71xEncO+p3zvQ53Hn9x/p53ypvHdscQ2GfMgjZn8zdkP1YW8DzUYQVZSLyA7L3uTjfld63urkGdWhupsDihsQ3U6yBE9L6sFYR2ywXVy4/3ODTdeRG3ot0hzGfJA1LnU5EZyJOeTyAbD2+jTsGFw8Lht5/W1wMNnuQ5nFIivn9+EHEHyC/LM5Z5kZfwxaqdhhvkaWVC2J93d6nY6nez4v4s8KL2mPj6ls02HTHcfeipN8oC0N3nJUpvLlcYVDNgD+APdTkzvDYteQAZA16XdgWkco66nqj/2IivlzrxaJ5H7b+ttX7f5NfXxq6gjI8gO7v7UmwPS/lKTqcr8R+h2lFdkyJEW0/zmwWTDos1cwlt2yl9jfXY6IdvTnYf9PLLx1/qS9lH+MYZpEeo+9C26QZrOpalbkA2yzrKfWMvwKIJf+5Cjg6abYmGsQaX6/VOpl/jSbWwupHvTls3rftX6yh9u26h9Yqdc1f/r1H2o9U0sG2mPogN7CHnC7xSyzl1IXq3waLpzs+1EHtfanhTsrYs3po6K6fncMeRxuu1og07g78N0T4wtQR5/dq3Pn02ONBpY3sm69Z10O5erk52sx9bny5Idr3PJtkibyx23rP+nqzueUfef1pc8tixntw5b5kdYji4iA57rkUHPq8m20RvJNuuWtJhOZNxp1nRH0pEh665Pk4Md9qZ7M7Klax4785aeQ9ZLbUZSbUR3hP/SZBv4NXQvvz+P3D+vJdvNba8eG0egt9PO7nffk13q/tW8BL/NDZDGEUQd2bJz2+kGXl232Ufp7t+dfX4rsm3XapqwUabZSHusV7Q2fqfflRDfY/rpG0a+D9Xvb07W3WfSHcW+JdnXPb7xuR1rOR0YqCLnqD2KPGZt3ee9d1BvukaeOJ52XdZl/yx5rH0W2R/drFEW3kLu68eQJ/NaDyTp81szvhqvrsur6V5pvGbN9xVkPdoZtb0CeexYpUV+OmktX/P1qpruJ7ntfLXNe2EM6vdvQgbKDm68tmUtRzuSJ1I687g+nXbH9N5YQpCxhKtonGyixcl1Fp0jeAdyhO2yZFDxk433Dib7gkMNauspV7396RWB69rmtV+5YJaDaJiDwSm9y063LbYv3Wkd25wcGnlfYJzpNtKfzeDQDeiO2D6InKpz+Z7PbFq3YasTEIwpttmibI50kMbQ22HOfqg7svMn5CWZ25IN+lfUlXwEGRg4agy/3brTQTY8vkQj4EreUOsTPa9tSY5g2rpFms0bAvyFDEquVyuQS8iz0t8nb2jRNiA9ls7rgN+b8eifnnX7VLJR/AGyAXnBLPM166DsFOnuWZdzabLhfVzN8+/IBt7Ks0j3W73f763ApvjuyIMBfdZls1Jehm7lvw8ZQJ525HEjvVGOum5bfxxcPz/wDsvUG6A0nu9cy/azyQZP56zmfdtun7kq89P8Xpu5hNcmb6byHrKBuUnjvW3JoPfezXU/rvy2KI8jnRahfr+5D61Bnsjq1KP3qNvpfWTwa2Sjr8nj0K4tPzvSoBLZUe8E4Vev+15zBNUvaARImNlonakatQfU/a1Ng3akHdhm2SBPrL6CnOOuMxL5pXU9P6Suz1aj05i6Lj698ZlN6m+1mtuu8b3m1RVX0L3R0cXkqJgzyeDxwGMbeSzoTLn0AvJ4+BVmMJdsI81h646VR7X/NNJsc6wcWTli0RtfHkMGe/5Ejhw8gKwzXg6cVD8z7cm2caRZPzfSjgwZyPsPte1LniD4FTmS88L62qa1nB9Gu+Dp/uSNir5HXhVwVH39RHJQxbGNz65Gy9FZjCfQ29vO3hB4SH18d3KfX+Tu59OkN5Yg6qiXnf7TDfyXWr818rgLWfe1mQN25Gk20hv7Fa2N3xqqLzSOfah+Zwuy73gBWVd8ge781tuS+9dRZFvhS0xzszNyv/w+ObjjKnIEaifQvR45T21nkEbbS8575ydejwwW79D4zNLk6OS/MoKTjczgajzyPjmb1Xy8iTx2fpzuYKFHkW2Fhw1TLut3l6rr9KVk2/K31CvI6vsLej4/KHh8N7JP9SKyvdIc2Pbquq6fOFXaU6TZb1BSZ3qI7es+9KyWy7oROTqyM/p7Q/Lqh3PIIGqnDnoQeeydUb+q8Xt71ryvUp+fUNfLSkxgEA1zODiFbiyhs+zHkydgBl7FzZj6AuNKd8DvDVsPBzn6/Ze1zOxKzkP+aXL/bh6f7k8ek1dukY+RxzaHKJsjH6Qx1DaY0x/rjux8Ntn5uJQcjXtM6e4Al7XZ+Wfw2206HfcgD7SHdDYeWfltUAvrL8iRwq8mRwUMczf1peoyv5QMWLy08d5Ccgj6hS3TGlvndZrfnfHon0YanR3iuXXH/S0t5oScJs0ZB2VbLO936B4EViVHeW80y3T3rRXYMDe8GnkwYEDevs+iZ5F3IYN1M5mLfGQB/hb1xwlkYGDaDid5MmdN8pK/BXV/+Sg52qlzhcGjyZGusy2fIy/zs8zPKmQA6u1k8OxHZEdjazJA1Bn52jn4j7QubpnHkU+LUNNYlhylcT55ouWLdC8V7hyg70Eeh0ZSb/bJx1TTVowjULUEeXy4jDxL/Xby8t5f0u3UnUJ3fsRZbWumbtS2Gak00g4sOcrhhTVPnY7LvrXMdOaz34UMyv+clje0oGVdXMvwwS2XfarA355k4/OBZAP9ueSxf8tp0rszeRLicTW9neq2/9+lvfVzD6deAtly+67CEHXHJP5GWY7Ijt+tZHCqE+hck8bdvutrL6BeMj6JNOtnRtqRIevLJ5HH/o+S8xp+jAzybkHOy/2eIbfN3mRb9Zqa10eQgdQ30b3J6NvJE/bDzF850kBv/dzAdjZ5DOr8Xtsrk8YRmB11kHuq6QbeQp3Htb7WCda0uaR7HGnO+RWtjd9u1Rcaxz5U012bDJJ22i4LyDbNdo3PbE8e124B9h1UTsl5dG+mexP25cjj53upAy3ojo4fdrRk7/zE15Aj4F9CBvxXJY+V095bZIjfPJj2V+N18ncoORDrTTT2yUZZfWLdjgMHp/RJ/9XUUbH1+bU0+v9DpNOJT3TabceQIz23buTxzXQHvbTZ16eq4x7TKFfb1nLwtBbp3YUM0t2XbLusQQb5vtL4zDFkv2ok+yPZpvs6Ge/4BO2ugBn5IBomMDilLvvXyDjVJxk8J/VY+gLjSrflbw8dk6r78LXkQLGdyHr4c+Sx6Qyyr/UthpgrnxHGNmdQNlce1focev3P+Q/mAfTHtcCdUiuSt5FnIVdisoGVnYBbG88/wqLzFK1PjlQ6nHqgHmIn6z2IfIrGnEg9nx10BnLkndch19Fsg7LNeWbuzDTzhg2R7tBB2SHS/Q4jHoXJcA2csQQDplnmH9TH9yQboLcZ3T5EeiML8LeoP6Ybedyc2mUJ8oD/fvLs5Glkh+4scjL+rzGCIOK4yvws87RbLX+rkx2xd9X95ynkKIdZ39xvBHkc2bQIZCflpWTQeGnyxMFldR/qBMqXpBvsn9XZ8Rks67iCSp35/zpz9O9AXsp7aV0f2zY+23rOvWl+s3WjtvGdkXdggQfUdfptssP+NnI02JPrPt4JxG9PtxM2qrr4xFqftOnEtQn8XUX3Eto2aXbm7X9J3Q4L6rZ/MdkRXpqc1uOLDHnJMPO47hh1OSLbW5+qy3YtGVzYj8axjByV9jVazpM3jjR7ts2oOjJ3J0eNPZgM6N4KPK/x/qrkCdtWAZValv83HUNd7k83fuvx5Ki/v5MdulZ9AcYT6B3Yzm6bTk+a4wiijnTZaTfdwJvJuuUG2gVrxpHmxK5obeShzaCkke5D9TvL1PX2EbIOWb2+fhl5EuZcusez9al14RRpdUbEb0W95Lzn/XvU/N11puW+fq8zP/HLa74PJdvvnyeD/kMFZVv+Zpur8R5AjtTevvm93n2yvr4sM5hugRxt+1e600osQwY6rxgynd74xFfJgOSXgbfW1y6m/UC0trGEZckTxFNOt8dt5xp/Glm/b0H2IX9DjpZ8Mdl2GOnl9mTQ71+0n7JxFUY4iIYJDk5pu+yMqS8wrnSH+P029XBzKqe9yalkDiaDtDuSx8njybruQloOJun5jZHENoctm5P8m8yPZmP5a40C1+rGaXOUt33JOfE+Ajyj570ZB08ZwUGEMXReJ7SOxzKikSGCsjNI90ujrvxo0cCpnxtbMGDAb+5LduR+RXcU6IzXKSMM8M+0/mDRQO7u5B2fVyIb3ZfV1/chg0vnMsRNa4b57Un81YNac/6tZciGzr3I+Rh/Ql4FcVUtZyM9ETOLfM9qWgS6HaSoZfA8MrDSuRv0S+o+1PqGNWNaznEEqtYgGzS32ZbkKLXHkyc2b3PZ8wiWp22jdqwdWPIY+UcyiPhUMpj2PXIE1M+AE4ZMr21d/CWGuylo26srBgb+yMtwO3NhBjmN0Cvpjrjembzk+Upy1M7dW+Rt3tcd4yxHddu+o66/I8lOxyfJS8PPJINeQ3UIx5FmI+1ZdWRY9Ia6e5HTdj2QvNHTjXSDf53n03aMajq/Jkcm3bPx+hVkcLGz/dYkR4tu0nJZxxHobdvOPoHc5ycVmB3psjOG6QbGkWbjexO7orVF3ka+D9XPb04GyZeq6/IqcsqAJ5Lt62eQwZGbyRN7awwqC3Snq1uL7PNu2vP+imT9ccgI1klnfuLmlVZLMMKR4TPI0xPoTgHYDDKtUMvpO0dRdsjj8NcaZXNZ4OwZpHOb+ETdf75NjkZen3qV3jTpDBNLeOygdcCi/aqjySul1gMeQ149tynZLjmZbHO2mqJlButmqPgMIzoRzjwYnDLdsjOmvsC40h3xutmCPLbu2imv5LHiPDIudw2wT+PznWD/TNoOI4ltjqpsjn3dTnCj7kce5JqXyk80yNLIx+7knFXN0Yr3Ixt5M77MhlkeRBhT5/X29EfLoOx8SXea3xx5MGDI39+N7kiZUTSiDmZEAf7Z1B/kpU5fp96Aim5j8e005hya6+09xnK0Hzmi653AuY3Xn0AG035It4O3AhO8JGaK/M9mWoTO2fFOo+Bwcq7Ap9b6csdafz6dEd7QcIbLOY5A1YF13f3vjsV0gzXrkg2SFzHLK0um+O02IwPG3oGlOyJ6pfr8AeQJ1q9SbzjSIo2x18XMPvDXGZX3m5qvU+m2GZ5RlznIud9eT7sA0GJRd4yjHDX2k6XJDuHadd39gLzh2/vI49kw81uPPM0B220mJ1k79wC5jO7NJU8kp3nZiGxnfoKsP9teXbA7eRXX0bXcPJ/GXPC1bN3E8AHPkQd66+dHesKe8QRmx7XsI59uYBxp9pSteXVF6zj2oZ50m/fiuTM5Bcy3WfTEzBZMc0MpMrB9E90bp11OBgt7R5NeQMt7A7RYhs78xBO9Co9uPfxy4LnN1xqf2Zxsg719hMv+FRrzFvf73Rbp9ItPnAg8pW2ajCGWQAaMv9Aph7WsP548rk05Cn4Ot/lIT4Q3ytC8HpzSyO9Y+gLjSneEy70Lefz9Ajmi90QyuH0meRXrEeSVT4eO6PeGjk2MumzO2bqd6I+PacToCAvB9+rjzcjO5n4jSHfogwgTDiT6N/d/jCEYMIu8jHI098gC8TOpP8j5xj9PbVw3DnQrkmf53lGf3y4CyOTIpxvqutqKPBO7QuP9y4FX1sfz8oqFmreZTIuwBnn5T+eO3HchR/m+kgxiPINs7DyAHME1kYMyYw4qcds7FndGRexAXlq7yoSWe846sOTxvHdu92j+H/DdOauLmeUIBrqj8k4nL2d9F/CGWo7eRfemQMu0SGuxqDvGWY7qdl2GHN15KY258chRhkPXGeNIc0BZGrYjs4CcFuindK+COIycAubg+pnnkaP62wa+tgXuXx9vXtN6HosGkT8AXD/k8o060Du2djYjDqKOetl70h75dAPjSLOnnM+bK1rHtA/1uz/P6fW37ky2EZ4CrDdEPk8H/kFe8bQTGaD+Mll33rt+5lgyOD2yqRBptNsnuZ1qXnar5XGb+rx5s6pHkUHQkQW7yfbWuSNIpxmf2JQ8hkw7ypMx1XHkyOdP9K6ruv6eSo7QXYEJxXkYw4lwFqPBKY08j6UvMK50R7jcO5EnZ/cnR4rfSAZlt6116ZHAwhH+XuvYxDjK5pyt14lnYAIjO4fI2z7A38iG374jTLf1QYR5FEj0b27/GGEw4Pb6N2z9QZ7Ru6Q+XpruiOPlyfkyR3Yjj0n/0R351Lmj8nbkjQ1e0VgH+5GXmc3b4HFjeYaa56x+50CyIXwv8iY2j66v70qeFX9+LQfLTXjZxhpU6tPAe3RtnAwcpTTmZZ7TDmw9nv+Gmc1jOGd1MbO8OoscsX9zLdfrk3NvfoC8jPqbtOscLTZ1x1yUIzLw+Rvg6SPM98jT7PMbrToy5I2i71Yfr0FOs/AcMsh3ATn9wmXU0a3M4LJzuh3tzchpB54H7NJ4f9o5fxvfH8c0LWNtZzOCIOo4ln2K3xn5dAPjSLORzsSvaB3nPsRt57+9lkXvz7NeLVPPp/2l92vQPeHw3vobm5HB70+Qo92+xojnq62/PS/6/WRA5hxytN82jdcPJwP2rQPyE8h7Mz6xT4vPj62Oq+XmS3Sv8uoEV1eq63hiIyYZw4lwFpPBKVPkfSx9gXGlO8Ll3ps8RixFtmefSb0CkfFMK9JmDvbFYpDGlPmfdAbm+x95uciMbyA2ojwYSLyD/jGCYMAd9Y9F5+bqBIrXqQe54xrvPZzs0M6rqyBGtA72rw27LclOx7NqOfpsrUNWIM/GrjXpvLZcnpnceHGReZQ75aE2KM5jgnPw9cnr2IJKtYH3VfLM9s3Um4lNcFnnvANb94ddZ/jdOauLmeXVWXU5v0PtuJAjHNcCNhoyjXlfd8xVOSKnAzhnJnXQXKbZ5zcGdmTqdnwtOVrykPracWQQZVXyJkjvr3Xoa0aUp83IDtzLgB3ra23mEh5nEGTs7WxmEUQd57JP8Xsjn25gHGk20p5VnTnL3x77PsSA+/M0ysc206RxH+A+jXL3AvLkxd7A1XTnCV2FHNk6b9pGY9x269b953oy0P9c8gT+yAPnY8j7UPGJUdRxLNqvWrHx+FVkP6pzJcCJ5Mj4id3sizGeCGcxGZwyRd7H0hcYV7ojXO79a75Wrs8necPnxWaQxpTLMOkMLC5/TDi4hIHEO+wfIwgG3NH+eho5J9UG0glksOG+5JnRF5A3IPkCt+M5w+kfQF0RuK4+nhcT8o95HXTmUV655/WJzMs1TV7HFlSqdcmtwJYTWrZ50YGd6fF8LutiZjlKqzbmvwOsPos05mXdMYlyRM4retUo98txpDnDfKxNzrH3c3JKhD3JuVU7l3bfmbwUd9MR/uYW5A1r1xzye2ML9DIH7WxmEUQd57JP8Xv/C8qOcLuPPM1G2hMb2ToX+xBT35/n7UxzZQ3dExA/AR5KXr69gAxY7E3OBfo+4KhJrcMJbrvlyBOP55AjxlvdqHi+/DFHVyixaL/qceQx95Kazi7kcfimWs6/zizn8h/RuhnbiXAWo8EpU6yXkfcFxpXuCPO3D3lD36GvRBzTNpj3gzSm+uvMAajFQETsT4602aGU8vuIWJUcjr98KeVHE82cxioi9iXnkbpfKeV3k87P4iIiTiUvXz6HHF3wGfIS0r+Tjf1bgctLKd+aVB7nQkTsSd50Z/tSyh8j4gTyhgJ7A38pd4ADQd2HXkLuQ7+fcHamFBFbkHeTP7yU8rcxpL/8ONJt8burA7cAPyNHKPyYbDy9lOy4rgocBVxWSrl0rvPX1uJUF0fEwWTdt00p5dYZpjGv6o5JlqNx7DuT2h/7iYitySDAteQcjisDJ5ZSvh8RS8y0DA34vaVKKf+ewff2JEcvb0kG5nYjA2DbkZ3D+5VS/jTDPI29nV33y2eS8y4OtU7HuexT/N6KpZS/jCq9caU5X4x7H4qI/YCXlVI2jYjNyCD1maWUa1p8tzPn73OBfwN3JwPeXymlvDUijicDLI/gDtIuvCOabR0XEacDDwEOIkecfoGcBuQb5BSd/wS+VEr5zniWYDgRsQ857/xTSynPr6+tCFxdStl1psehms6eZJ9y+2a9O5+O61MZVx7n+7LX8v/XUsp18yAvYyub42YAeTGzOHVeNVqjCAbc3kXE/cmRFV8jz6gfTTaWjyWDCteT01hcWEr52qTyOQm17nghOU/XEcCjSilfn2yu5laz4w6U+dpBmu8NsJm6vXRgF6e6eBTBmvlWd9xeytF8FBHrkevuvuRIyieSbc55VV+OM9A7F+3s2eyXDiaZ38a9D9WgwxXkDZaeVEr5wBDf3Z2c4mRrciTyUeTJuBPI+zBQSvm/2eZR89swdVwNkm5HjtR+Ojl//avJG3XuSU6tsi3wGODz8+k40THOE+GLy+AULSoiYj6U1fk2SKMtA8iLocWp86rRuj2P3JitiNgbuJCcj2ohOXfQVWTA+IWllL0iYkvyUs93AeeVUv46qfxOQkQcQHY87ltK+cak8zMJ7kOTdXvpwN7RytF8qztuL+VoPoqIpYBlybkcX1RK+faEs9TXOAO9872d7WCS+W3c+1Ct/+5USrlyBt/djxwlfb9Syl8iYuNSyg9HmT/Nf23quFrPvIAMkD4G+HIp5fiI2AR4bSllt/q5H5E37zyrlPKP8ed+eOM8Eb64DE7R/DTfBmm0YQB5MXVH67xKg0TENuTdTPcspdwQEQeRDfd9yLnfXldKuXetpI8GnlBK+c3kcjw5t9fRrVp82IFdPM23usNypHEGeud7O3u+B7k1fjMdRVfrzheRN7H8/WzS0uJrUB0XEZ2bP55TSnljfe2b5Ij6L5Nzb59HnrA9ggwe/2QOsj1j4zwRPt+PF5rf5tsgjeksmHQGNDNWUtIi/k02dPYCbiilvC8ijiNvCPG5iPhWRHyWvAHUYXfU4DHAfAoA6Y6plHJNRAB8PiJ27AT97MDOb/Ot7rAcqZTy3oj46DgCqPO9nT3OZdfiYab1XK07lwI+EhGOmryDmqaOW4q8wd6qEXGPUso3yRt8/Rv4A3AZ8FhgPeCI+R48BiilXB0Rq4yjLTPfjxea38ZZNsfBEciSFnsRsQRwb/Lu5LcASwD3BA4tpfy9fmYh8LNSyq8mllFJ/+NlfxoFy5EkDc9RkxokInYgb5j3W2ALYDXgwaWU/0bEMuS8yMvar5LuWAwgS1qsde5sXYPI9wGeBuwMrFdK+U9ELNcJIkuaX+zAahQsR5IkzV5ELFlK+W99fD/yHgMPAI4ppXw1IpYE6HxG0h2LAWRJi52I2BpYvZRybX3eCSIHORL5scDPgWfZwJEkSZKk24qILcib0r6zDr5pBpG3Iu8f8yvgY6WUL00up5ImbYlJZ0CShhERC8hGzlMjYjeAzgjkeuny14GXkZdbPWtyOZUkSZKk+akOvtmdHGX8kIhYUKep6Iw0/jLwbmATYI+IWHpimZU0cY5AlrTYiYjVgIOBhwIvLqV8pL7enM7iHsDvSim/nGBWJUmSJGleiohlgeOBuwOfAd7VZyTyQuAnd+QbkUsygCxpMRER0bw5UkQsBxwDHEKfIPJkcilJkiRJ81efftXSZL9qG+AG+gSRJWnBpDMgSdNpNnIi4gBgGeAbwFuA/wKPi4hbSykfM3gsSZIkSbfV0686gYwJLVFKeU2d0mJ74NaIeHcp5T+TzKuk+cU5kCUtNiLiUcBTgfWBL5E3zLuSnJvrWRHxgAlmT5IkSZLmrUbw+DRy6oqbgRdGxBHA2+rzvcnpAiXpfwwgS5q3ImIDyIZORGwO7AHsBfwfcCPwhVLKH8jGziXADyaVV0mSJEmajyJig4i4c328ErAtGSjeDrgeuKKU8g/gdcB15FQWkvQ/zoEsaV6KiNXJoPCnSykvjIilgDOADYCNgANKKf+OiMcCl5ZSbplcbiVJkiRp/qmB46cBPwPeUkr5ZURcCvwDWAk4rpTyt4g4HfhsKeVzE8yupHnKEciS5qv/A14K7BARp5ZS/g1sDOwEPLgGjw8DTgCWn2A+JUmSJGleKqX8GvggsBZwWH35enIKi6fU4PFRwEnAryeSSUnznjfRkzQvlVL+FRFrAX8ATo6I3wOPAd4LXFTvFrwFcEwp5ccTzKokSZIkzWerA3cDDoyIW8mpKlYGPhARnwC2BI62XyVpKk5hIWleioiTgEeT01ZsT87T9XbypnnbAGsCX7aRI0mSJEn9RcSDgKcDBwJHkzck/24p5WURcS/gVuDPpZSfTTCbkuY5RyBLmq/WAp5TSrk2Ij4H7EoGk1cupbxmojmTJEmSpMXDBsAnSyk/B86v01U8KSKWBd5Up7iQpIGcA1nSfHUrcEZErFRK+RPwaeB3wO4RsdpksyZJkiRJi4VPAxtFxI4ApZRLyRvqrQb8e5IZk7T4cASypImKiM2AP5VSflOfR8m5dV4IrAG8LiJOA3Yk50N+Qinl9xPLsCRJkiQtPn4I3AQcEhF3B34PLAO8zH6VpLacA1nSREREAEsD7wJ+BJzbe/lURNwZOBvYHLgTcHIp5atznFVJkiRJmrcag3D6vhYRmwBbA0cCBTinlPK1uc+ppMWVAWRJExERS5RSbo2IpYErgC8CLy6l/KHPZ1cCbi2l/HWu8ylJkiRJ81VPoHhv8irObwDfLKX8q+ezSwDLlFL+Pvc5lbQ4cw5kSRNRSrm1PjwE+AfwWOCFEbFm5zO1gUMp5f8MHkuSJEnSohrB40cDLwK2AV4DnFCv6KS+H6WUWw0eS5oJA8iSJiYi9gKeCjyMbOisDTw1IlaBRYLMkiRJkqSqTgnYebwacABwQCnlCcBZwE5kHwvoBpolaSYMIEuapH8C3wb+VUr5HnAi8BDg5c2z5ZIkSZKkrsbI47sBfwb+COwaEQtKKR8DbgBOioglJ5dLSbcXBpAlzYnmGfLG858AAdwnIpavN9G7GFgL+Pfc51KSJEmSFg8RsQ3wvFLKf4BPABsBO9a3fw/8juxvSdKseBM9SWPXc2OHRwPrkA2Z5wDHAXsAXybvCLwTcGop5SeTya0kSZIkzX8RsQLwLuDhwALgkcAW9fEGwPGllK9MLoeSbi8MIEuaMxHxWOBg4AzgVcAtwEOBbYHtgM2BC0sp35xYJiVJkiRpHouIk4G7AkvW/y8tpXyivrcxcGfgZ6WUn00ul5JuTxZMOgOSbr8i4r7AfUopb4qI1YFNgIOAR5HTV9wCXA08tJRyfZ2v6z+Ty7EkSZIkzS/NKzqrbwJ/Au5O3ijvTRHxGeA/wPWllEsmkE1Jt2MGkCWNRUQsADYEjo2If5VS3h4RzwTuDRxcStkxIjYBPga8IyL2AW6dYJYlSZIkaV7pmQ7wYDJw/J9Syjvqa/8A7gU8BdgX+MCk8irp9sub6EkaudrI+U8p5T3AO8m7/x5cSvkD8Hfg6zXAvB05lcXDSyn/LaUYQJYkSZKkqhE8fizwJHLav9dFxO71I58A/lxK+Xkp5ZJSys8nlFVJt2MGkCWNTUScBuxCjix+bEQcBXwPWB94A/AC4MpSyk8nl0tJkiRJml8iYvnG4w2BPUopO5M3JP8W8PH69v8BCyNixYgwxiNpLJzCQtLI1Bs2/LKU8o+IuBtwMnB/YGVgIXAqOffxIeRdgf9p8FiSJEmSuiJiP2CviHgR8DPgv8DvIuLZwFbA4aWUWyPiaOBTZHD5LxPLsKTbPc9OSRqJiNgXeCmwZn1pCeAfpZS/1MuoPg38Eng1cEAp5XsGjyVJkiSpKyIOAJ4HXFdK+WlJPwOWJG9G/pBSyt8j4jjgdODvpZQ/TzDLku4AHIEsadYiYk/gPOCMUspPI2KZUsq3IuK7EfGKUsqjSym3RMRXgR8Dn59sjiVJkiRpfomItYEnAieVUj4fEUsDywLLk/2t3wDXRcTHyRvmHVdK+fXEMizpDsMAsqRZiYjdgCuBbUop346IuwJPi4hnAc8AzoqIG4D3A8cA+zryWJIkSZJu45/Av4F/RMSywJnATmTs5ofAE8jA8Z+AN5ZSvjepjEq6YzGALGm2fgssB2wYEd8F3gZcXkr5SX3/pIh4ZH18aON1SZIkSVLXH4EPARcA9wQ+AlwGfJ2cvmL7UsqlE8udpDusKKVMOg+SFnMRsS3wYeBW4FGllHdERJRSSkTcE/h+KeUfk82lJEmSJM1vEbEicG9gfeC9pZR/1tdfR86L/JZJ5k/SHZM30ZM0a6WUzwO7kHXKkvW1Um/scCFwpwlmT5IkSZIWC/Um5DeWUt7ZCB4fCmxJ3phckuacU1hIGolSytciYi/gwxHxX+AW4DTg+FLKbyabO0mSJElavETEOsDhwCOAw0sp359wliTdQTmFhaSRioiFwOfIAPKupZSbJ5wlSZIkSVrsRMRywG7At71hnqRJMoAsaeQi4h7Af0sp3550XiRJkiRJkjRzBpAlSZIkSZIkSX15Ez1JkiRJkiRJUl8GkCVJkiRJkiRJfRlAliRJkiRJkiT1ZQBZkiRJkiRJktSXAWRJkiRNRET8NyK+3PjbKCJ2jYg/9by+R+M7D4qIEhFb1OefrZ/5SUTc0pPWX3p+7/iIuKg+Picifl4/+82IOLLxuTdGxA8baX26T953jYirG+mWiNi9Tz4fWp9fFxHfjoivRMSnImLz+vrSEfGSiPh+RHw3It4bEev1WUdfj4irImKVaZZ5QUT8NiKe15Pf6yLipsbzhRFxXeP5dhHxiZrHb0XEJRGxfF225m98OSLuMfTGliRJ0mJrwaQzIEmSpDusv5dStmq+EBEbAZ8spRwwxXeOBG4AjgDOKaVsX793PLCwlHJaI63pfv/FpZQLImIz4AsRcXkp5d/1vSeXUi4fYlm+VvP20fr8COArPZ85upRyU0ScDLwQOAg4D1gJuFsp5b8RcQJwRURsX0opNNZRRLwJePQ0y7wf8G3gsIh4ak2jY62I2LeU8oFmpiLizsC7gCNKKTdGrriH1HwBvKP5G5IkSbpjcQSyJEmSFgsRsSKwI3AiGaAdiVLKd4G/AavOIplPAttFxFI1n5sCX57is58ANo2I5YETgMeXUv5b8/IG4J/Abn2+dyOw7jT5OBJ4KfATYIee914InN3nO48G3lRKubHmoZRSLi+l/Hqa35IkSdIdgAFkSZIkTcpyjWkRrmy8vnPPlAmb1NcPAT5YSvkO8PuI2HoUmajpfLeU8pvGyy9s/P7bWiRTgI8AewMHA+8b8NkDyRHLmwI/KaX8uef9m4B79uRxSWD3QelGxHL1M1cDbyeDyU03Av+MiAf2vH4v4AsD8nt4z/ZYbsBnJUmSdDtjAFmSJEmT8vdSylb170GN1z/ZeH2rUsr36+tHApfVx5dx2wBpG80pHR4fEd8GPguc0/O5Jzd+/+iWaV9Gjow+ggzg9npbRHyZHEX9JCB68tPRfH25+p3fAasB1w74/QOAj5dS/ga8G3hQDTw3PZf+o5AHeUfP9vj7kN+XJEnSYswAsiRJkua9iFidnNbhkoj4EfBkcmTsoImO/x4RSzeerwb8tvH8xaWUzYHDgTdHxLKzyWMp5XPkaN416ijpXkfXAOwhpZSfAt8DNoyIlXo+tzXwzc4y1DmQNwSWJqebmMqRwB51/XwBWB1YZLRxKeVjwLIsOr3FN4Btpl9CSZIk3REZQJYkSdLi4KHAm0spG5ZSNiqlrA/8ENhpwHeuB46B/03vcBjw8d4PlVKuIKeNOG4E+TwLeGqbD5ZS/gq8CbiwM1I4Ih4GLA98rOezfwIeAzwpIpbqTSsi7kSuiw3q+tmIDDb3G6V9LnBG4/lFwHERsX0jvWMiYu02yyFJkqTbNwPIkiRJmm9650B+KBkIvbLnc+8GjhqQzmOBB9cpID4DvKuU8okpPvts4AkR0Wkfv7AnD0tP8b1FlFI+UEq5TZB6gLOAfwDfiYjvAocCDyql3GZqi1LKl4Cv0P8Ggg8GPlZK+WfjtfcCB0XEMj3pXAPc0nj+65rmBRHx7Yi4GdgZ6MzN3DsH8v2HWD5JkiQt5qJP21SSJEmSJEmSJEcgS5IkSZIkSZL6M4AsSZIkSZIkSerLALIkSZIkSZIkqS8DyJIkSZIkSZKkvgwgS5IkSZIkSZL6MoAsSZIkSZIkSerLALIkSZIkSZIkqS8DyJIkSZIkSZKkvv4fIgM+cwdC/6oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "#Plot feature importance\n",
    "def plot_feature_importance(importance,names,model_type):\n",
    "\n",
    "  #Create arrays from feature importance and feature names\n",
    "  feature_importance = np.array(importance)\n",
    "  feature_names = np.array(names)\n",
    "\n",
    "  #Create a DataFrame using a Dictionary\n",
    "  data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "  fi_df = pd.DataFrame(data)\n",
    "\n",
    "  #Sort the DataFrame in order decreasing feature importance\n",
    "  fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "  #Define size of bar plot\n",
    "  fig = plt.figure(figsize=(20,6))\n",
    "  #Plot Searborn bar chart\n",
    "  sns.barplot(y=fi_df['feature_importance'], x=fi_df['feature_names'])\n",
    "  #Add chart labels\n",
    "  plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "  plt.xlabel('FEATURE IMPORTANCE')\n",
    "  plt.ylabel('FEATURE NAMES')\n",
    "  plt.tight_layout()\n",
    "  fig.autofmt_xdate(rotation=45)\n",
    "\n",
    "\n",
    "plot_feature_importance(xgb_model.feature_importances_*100,x_train_1.columns,'XGBoost ')\n",
    "\n",
    "print(np.sum(xgb_model.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRc6k4ErgEKI"
   },
   "source": [
    "A partir de este grÃ¡fico se puede observar la importancia de cada caracterÃ­stica haciendo uso de XGBoost. AsÃ­ pues, VCM es la variable que aporta mayor informaciÃ³n al realizar la tarea de clasificaciÃ³n, con lo que permitirÃ¡, en mayor medida, diferenciar un paciente sano de uno no sano. No obstante, las 3  variables siguientes MO-Y, MacR y IG tambiÃ©n presentan informaciÃ³n relevante para la predicciÃ³n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lw5m7_pB2id9"
   },
   "source": [
    "**SelecciÃ³n de las caracterÃ­sticas en base a la importancia de Ã©stas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "0iM8ZAFW0kJV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 de 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/obarquero/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=6, n_estimators=125;, score=0.806 total time=   6.6s\n",
      "[21:48:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.15, max_depth=12, n_estimators=200;, score=0.806 total time=   9.8s\n",
      "[21:48:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.3, max_depth=6, n_estimators=200;, score=1.000 total time=   8.8s\n",
      "[21:49:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=6, n_estimators=125;, score=0.972 total time=   8.4s\n",
      "[21:49:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=50;, score=0.962 total time=   3.6s\n",
      "[21:49:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.15, max_depth=4, n_estimators=175;, score=0.923 total time=  11.0s\n",
      "[21:49:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.3, max_depth=6, n_estimators=200;, score=0.861 total time=   4.9s\n",
      "[21:49:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END colsample_bytree=0.45, gamma=0.48, learning_rate=0.15, max_depth=11, n_estimators=192;, score=0.962 total time=  11.4s\n",
      "[21:49:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5] END colsample_bytree=0.45, gamma=0.48, learning_rate=0.15, max_depth=11, n_estimators=192;, score=0.917 total time=  12.9s\n",
      "[21:49:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END colsample_bytree=0.4, gamma=0.48, learning_rate=0.15, max_depth=15, n_estimators=200;, score=1.000 total time=  11.1s\n",
      "[21:50:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5] END colsample_bytree=0.45, gamma=0.3, learning_rate=0.15, max_depth=16, n_estimators=202;, score=0.972 total time=   5.6s\n",
      "[21:53:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:53:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:55:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:55:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:55:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5481/913984432.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mselection_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolsample_bytree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#cv estimation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_x_train_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mscores_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    446\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    248\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    249\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 250\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    251\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    252\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#SelectFromModel\n",
    "\n",
    "scores_cv = []\n",
    "thresholds = np.sort(xgb_model.feature_importances_) # obtiene la importancia de cada caracterÃ­stica\n",
    "i = 0\n",
    "for thresh in thresholds:\n",
    "    print(\"{} de {}\".format(i,len(thresholds)))\n",
    "    selection = SelectFromModel(xgb_model, threshold=thresh, prefit=True)\n",
    "    select_x_train_1 = selection.transform(x_train_1)\n",
    "    # train model\n",
    "    selection_model = xgb.XGBClassifier(colsample_bytree=0.7, gamma=0.3, learning_rate=0.3, max_depth=8)\n",
    "    #cv estimation\n",
    "    sc =cross_val_score(selection_model, select_x_train_1, y_train_1, cv=10, scoring='roc_auc',n_jobs=-1)\n",
    "    scores_cv.append(sc)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZpG_Bv92uN-"
   },
   "outputs": [],
   "source": [
    "plt.rc('xtick',labelsize=15)\n",
    "plt.rc('ytick',labelsize=15)\n",
    "plt.figure(figsize = (80,20))\n",
    "sc_cv = np.asarray(scores_cv)\n",
    "scores_m = np.mean(sc_cv,axis = 1)\n",
    "scores_std = np.std(sc_cv,axis = 1)\n",
    "xx = np.arange(len(scores_m))\n",
    "plt.plot(xx,scores_m,'o-')\n",
    "plt.grid()\n",
    "_ = plt.xticks(xx,labels= np.arange(1,len(scores_m)+1))\n",
    "plt.xlabel('Number of features removed')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPWHtcuDgz84"
   },
   "source": [
    "Esta grÃ¡fica muestra el ***accuracy*** que se alcanza cuando se escogen X caracterÃ­sticas. Desde la izquierda hacia la derecha se van quitando variables consecutivamente, y se puede observar que la predicciÃ³n del modelo no se degrada hasta llegar a 67 variables. Es decir, solo quedÃ¡ndonos con 4  variables, el modelo es capaz de tener el mismo desempeÃ±o en predicciÃ³n que utilizando todas las variables. Estas caracterÃ­stica son las 4 primeras representadas anteriormente en la grÃ¡fica anterior.\n",
    "\n",
    "AdemÃ¡s siempre es preferible tener un modelo menos complejo para que de esta forma pueda haber una mejor generalizacion con la incorporaciÃ³n de datos nuevos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2Ic4559fxkF"
   },
   "source": [
    "## 1.4 Rendimiento con FS en el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbNtndTNWPbj"
   },
   "outputs": [],
   "source": [
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)\n",
    "\n",
    "#convert into a dataframe with sorted feature importances\n",
    "fi = rf_feat_importance(xgb_model,x_train_1)\n",
    "\n",
    "#select the features\n",
    "selected_features_RF = fi[:len(fi)-63]['cols'].to_list()\n",
    "print(\"Numero de variables seleccionadas Pars:\",len(selected_features_RF))\n",
    "print(\"Selected features:\",selected_features_RF)\n",
    "\n",
    "\n",
    "X_train_FT_xgb = x_train_1[selected_features_RF]\n",
    "X_test_FT_xgb = x_test[selected_features_RF]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1OHoycnkr11"
   },
   "outputs": [],
   "source": [
    "xgb_FS = xgb.XGBClassifier(colsample_bytree=0.45, gamma=0.3, learning_rate=0.15,\n",
    "              max_depth=16, n_estimators=202)\n",
    "xgb_FS.fit(X_train_FT_xgb, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIYve4K_eYNf"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#Todas las caracterÃ­sticas\n",
    "y_pred_tot = xgb_model.predict(x_test)\n",
    "acc_tot = accuracy_score(y_test, y_pred_tot)\n",
    "sensibilidad_tot = recall_score(y_test, y_pred_tot)\n",
    "#precision_tot=precision_score(y_test, y_pred_tot)\n",
    "specificity_tot = confusion_matrix(y_test, y_pred_tot)[0][0]/(confusion_matrix(y_test, y_pred_tot)[0][0]+confusion_matrix(y_test, y_pred_tot)[0][1])\n",
    "auc_tot = roc_auc_score(y_test, y_pred_tot)\n",
    "\n",
    "\n",
    "#8 caracterÃ­sticas \n",
    "y_pred_8 = xgb_FS.predict(X_test_FT_xgb)\n",
    "acc_8 = accuracy_score(y_test, y_pred_8)\n",
    "sensibilidad_8 = recall_score(y_test, y_pred_8)\n",
    "#precision_8 = precision_score(y_test, y_pred_8)\n",
    "specificity_8 = confusion_matrix(y_test, y_pred_8)[0][0]/(confusion_matrix(y_test, y_pred_8)[0][0]+confusion_matrix(y_test, y_pred_8)[0][1])\n",
    "auc_8 = roc_auc_score(y_test, y_pred_8)\n",
    "\n",
    "Tabla_xgb = pd.DataFrame({\"Prestaciones en test\":[\"Accuracy\",\"Sensibility\",'Specificity',\"AUC ROC\"],\n",
    "                          \"XGBoost total\" : [acc_tot, sensibilidad_tot, specificity_tot, auc_tot], \n",
    "                      \"XGBoost 8 features \" : [acc_8, sensibilidad_8, specificity_8, auc_8]})\n",
    "Tabla_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4yngAoGR3pp"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "#XGBoost all features\n",
    "plot_confusion_matrix(xgb_model, x_test, y_test,display_labels=[\"Sano\",\"No sano\"],\n",
    "                                 cmap=plt.cm.Blues)\n",
    "plt.title(\"XGBoost all features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXjpBigeVV1p"
   },
   "outputs": [],
   "source": [
    "#XGBoost 8 features\n",
    "plot_confusion_matrix(xgb_FS, X_test_FT_xgb, y_test,display_labels=[\"Sano\",\"No sano\"],\n",
    "                                 cmap=plt.cm.Blues)\n",
    "plt.title(\"XGBoost 8 features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8MaaLxwrHnY"
   },
   "source": [
    "# 2.Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YK45kpe0BT4W"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQxjCymApESi"
   },
   "source": [
    "## 2.1 OptimizaciÃ³n de los hiperparÃ¡metros usando RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70RPb-H7MWNt"
   },
   "outputs": [],
   "source": [
    "#Indico que el clasificador que voy a utlizar es GBoosting\n",
    "\n",
    "gb_model = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMXjUhN5Mgdo"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    " 'n_estimators' : [150,200,250,300,350,400,450,500],\n",
    " 'learning_rate' : [0.05,0.10,0.15,0.20,0.25,0.30],\n",
    " 'max_depth' : [20,25,30,35,40,45],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ap81OEvyMjTC"
   },
   "outputs": [],
   "source": [
    "#verbose = genera mensajes durante el entramiento del modelo 'Fitting 5 folds...'\n",
    "\n",
    "#roc_auc = curva AUC-ROC es la mÃ©trica de selecciÃ³n del modelo para el problema de clasificaciÃ³n \n",
    "#de dos clases mÃºltiples.ROC nos dice quÃ© tan bueno es el modelo para distinguir las clases dadas, \n",
    "#en tÃ©rminos de la probabilidad predicha.\n",
    "\n",
    "#n_jobs = nÃºmero de nucleos que se utilizan (-1 quiere decir que se utilizan todos)\n",
    "\n",
    "r_s_model_2 = RandomizedSearchCV(gb_model , param_distributions=params, n_iter=5, \n",
    "                               scoring='roc_auc',n_jobs=-1,cv=5,verbose=3,random_state = 2)\n",
    "\n",
    "r_s_model_2.fit(x_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ohuKN0wMqqM"
   },
   "outputs": [],
   "source": [
    "r_s_model_2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NaX_GvsYItTG"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    " 'n_estimators' : [335,340,345,350,355,360,365],\n",
    " 'learning_rate' : [0.14,0.16,0.18,0.20,0.22,0.24,0.26],\n",
    " 'max_depth' : [26,27,28,29,30,31,32,33,34],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtKeKdCDJPjW"
   },
   "outputs": [],
   "source": [
    "#verbose = genera mensajes durante el entramiento del modelo 'Fitting 5 folds...'\n",
    "\n",
    "#roc_auc = curva AUC-ROC es la mÃ©trica de selecciÃ³n del modelo para el problema de clasificaciÃ³n \n",
    "#de dos clases mÃºltiples.ROC nos dice quÃ© tan bueno es el modelo para distinguir las clases dadas, \n",
    "#en tÃ©rminos de la probabilidad predicha.\n",
    "\n",
    "#n_jobs = nÃºmero de nucleos que se utilizan (-1 quiere decir que se utilizan todos)\n",
    "\n",
    "r_s_model_2 = RandomizedSearchCV(gb_model , param_distributions=params, n_iter=5, \n",
    "                               scoring='roc_auc',n_jobs=-1,cv=5,verbose=3,random_state = 2)\n",
    "\n",
    "r_s_model_2.fit(x_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_L5mXQ-JRtg"
   },
   "outputs": [],
   "source": [
    "r_s_model_2.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoVKotCcpLRy"
   },
   "source": [
    "## 2.2 Rendimiento con todas las features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22LZf3hgMvey"
   },
   "outputs": [],
   "source": [
    "#Construyendo el modelo final\n",
    "gb_model = GradientBoostingClassifier(learning_rate=0.16, max_depth=26, n_estimators=355)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53iLdlm0M4hS"
   },
   "outputs": [],
   "source": [
    "#MÃ©tricas\n",
    "\n",
    "gb_model.fit(x_train_1, y_train_1)\n",
    "\n",
    "y_pred = gb_model.predict(x_test)\n",
    "\n",
    "acc_gb = accuracy_score(y_test, y_pred)\n",
    "sensibilidad_gb = recall_score(y_test, y_pred)\n",
    "#precision_xgb = precision_score(y_test, y_pred)\n",
    "specificity_gb = confusion_matrix(y_test, y_pred)[0][0]/(confusion_matrix(y_test, y_pred)[0][0]+confusion_matrix(y_test, y_pred)[0][1])\n",
    "auc_gb = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "Tabla_2 = pd.DataFrame({ \"Prestaciones en test\":[\"Accuracy\",\"Sensibility\",'Specificity',\"AUC ROC\"],\n",
    "                      \"GBoost\" : [acc_gb, sensibilidad_gb, specificity_gb, auc_gb]})\n",
    "\n",
    "Tabla_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijH2kiaPpQ41"
   },
   "source": [
    "## 2.3 SelecciÃ³n de caracterÃ­sticas (FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQl1rMUr4xGN"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#Plot feature importance\n",
    "def plot_feature_importance(importance,names,model_type):\n",
    "\n",
    "  #Create arrays from feature importance and feature names\n",
    "  feature_importance = np.array(importance)\n",
    "  feature_names = np.array(names)\n",
    "\n",
    "  #Create a DataFrame using a Dictionary\n",
    "  data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "  fi_df = pd.DataFrame(data)\n",
    "\n",
    "  #Sort the DataFrame in order decreasing feature importance\n",
    "  fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "  #Define size of bar plot\n",
    "  fig = plt.figure(figsize=(20,6))\n",
    "  #Plot Searborn bar chart\n",
    "  sns.barplot(y=fi_df['feature_importance'], x=fi_df['feature_names'])\n",
    "  #Add chart labels\n",
    "  plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "  plt.xlabel('FEATURE IMPORTANCE')\n",
    "  plt.ylabel('FEATURE NAMES')\n",
    "  plt.tight_layout()\n",
    "  fig.autofmt_xdate(rotation=45)\n",
    "\n",
    "\n",
    "plot_feature_importance(gb_model.feature_importances_*100,x_train_1.columns,'Gradient Boosting')\n",
    "\n",
    "print(np.sum(gb_model.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zc8gjLZWq6G1"
   },
   "source": [
    "A partir de este grÃ¡fico se puede observar la importancia de cada caracterÃ­stica haciendo uso de XGBoost. AsÃ­ pues, MO-Y es la variable que aporta mayor informaciÃ³n al realizar la tarea de clasificaciÃ³n, con lo que permitirÃ¡, en mayor medida, diferenciar un paciente sano de uno no sano. No obstante, la siguiente variable UCI tambiÃ©n presentan informaciÃ³n relevante para la predicciÃ³n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slKvOlOp48LL"
   },
   "source": [
    "**SelecciÃ³n de las caracterÃ­sticas en base a la importancia de Ã©stas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9OdM9pcr48_P"
   },
   "outputs": [],
   "source": [
    "#SelectFromModel\n",
    "\n",
    "scores_cv = []\n",
    "thresholds = np.sort(gb_model.feature_importances_) # obtiene la importancia de cada caracterÃ­stica\n",
    "i = 0\n",
    "for thresh in thresholds:\n",
    "    print(\"{} de {}\".format(i,len(thresholds)))\n",
    "    selection = SelectFromModel(gb_model, threshold=thresh, prefit=True)\n",
    "    select_x_train_1 = selection.transform(x_train_1)\n",
    "    # train model\n",
    "    selection_model = GradientBoostingClassifier(learning_rate=0.05, max_depth=25, n_estimators=350)\n",
    "    #cv estimation\n",
    "    sc =cross_val_score(selection_model, select_x_train_1, y_train_1, cv=10, scoring='roc_auc',n_jobs=-1)\n",
    "    scores_cv.append(sc)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JehCEQKh5MEg"
   },
   "outputs": [],
   "source": [
    "plt.rc('xtick',labelsize=15)\n",
    "plt.rc('ytick',labelsize=15)\n",
    "plt.figure(figsize = (80,20))\n",
    "sc_cv = np.asarray(scores_cv)\n",
    "scores_m = np.mean(sc_cv,axis = 1)\n",
    "scores_std = np.std(sc_cv,axis = 1)\n",
    "xx = np.arange(len(scores_m))\n",
    "plt.plot(xx,scores_m,'o-')\n",
    "plt.grid()\n",
    "_ = plt.xticks(xx,labels= np.arange(1,len(scores_m)+1))\n",
    "plt.xlabel('Number of features removed')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dK_wom1irWSd"
   },
   "source": [
    "Esta grÃ¡fica muestra el ***accuracy*** que se alcanza cuando se escogen X caracterÃ­sticas. Desde la izquierda hacia la derecha se van quitando variables consecutivamente, y se puede observar que la predicciÃ³n del modelo no se degrada hasta llegar a 69 variables. Es decir, solo quedÃ¡ndonos con 2  variables, el modelo es capaz de tener el mismo desempeÃ±o en predicciÃ³n que utilizando todas las variables. Estas caracterÃ­stica son las 2 primeras representadas anteriormente en la grÃ¡fica anterior.\n",
    "\n",
    "AdemÃ¡s siempre es preferible tener un modelo menos complejo para que de esta forma pueda haber una mejor generalizacion con la incorporaciÃ³n de datos nuevos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1COH2pM_rfZr"
   },
   "source": [
    "## 2.4 Rendimiento con FS en el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bBSit54rkw7"
   },
   "outputs": [],
   "source": [
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)\n",
    "\n",
    "#convert into a dataframe with sorted feature importances\n",
    "fi = rf_feat_importance(gb_model,x_train_1)\n",
    "\n",
    "#select the features\n",
    "selected_features_RF = fi[:len(fi)-69]['cols'].to_list()\n",
    "print(\"Numero de variables seleccionadas Pars:\",len(selected_features_RF))\n",
    "print(\"Selected features:\",selected_features_RF)\n",
    "\n",
    "\n",
    "X_train_FT_gb = x_train_1[selected_features_RF]\n",
    "X_test_FT_gb = x_test[selected_features_RF]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqiyN7kNr8aC"
   },
   "outputs": [],
   "source": [
    "gb_FS = GradientBoostingClassifier(learning_rate=0.16, max_depth=26, n_estimators=355)\n",
    "gb_FS.fit(X_train_FT_gb, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qimkky5zsKT-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#Todas las caracterÃ­sticas\n",
    "y_pred_tot = gb_model.predict(x_test)\n",
    "acc_tot = accuracy_score(y_test, y_pred_tot)\n",
    "sensibilidad_tot = recall_score(y_test, y_pred_tot)\n",
    "#precision_tot=precision_score(y_test, y_pred_tot)\n",
    "specificity_tot = confusion_matrix(y_test, y_pred_tot)[0][0]/(confusion_matrix(y_test, y_pred_tot)[0][0]+confusion_matrix(y_test, y_pred_tot)[0][1])\n",
    "auc_tot = roc_auc_score(y_test, y_pred_tot)\n",
    "\n",
    "\n",
    "#2 caracterÃ­sticas \n",
    "y_pred_2 = gb_FS.predict(X_test_FT_gb)\n",
    "acc_2 = accuracy_score(y_test, y_pred_2)\n",
    "sensibilidad_2 = recall_score(y_test, y_pred_2)\n",
    "#precision_2 = precision_score(y_test, y_pred_2)\n",
    "specificity_2 = confusion_matrix(y_test, y_pred_2)[0][0]/(confusion_matrix(y_test, y_pred_2)[0][0]+confusion_matrix(y_test, y_pred_2)[0][1])\n",
    "auc_2 = roc_auc_score(y_test, y_pred_2)\n",
    "\n",
    "Tabla_gb = pd.DataFrame({\"Prestaciones en test\":[\"Accuracy\",\"Sensibility\",'Specificity',\"AUC ROC\"],\n",
    "                         \"GBoost total\" : [acc_tot, sensibilidad_tot, specificity_tot, auc_tot], \n",
    "                      \"GBoost 2 features \" : [acc_2, sensibilidad_2, specificity_2, auc_2]})\n",
    "Tabla_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9k_dOJt2WE41"
   },
   "outputs": [],
   "source": [
    "#GBoost all features\n",
    "plot_confusion_matrix(gb_model, x_test, y_test,display_labels=[\"Sano\",\"No sano\"],\n",
    "                                 cmap=plt.cm.Blues)\n",
    "plt.title(\"GBoost all features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSyoj6KZWUPW"
   },
   "outputs": [],
   "source": [
    "#GBoost 2 features\n",
    "plot_confusion_matrix(gb_FS, X_test_FT_gb, y_test,display_labels=[\"Sano\",\"No sano\"],\n",
    "                                 cmap=plt.cm.Blues)\n",
    "plt.title(\"GBoost 2 features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tI-esAG5rP9Q"
   },
   "source": [
    "# 3.Histogram-based Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jtl4ZFN3bbe8"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKZi2FJsvLCb"
   },
   "source": [
    "## 3.1 OptimizaciÃ³n de los hiperparÃ¡metros usando RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQ2c4qzsbb8K"
   },
   "outputs": [],
   "source": [
    "#Indico que el clasificador que voy a utlizar es XGBosst\n",
    "\n",
    "hb_model = HistGradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymoVMrSmbcLj"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    " 'max_leaf_nodes': [1,3,5,7,10,13,15,20,25,30,35,40],\n",
    " 'learning_rate' : [0.05,0.10,0.15,0.20,0.25,0.30],\n",
    " 'max_depth' : [3,4,5,6,8,10,12,15,20,25,30],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jOtwpuEbcTj"
   },
   "outputs": [],
   "source": [
    "#verbose = genera mensajes durante el entramiento del modelo 'Fitting 5 folds...'\n",
    "\n",
    "#roc_auc = curva AUC-ROC es la mÃ©trica de selecciÃ³n del modelo para el problema de clasificaciÃ³n \n",
    "#de dos clases mÃºltiples.ROC nos dice quÃ© tan bueno es el modelo para distinguir las clases dadas, \n",
    "#en tÃ©rminos de la probabilidad predicha.\n",
    "\n",
    "#n_jobs = nÃºmero de nucleos que se utilizan (-1 quiere decir que se utilizan todos)\n",
    "\n",
    "r_s_model_3 = RandomizedSearchCV(hb_model , param_distributions=params, n_iter=5, \n",
    "                               scoring='roc_auc',n_jobs=-1,cv=5,verbose=3,random_state = 2)\n",
    "r_s_model_3.fit(x_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hj7W2xHRbix2"
   },
   "outputs": [],
   "source": [
    "r_s_model_3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEwcF98aJXP1"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    " 'max_leaf_nodes': [22,23,24,25,26,27,28],\n",
    " 'learning_rate' : [0.20,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,0.30],\n",
    " 'max_depth' : [4,5,6,7,8,9,10,11,12],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58zIcoAaJyuR"
   },
   "outputs": [],
   "source": [
    "#verbose = genera mensajes durante el entramiento del modelo 'Fitting 5 folds...'\n",
    "\n",
    "#roc_auc = curva AUC-ROC es la mÃ©trica de selecciÃ³n del modelo para el problema de clasificaciÃ³n \n",
    "#de dos clases mÃºltiples.ROC nos dice quÃ© tan bueno es el modelo para distinguir las clases dadas, \n",
    "#en tÃ©rminos de la probabilidad predicha.\n",
    "\n",
    "#n_jobs = nÃºmero de nucleos que se utilizan (-1 quiere decir que se utilizan todos)\n",
    "\n",
    "r_s_model_3 = RandomizedSearchCV(hb_model , param_distributions=params, n_iter=5, \n",
    "                               scoring='roc_auc',n_jobs=-1,cv=5,verbose=3,random_state = 2)\n",
    "r_s_model_3.fit(x_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXRFbyuvJ0ZZ"
   },
   "outputs": [],
   "source": [
    "r_s_model_3.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uo3TDvgGvTow"
   },
   "source": [
    "## 3.2 Rendimiento con todas las features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wdCrrnJabi6y"
   },
   "outputs": [],
   "source": [
    "#Construyendo el modelo final\n",
    "hb_model = HistGradientBoostingClassifier(learning_rate=0.29, max_depth=6,\n",
    "                               max_leaf_nodes=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coLW01zXdkLN"
   },
   "outputs": [],
   "source": [
    "#MÃ©tricas\n",
    "\n",
    "hb_model.fit(x_train_1, y_train_1)\n",
    "\n",
    "y_pred = hb_model.predict(x_test)\n",
    "\n",
    "acc_hb = accuracy_score(y_test, y_pred)\n",
    "sensibilidad_hb = recall_score(y_test, y_pred)\n",
    "#precision_xgb = precision_score(y_test, y_pred)\n",
    "specificity_hb = confusion_matrix(y_test, y_pred)[0][0]/(confusion_matrix(y_test, y_pred)[0][0]+confusion_matrix(y_test, y_pred)[0][1])\n",
    "auc_hb = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "Tabla_3 = pd.DataFrame({ \"Prestaciones en test\":[\"Accuracy\",\"Sensibility\",'Specificity',\"AUC ROC\"],\n",
    "                      \"HBoost\" : [acc_hb, sensibilidad_hb, specificity_hb, auc_hb]})\n",
    "\n",
    "Tabla_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1QskmnvvZmu"
   },
   "source": [
    "## 3.3 SelecciÃ³n de caracterÃ­sticas (FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UF7lKwhL5Y0d"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#Plot feature importance\n",
    "def plot_feature_importance(importance,names,model_type):\n",
    "\n",
    "  #Create arrays from feature importance and feature names\n",
    "  feature_importance = np.array(importance)\n",
    "  feature_names = np.array(names)\n",
    "\n",
    "  #Create a DataFrame using a Dictionary\n",
    "  data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "  fi_df = pd.DataFrame(data)\n",
    "\n",
    "  #Sort the DataFrame in order decreasing feature importance\n",
    "  fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "  #Define size of bar plot\n",
    "  fig = plt.figure(figsize=(20,6))\n",
    "  #Plot Searborn bar chart\n",
    "  sns.barplot(y=fi_df['feature_importance'], x=fi_df['feature_names'])\n",
    "  #Add chart labels\n",
    "  plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "  plt.xlabel('FEATURE IMPORTANCE')\n",
    "  plt.ylabel('FEATURE NAMES')\n",
    "  plt.tight_layout()\n",
    "  fig.autofmt_xdate(rotation=45)\n",
    "\n",
    "\n",
    "plot_feature_importance(hb_model.feature_importances_*100,x_train_1.columns,'Histogram-based')\n",
    "\n",
    "print(np.sum(hb_model.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uu8VMWix5n00"
   },
   "source": [
    "**SelecciÃ³n de las caracterÃ­sticas en base a la importancia de Ã©stas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00Ov1Kpq5n88"
   },
   "outputs": [],
   "source": [
    "#SelectFromModel\n",
    "\n",
    "scores_cv = []\n",
    "thresholds = np.sort(hb_model.feature_importances_) # obtiene la importancia de cada caracterÃ­stica\n",
    "i = 0\n",
    "for thresh in thresholds:\n",
    "    print(\"{} de {}\".format(i,len(thresholds)))\n",
    "    selection = SelectFromModel(hb_model, threshold=thresh, prefit=True)\n",
    "    select_x_train_1 = selection.transform(x_train_1)\n",
    "    # train model\n",
    "    selection_model = HistGradientBoostingClassifier(learning_rate=0.05, max_depth=25, max_leaf_nodes=25)\n",
    "    #cv estimation\n",
    "    sc =cross_val_score(selection_model, select_x_train_1, y_train_1, cv=10, scoring='roc_auc',n_jobs=-1)\n",
    "    scores_cv.append(sc)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mXll6dW6GQK"
   },
   "outputs": [],
   "source": [
    "plt.rc('xtick',labelsize=15)\n",
    "plt.rc('ytick',labelsize=15)\n",
    "plt.figure(figsize = (80,20))\n",
    "sc_cv = np.asarray(scores_cv)\n",
    "scores_m = np.mean(sc_cv,axis = 1)\n",
    "scores_std = np.std(sc_cv,axis = 1)\n",
    "xx = np.arange(len(scores_m))\n",
    "plt.plot(xx,scores_m,'o-')\n",
    "plt.grid()\n",
    "_ = plt.xticks(xx,labels= np.arange(1,len(scores_m)+1))\n",
    "plt.xlabel('Number of features removed')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5VOjw0FeWeb"
   },
   "source": [
    "## 3.4 Rendimiento con FS en el conjunto de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWyGEa_1fid8"
   },
   "source": [
    "# Machine learning para todas las revisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1klGt7oBBeax"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXsIk3ig90lW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Te damos la bienvenida a Colaboratory",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
